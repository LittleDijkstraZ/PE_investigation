{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCarryOps(a, b):\n",
    "    a,b=int(a),int(b)\n",
    "    def digitSum(n):\n",
    "        return sum(map(int,str(n)))\n",
    "    # assert(a >= 0); assert(b >= 0);\n",
    "    return int((digitSum(a) + digitSum(b) - digitSum(a+b)) / 9)\n",
    "\n",
    "\n",
    "def get_two_operands(line):\n",
    "    x, y = line.split('+')\n",
    "    y = y.split('=')[0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  add_examples_10000_no5_2nddigit.txt\n"
     ]
    }
   ],
   "source": [
    "# open add_examples_10000.txt and select samples with 2nd digit = 5\n",
    "no_5 = ['0','1','2','3','4','6','7','8','9']\n",
    "\n",
    "with open('add_examples_10000.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "output_file_path = 'add_examples_10000_no5_2nddigit.txt'\n",
    "if not os.path.exists(output_file_path):\n",
    "    print('creating file: ', output_file_path)\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for line in lines:\n",
    "            x, y = get_two_operands(line)\n",
    "            if len(x) > 1 and x[-2] == '5':\n",
    "                x = list(x)\n",
    "                x[-2] = random.choice(no_5)\n",
    "                x = ''.join(x)\n",
    "            if len(y) > 1 and y[-2] == '5':\n",
    "                y = list(y)\n",
    "                y[-2] = random.choice(no_5)\n",
    "                y = ''.join(y)\n",
    "            z = int(x) + int(y)\n",
    "            line = f'{x}+{y}={z}\\n'\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2473, 2535, 2589, 2403]\n"
     ]
    }
   ],
   "source": [
    "# count number of carry operations\n",
    "num_carry_list = [0,0,0,0]\n",
    "with open(output_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        x, y = get_two_operands(line)\n",
    "        num_carry = numCarryOps(x, y)\n",
    "        num_carry_list[num_carry] += 1\n",
    "\n",
    "print(num_carry_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 120,015\n",
      "all the unique characters: \n",
      "+0123456789=\n",
      "vocab size: 13\n",
      "train has 120,015 tokens\n"
     ]
    }
   ],
   "source": [
    "# prepare meta file, .bin file\n",
    "\n",
    "output_file_path = 'add_examples_10000_no5_2nddigit.txt'\n",
    "\n",
    "with open(output_file_path, 'r') as f:\n",
    "    data = f.read()        \n",
    "\n",
    "print(f\"length of dataset in characters: {len(data):,}\")\n",
    "\n",
    "# get all the unique characters that occur in this text\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ''.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):  \n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# create the train and test splits\n",
    "n = len(data) # 130,023\n",
    "# train_data = data[:int(n*0.9)]\n",
    "train_data = data\n",
    "# val_data = data[int(n*0.9):]\n",
    "\n",
    "# encode both to integers\n",
    "train_ids = encode(train_data)\n",
    "# val_ids = encode(val_data)\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "# print(f\"val has {len(val_ids):,} tokens\")\n",
    "\n",
    "# export to bin files\n",
    "train_ids = np.array(train_ids, dtype=np.uint16)\n",
    "# val_ids = np.array(val_ids, dtype=np.uint16)\n",
    "train_ids.tofile(f'train_no5_2nddigit.bin')\n",
    "# val_ids.tofile(f'val_no527.bin')\n",
    "\n",
    "# save the meta information as well, to help us encode/decode later\n",
    "meta = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'itos': itos,\n",
    "    'stoi': stoi,\n",
    "}\n",
    "\n",
    "if not os.path.exists('meta.pkl'):\n",
    "    print('saving meta file!')\n",
    "    with open(f'meta.pkl', 'wb') as f:\n",
    "        pickle.dump(meta, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  no5_2nddigit_test.txt\n"
     ]
    }
   ],
   "source": [
    "# create test prompts with 2nd digit = 5\n",
    "test_file_path = 'no5_2nddigit_test.txt'\n",
    "\n",
    "if not os.path.exists(test_file_path):\n",
    "    print('creating file: ', test_file_path)\n",
    "    with open(test_file_path, 'w') as f:\n",
    "        for i in range(1000):\n",
    "            x = random.randint(10, 999)\n",
    "            x = list(str(x))\n",
    "            x[-2] = '5'\n",
    "            x = ''.join(x)\n",
    "            y = random.randint(1, 999)\n",
    "            line = f'{x}+{y}=\\n'\n",
    "            f.write(line)\n",
    "        for i in range(1000):\n",
    "            x = random.randint(1, 999)\n",
    "            y = random.randint(10, 999)\n",
    "            y = list(str(y))\n",
    "            y[-2] = '5'\n",
    "            y = ''.join(y)\n",
    "            line = f'{x}+{y}=\\n'\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  no5_2nddigit_test_dollar.txt\n"
     ]
    }
   ],
   "source": [
    "# append $ in front of the created test prompt too!\n",
    "test_file_dollar_path = 'no5_2nddigit_test_dollar.txt'\n",
    "test_file_path = 'no5_2nddigit_test.txt'\n",
    "\n",
    "if not os.path.exists(test_file_dollar_path):\n",
    "    print('creating file: ', test_file_dollar_path)\n",
    "    with open(test_file_dollar_path, 'w') as f:\n",
    "        with open(test_file_path, 'r') as f2:\n",
    "            lines = f2.readlines()\n",
    "            for line in lines:\n",
    "                line = '$' + line\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  add_examples_10000_no5_1stdigit.txt\n",
      "[2457, 2598, 2563, 2382]\n"
     ]
    }
   ],
   "source": [
    "# open add_examples_10000.txt and select samples with 2nd digit = 5\n",
    "no_5 = ['0','1','2','3','4','6','7','8','9']\n",
    "\n",
    "with open('add_examples_10000.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "output_file_path = 'add_examples_10000_no5_1stdigit.txt'\n",
    "if not os.path.exists(output_file_path):\n",
    "    print('creating file: ', output_file_path)\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for line in lines:\n",
    "            x, y = get_two_operands(line)\n",
    "            if len(x) > 0 and x[-1] == '5':\n",
    "                x = list(x)\n",
    "                x[-1] = random.choice(no_5)\n",
    "                x = ''.join(x)\n",
    "            if len(y) > 0 and y[-1] == '5':\n",
    "                y = list(y)\n",
    "                y[-1] = random.choice(no_5)\n",
    "                y = ''.join(y)\n",
    "            z = int(x) + int(y)\n",
    "            line = f'{x}+{y}={z}\\n'\n",
    "            f.write(line)\n",
    "\n",
    "# count number of carry operations\n",
    "num_carry_list = [0,0,0,0]\n",
    "with open(output_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        x, y = get_two_operands(line)\n",
    "        num_carry = numCarryOps(x, y)\n",
    "        num_carry_list[num_carry] += 1\n",
    "\n",
    "print(num_carry_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 120,018\n",
      "all the unique characters: \n",
      "+0123456789=\n",
      "vocab size: 13\n",
      "train has 120,018 tokens\n"
     ]
    }
   ],
   "source": [
    "# prepare meta file, .bin file\n",
    "\n",
    "output_file_path = 'add_examples_10000_no5_1stdigit.txt'\n",
    "\n",
    "with open(output_file_path, 'r') as f:\n",
    "    data = f.read()        \n",
    "\n",
    "print(f\"length of dataset in characters: {len(data):,}\")\n",
    "\n",
    "# get all the unique characters that occur in this text\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ''.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):  \n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# create the train and test splits\n",
    "n = len(data) # 130,023\n",
    "# train_data = data[:int(n*0.9)]\n",
    "train_data = data\n",
    "# val_data = data[int(n*0.9):]\n",
    "\n",
    "# encode both to integers\n",
    "train_ids = encode(train_data)\n",
    "# val_ids = encode(val_data)\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "# print(f\"val has {len(val_ids):,} tokens\")\n",
    "\n",
    "# export to bin files\n",
    "train_ids = np.array(train_ids, dtype=np.uint16)\n",
    "# val_ids = np.array(val_ids, dtype=np.uint16)\n",
    "train_ids.tofile(f'train_no5_1stdigit.bin')\n",
    "# val_ids.tofile(f'val_no527.bin')\n",
    "\n",
    "# save the meta information as well, to help us encode/decode later\n",
    "meta = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'itos': itos,\n",
    "    'stoi': stoi,\n",
    "}\n",
    "\n",
    "if not os.path.exists('meta.pkl'):\n",
    "    print('saving meta file!')\n",
    "    with open(f'meta.pkl', 'wb') as f:\n",
    "        pickle.dump(meta, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  no5_1stdigit_test.txt\n",
      "creating file:  no5_1stdigit_test_dollar.txt\n"
     ]
    }
   ],
   "source": [
    "# create test prompts with 2nd digit = 5\n",
    "test_file_path = 'no5_1stdigit_test.txt'\n",
    "\n",
    "if not os.path.exists(test_file_path):\n",
    "    print('creating file: ', test_file_path)\n",
    "    with open(test_file_path, 'w') as f:\n",
    "        for i in range(1000):\n",
    "            x = random.randint(1, 999)\n",
    "            x = list(str(x))\n",
    "            x[-1] = '5'\n",
    "            x = ''.join(x)\n",
    "            y = random.randint(1, 999)\n",
    "            line = f'{x}+{y}=\\n'\n",
    "            f.write(line)\n",
    "        for i in range(1000):\n",
    "            x = random.randint(1, 999)\n",
    "            y = random.randint(1, 999)\n",
    "            y = list(str(y))\n",
    "            y[-1] = '5'\n",
    "            y = ''.join(y)\n",
    "            line = f'{x}+{y}=\\n'\n",
    "            f.write(line)\n",
    "\n",
    "# append $ in front of the created test prompt too!\n",
    "test_file_dollar_path = 'no5_1stdigit_test_dollar.txt'\n",
    "test_file_path = 'no5_1stdigit_test.txt'\n",
    "\n",
    "if not os.path.exists(test_file_dollar_path):\n",
    "    print('creating file: ', test_file_dollar_path)\n",
    "    with open(test_file_dollar_path, 'w') as f:\n",
    "        with open(test_file_path, 'r') as f2:\n",
    "            lines = f2.readlines()\n",
    "            for line in lines:\n",
    "                line = '$' + line\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  add_examples_10000_no5_3rddigit.txt\n",
      "[2476, 2543, 2568, 2413]\n"
     ]
    }
   ],
   "source": [
    "# open add_examples_10000.txt and select samples with 2nd digit = 5\n",
    "no_5 = ['0','1','2','3','4','6','7','8','9']\n",
    "\n",
    "with open('add_examples_10000.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "output_file_path = 'add_examples_10000_no5_3rddigit.txt'\n",
    "if not os.path.exists(output_file_path):\n",
    "    print('creating file: ', output_file_path)\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for line in lines:\n",
    "            x, y = get_two_operands(line)\n",
    "            if len(x) > 2 and x[-3] == '5':\n",
    "                x = list(x)\n",
    "                x[-3] = random.choice(no_5)\n",
    "                x = ''.join(x)\n",
    "            if len(y) > 2 and y[-3] == '5':\n",
    "                y = list(y)\n",
    "                y[-3] = random.choice(no_5)\n",
    "                y = ''.join(y)\n",
    "            z = int(x) + int(y)\n",
    "            line = f'{x}+{y}={z}\\n'\n",
    "            f.write(line)\n",
    "\n",
    "# count number of carry operations\n",
    "num_carry_list = [0,0,0,0]\n",
    "with open(output_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        x, y = get_two_operands(line)\n",
    "        num_carry = numCarryOps(x, y)\n",
    "        num_carry_list[num_carry] += 1\n",
    "\n",
    "print(num_carry_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 119,928\n",
      "all the unique characters: \n",
      "+0123456789=\n",
      "vocab size: 13\n",
      "train has 119,928 tokens\n"
     ]
    }
   ],
   "source": [
    "# prepare meta file, .bin file\n",
    "\n",
    "output_file_path = 'add_examples_10000_no5_3rddigit.txt'\n",
    "\n",
    "with open(output_file_path, 'r') as f:\n",
    "    data = f.read()        \n",
    "\n",
    "print(f\"length of dataset in characters: {len(data):,}\")\n",
    "\n",
    "# get all the unique characters that occur in this text\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ''.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):  \n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# create the train and test splits\n",
    "n = len(data) # 130,023\n",
    "# train_data = data[:int(n*0.9)]\n",
    "train_data = data\n",
    "# val_data = data[int(n*0.9):]\n",
    "\n",
    "# encode both to integers\n",
    "train_ids = encode(train_data)\n",
    "# val_ids = encode(val_data)\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "# print(f\"val has {len(val_ids):,} tokens\")\n",
    "\n",
    "# export to bin files\n",
    "train_ids = np.array(train_ids, dtype=np.uint16)\n",
    "# val_ids = np.array(val_ids, dtype=np.uint16)\n",
    "train_ids.tofile(f'train_no5_3rddigit.bin')\n",
    "# val_ids.tofile(f'val_no527.bin')\n",
    "\n",
    "# save the meta information as well, to help us encode/decode later\n",
    "meta = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'itos': itos,\n",
    "    'stoi': stoi,\n",
    "}\n",
    "\n",
    "if not os.path.exists('meta.pkl'):\n",
    "    print('saving meta file!')\n",
    "    with open(f'meta.pkl', 'wb') as f:\n",
    "        pickle.dump(meta, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file:  no5_3rddigit_test.txt\n",
      "creating file:  no5_3rddigit_test_dollar.txt\n"
     ]
    }
   ],
   "source": [
    "# create test prompts with 2nd digit = 5\n",
    "test_file_path = 'no5_3rddigit_test.txt'\n",
    "\n",
    "if not os.path.exists(test_file_path):\n",
    "    print('creating file: ', test_file_path)\n",
    "    with open(test_file_path, 'w') as f:\n",
    "        for i in range(1000):\n",
    "            x = random.randint(100, 999)\n",
    "            x = list(str(x))\n",
    "            x[-3] = '5'\n",
    "            x = ''.join(x)\n",
    "            y = random.randint(1, 999)\n",
    "            line = f'{x}+{y}=\\n'\n",
    "            f.write(line)\n",
    "        for i in range(1000):\n",
    "            x = random.randint(1, 999)\n",
    "            y = random.randint(100, 999)\n",
    "            y = list(str(y))\n",
    "            y[-3] = '5'\n",
    "            y = ''.join(y)\n",
    "            line = f'{x}+{y}=\\n'\n",
    "            f.write(line)\n",
    "\n",
    "# append $ in front of the created test prompt too!\n",
    "test_file_dollar_path = 'no5_3rddigit_test_dollar.txt'\n",
    "test_file_path = 'no5_3rddigit_test.txt'\n",
    "\n",
    "if not os.path.exists(test_file_dollar_path):\n",
    "    print('creating file: ', test_file_dollar_path)\n",
    "    with open(test_file_dollar_path, 'w') as f:\n",
    "        with open(test_file_path, 'r') as f2:\n",
    "            lines = f2.readlines()\n",
    "            for line in lines:\n",
    "                line = '$' + line\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
