{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../')\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "\n",
    "# from model import GPTConfig, GPT\n",
    "from pe_info.model_nope import GPTConfig as GPTConfig_nope, GPT as GPT_nope\n",
    "from main_utils import *\n",
    "from vis_utils import *\n",
    "\n",
    "\n",
    "# refresh parames from here\n",
    "\n",
    "from vis_params import * # import the default parameters\n",
    "config_keys = [k for k, v in globals().items() if not k.startswith(\n",
    "    '_') and isinstance(v, (int, float, bool, str, type(None)))]\n",
    "# exec(open('./pe_info/config2_pe/modp/jason_train_addition_bal.py').read()) # overrides from command line or config file\n",
    "# exec(open('./pe_info/config2_pe/mod3/jason_train_addition_bal.py').read()) # overrides from command line or config file\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/paridy/jason_train_addition_bal.py').read()) # overrides from command line or config file\n",
    "\n",
    "# overrides from command line or config file\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/addition/reverse/jason_train_addition_bal.py').read())\n",
    "# exec(open('./pe_info/config2_pe/order/jason_train_addition_bal.py').read())\n",
    "# exec(open('./pe_info/config2_pe/rev/rev16.py').read())\n",
    "exec(open('./pe_info/config2_pe/identify/identify9.py').read())\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/wherex/wherex9.py').read())\n",
    "\n",
    "\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/wherex/wherex78x7.py').read())\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/wherex/wherex78x7.py').read())\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/rev/add3.py').read())\n",
    "\n",
    "\n",
    "# exec(open('./pe_info/config2_pe/modclean/jason_train_addition_bal.py').read())\n",
    "\n",
    "\n",
    "\n",
    "config = {k: globals()[k] for k in config_keys}  # will be useful for logging\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks\n",
    "val_data_path = start.split(':')[-1] # get the test data path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating meta file for all reasonable characters...\n",
      "all the unique characters: \n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
      "vocab size: 96\n",
      "data has 240,000 tokens\n",
      "data has 240,000 tokens\n"
     ]
    }
   ],
   "source": [
    "# for later use in torch.autocast\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {'float32': torch.float32,\n",
    "           'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(\n",
    "    device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# poor man's data loader\n",
    "if data_type == 'binary':\n",
    "    data_dir = os.path.join('data', dataset)\n",
    "    train_data = np.memmap(os.path.join(\n",
    "        data_dir, train_data_path), dtype=np.uint16, mode='r')\n",
    "    val_data = np.memmap(os.path.join(\n",
    "        data_dir, val_data_path), dtype=np.uint16, mode='r')\n",
    "    if train_both:\n",
    "        train_data2 = np.memmap(os.path.join(\n",
    "            data_dir, train_data_path2), dtype=np.uint16, mode='r')\n",
    "        val_data2 = np.memmap(os.path.join(\n",
    "            data_dir, val_data_path2), dtype=np.uint16, mode='r')\n",
    "    if eval_text:\n",
    "        if eval_text_data_path is None:\n",
    "            print(\n",
    "                'eval_text_data_path is None!!! No binary file to evaluate perplexity on.')\n",
    "        eval_text_data = np.memmap(\n",
    "            eval_text_data_path, dtype=np.uint16, mode='r')\n",
    "    # test_data_str = None # test_data for addition testing will be handled with \"start\"\n",
    "    meta_path = None\n",
    "else:\n",
    "    # check for data_format\n",
    "    if data_type == 'text':\n",
    "        if ('reverse' in data_format and not reverse_c) or (reverse_c and 'reverse' not in data_format):\n",
    "            raise ValueError(\n",
    "                'reverse_c must be True for data_format == \"reverse\"')\n",
    "        elif (data_format == 'algo_reasoning' and not algo_reason) or (algo_reason and data_format != 'algo_reasoning'):\n",
    "            raise ValueError(\n",
    "                'algo_reason must be True for data_format == \"algo_reasoning\"')\n",
    "    meta_path_specified = False\n",
    "\n",
    "    data_dir = os.path.join('data', dataset)\n",
    "    train_data_path = os.path.join(data_dir, train_data_path)\n",
    "    # val_data = os.path.join(data_dir, val_data_path)\n",
    "    train_data_list = get_data_list(\n",
    "        train_data_path, operator=operator)  # a list of (x, y, op)\n",
    "    val_data_list = get_data_list(filename=val_data_path, operator=operator)\n",
    "    train_data_str = generate_data_str(train_data_list, operator=operator, format=data_format, train=True,\n",
    "                                       shuffle=data_shuffle, add_space=add_space, simple=simple, random_A=random_A, random_C=random_C)\n",
    "    val_data_str = generate_data_str(val_data_list, operator=operator, format=data_format, train=True,\n",
    "                                     shuffle=data_shuffle, add_space=add_space, simple=simple, random_A=random_A, random_C=random_C)\n",
    "    meta, meta_path, data_encoder, data_decoder = create_meta_file(\n",
    "        vocabulary=vocabulary, input_data_str=train_data_str, tokenizer=tokenizer)\n",
    "    meta_vocab_size = meta['vocab_size']\n",
    "    train_data = data_encoder(train_data_str)\n",
    "    val_data = data_encoder(val_data_str)\n",
    "    if eval_addition_train and start_train is None:\n",
    "        # specify the start_train to be our train data file\n",
    "        start_train = f\"FILE:{train_data_path}\"\n",
    "\n",
    "    if train_both:\n",
    "        # This is for the case where we use two different datasets for training\n",
    "        # we sample from both with a specified ratio - data_ratio\n",
    "        # TODO: let's leave this here for now.\n",
    "        train_data2 = np.memmap(os.path.join(\n",
    "            data_dir, train_data_path2), dtype=np.uint16, mode='r')\n",
    "        val_data2 = np.memmap(os.path.join(\n",
    "            data_dir, val_data_path2), dtype=np.uint16, mode='r')\n",
    "\n",
    "    if eval_text:\n",
    "        # eval_text_data = np.memmap(eval_text_data_path, dtype=np.uint16, mode='r')\n",
    "        text_data_list = get_data_list(eval_text_data_path, operator='text')\n",
    "        text_data_str = generate_data_str(\n",
    "            text_data_list, operator='text', format=data_format, train=False, shuffle=False)\n",
    "        eval_text_data = data_encoder(text_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1 tokens\n",
      "data has 1 tokens\n",
      "data has 1 tokens\n",
      "data has 1 tokens\n"
     ]
    }
   ],
   "source": [
    "from numpy import block\n",
    "\n",
    "\n",
    "space_token = data_encoder(' ')[0]\n",
    "switch_line_token = data_encoder('\\n')[0]\n",
    "equal_token = data_encoder('=')[0]\n",
    "dollar_token = data_encoder('$')[0]\n",
    "# non_causal_fix_length = 15\n",
    "# non_causal_fix_length = 27\n",
    "answer_length = 1\n",
    "\n",
    "\n",
    "def get_batch(split, autoregressive_training=False, batch_size=batch_size):\n",
    "    global causal_training\n",
    "    attn_mask = None\n",
    "    w = None\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    if train_both:\n",
    "        data2 = train_data2 if split == 'train' else val_data2\n",
    "        batch_size2 = int(batch_size*data_ratio)\n",
    "        ix = torch.randint(len(data) - block_size, (batch_size-batch_size2,))\n",
    "        ix2 = torch.randint(len(data2) - block_size, (batch_size2,))\n",
    "    else:\n",
    "        if causal_training:\n",
    "            ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "        else:\n",
    "            split_points = np.where(data == (switch_line_token))[0]\n",
    "            answer_split_points = np.where(data == (equal_token))[0]\n",
    "            answer_length_list = split_points - answer_split_points - 1\n",
    "            split_points = split_points + 1  # i should have had this\n",
    "            split_points = np.hstack([np.array([0]), split_points.flatten()])\n",
    "\n",
    "            sample_length_list = np.diff(split_points)\n",
    "            start_points = split_points[:-1]\n",
    "\n",
    "            randidx = np.random.permutation(len(start_points))[:batch_size]\n",
    "            ix = start_points[randidx]\n",
    "            sample_length_list = sample_length_list[randidx]\n",
    "            answer_length_list = answer_length_list[randidx]\n",
    "\n",
    "    if causal_training:\n",
    "        x = torch.stack(\n",
    "            [torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "        y = torch.stack(\n",
    "            [torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    else:\n",
    "        remove_dollar_count = 1 if dollar_token in data else 0\n",
    "        if not autoregressive_training:\n",
    "            cur_answer_length_list = np.random.randint(\n",
    "                1+remove_dollar_count, answer_length_list+1) + 1\n",
    "        else:\n",
    "            cur_answer_length_list = answer_length_list + 1 + 4\n",
    "        x = [data[ix[i]:ix[i]+sample_length_list[i]-cur_answer_length_list[i]\n",
    "                  ].astype(np.int64) for i in range(len(ix))]\n",
    "        x_len = [len(x[i]) for i in range(len(x))]\n",
    "        pad_to_length = max(x_len)\n",
    "        min_length = min(x_len)\n",
    "        # only do padding when the length is not equal\n",
    "        if pad_to_length > min_length:\n",
    "            x = np.vstack([np.pad(x[i], (pad_to_length-len(x[i]), 0), mode='constant',\n",
    "                          constant_values=space_token) for i in range(len(x))])\n",
    "            attn_mask = np.ones_like(x)\n",
    "            # mask out the paddings\n",
    "            attn_mask[x == space_token] = 0\n",
    "            attn_mask = attn_mask[..., None]\n",
    "            attn_mask = attn_mask @ attn_mask.transpose(0, 2, 1)\n",
    "            attn_mask = attn_mask.astype(bool)\n",
    "            if (attn_mask == 1).all():\n",
    "                attn_mask = None\n",
    "            else:\n",
    "                attn_mask = torch.from_numpy(attn_mask)\n",
    "        else:\n",
    "            x = np.vstack(x)\n",
    "            attn_mask = None\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        # predict the next digit\n",
    "        if not autoregressive_training:\n",
    "            y = torch.stack([torch.from_numpy((data[ix[i]+sample_length_list[i]-cur_answer_length_list[i]:ix[i] +\n",
    "                            1+sample_length_list[i]-cur_answer_length_list[i]]).astype(np.int64)) for i in range(len(ix))])\n",
    "        else:\n",
    "            y = [torch.from_numpy((data[ix[i]+sample_length_list[i]-cur_answer_length_list[i]:ix[i]-1+sample_length_list[i]]).astype(np.int64)) for i in range(len(ix))]\n",
    "            max_len_y = max([len(y[i]) for i in range(len(y))])\n",
    "            y = np.vstack([np.pad(y[i], (0, max_len_y-len(y[i])), mode='constant',\n",
    "                          constant_values=space_token) for i in range(len(y))])\n",
    "            y = torch.from_numpy(y)\n",
    "            w = torch.ones_like(y)\n",
    "            w[y == space_token] = 0\n",
    "\n",
    "    if train_both:\n",
    "        x2 = torch.stack(\n",
    "            [torch.from_numpy((data2[i:i+block_size]).astype(np.int64)) for i in ix2])\n",
    "        y2 = torch.stack(\n",
    "            [torch.from_numpy((data2[i+1:i+1+block_size]).astype(np.int64)) for i in ix2])\n",
    "        x = torch.cat([x, x2])\n",
    "        y = torch.cat([y, y2])\n",
    "\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(\n",
    "            device, non_blocking=True)\n",
    "        if autoregressive_training:\n",
    "            w = w.pin_memory().to(device, non_blocking=True)\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.to(device)\n",
    "\n",
    "    # attn_mask = None\n",
    "    return x, y, attn_mask, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22]) torch.Size([1, 1])\n",
      "identify(161541152,1)= 1\n",
      "i,d,e,n,t,i,f,y,(,1,6,1,5,4,1,1,5,2,,,1,),=,\n"
     ]
    }
   ],
   "source": [
    "causal_training = False\n",
    "x, y, z, w = get_batch('test', autoregressive_training=False, batch_size=1)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "if z is not None:\n",
    "    print(z.shape)\n",
    "\n",
    "for hidx in range(min(10, len(x))):\n",
    "    print(data_decoder(x[hidx].cpu().numpy()), data_decoder(y[hidx].cpu().numpy()))\n",
    "    for xi in x[hidx].cpu().numpy():\n",
    "        print(data_decoder(xi[..., None]), end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a new model from scratch\n",
      "Loading meta from meta_all_ascii_chars.pkl...\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# init these up here, can override if init_from='resume' (i.e. from a checkpoint)\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "best_perplexity = 1e9  # on text data\n",
    "best_accuracy = -1  # on addition data\n",
    "\n",
    "if meta_path_specified:\n",
    "    # attempt to derive vocab_size from the dataset\n",
    "    meta_path = os.path.join(data_dir, 'meta.pkl')\n",
    "    meta_vocab_size = None\n",
    "    if os.path.exists(meta_path):\n",
    "        with open(meta_path, 'rb') as f:\n",
    "            meta = pickle.load(f)\n",
    "        meta_vocab_size = meta['vocab_size']\n",
    "        print(f\"found vocab_size = {meta_vocab_size} (inside {meta_path})\")\n",
    "    else:\n",
    "        meta_path = None\n",
    "\n",
    "# model init\n",
    "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
    "                  bias=bias, vocab_size=None, dropout=dropout)  # start with model_args from command line\n",
    "\n",
    "\n",
    "# init a new model from scratch\n",
    "print(\"Initializing a new model from scratch\")\n",
    "# determine the vocab size we'll use for from-scratch training\n",
    "if meta_vocab_size is None:\n",
    "    print(\"defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\")\n",
    "model_args['vocab_size'] = meta_vocab_size if meta_vocab_size is not None else 50304\n",
    "# gptconf = GPTConfig(**model_args)\n",
    "# model = GPT(gptconf)\n",
    "\n",
    "encode, decode = get_encode_decode(meta_path, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Flash Attention\n",
      "Block 0: 1.0 | att_res True | perm 0.0 | mlp_res True | layerwise_pe 0.0 | casual True\n",
      "Using Flash Attention\n",
      "Block 1: 1.0 | att_res True | perm 0.0 | mlp_res True | layerwise_pe 0.0 | casual True\n",
      "Using Flash Attention\n",
      "Block 2: 1.0 | att_res True | perm 0.0 | mlp_res True | layerwise_pe 0.0 | casual True\n",
      "Using Flash Attention\n",
      "Block 3: 1.0 | att_res True | perm 0.0 | mlp_res True | layerwise_pe 0.0 | casual True\n",
      "Using Flash Attention\n",
      "Block 4: 1.0 | att_res True | perm 0.0 | mlp_res True | layerwise_pe 0.0 | casual True\n",
      "Using Flash Attention\n",
      "Block 5: 1.0 | att_res True | perm 0.0 | mlp_res True | layerwise_pe 0.0 | casual True\n",
      "PE in use: original\n",
      "number of parameters: 10.66M\n",
      "test_run\n",
      "0 \n",
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(96, 384)\n",
      "    (drop): Dropout(p=0.2, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-5): 6 x Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (pre_att_identity): Identity()\n",
      "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
      "          (identity): Identity()\n",
      "          (iq): Identity()\n",
      "          (ik): Identity()\n",
      "          (iv): Identity()\n",
      "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm()\n",
      "    (wpe): Embedding(256, 384)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=384, out_features=96, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model init\n",
    "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
    "                  bias=bias, vocab_size=None, dropout=dropout, use_flash=use_flash,\n",
    "                  use_residual=use_residual, use_pe=use_pe,\n",
    "                  no_att_residual=no_att_residual,\n",
    "                  no_mlp_residual=no_mlp_residual,\n",
    "                  layerwise_pe=layerwise_pe,\n",
    "                  permute=permute,\n",
    "                  not_causal=not_causal\n",
    "                  )  # jason's change\n",
    "model_args['vocab_size'] = meta_vocab_size if meta_vocab_size is not None else 50304\n",
    "# if use_pe=='original':\n",
    "#     gptconf = GPTConfig(**model_args)\n",
    "#     model = GPT(gptconf)\n",
    "# elif use_pe == 'nope':\n",
    "gptconf = GPTConfig_nope(**model_args)\n",
    "model = GPT_nope(gptconf)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identify(641622748\n",
      "tensor([[13, 19, 10, 30, 18]], device='cuda:0')\n",
      ",2)=1\n",
      "ap~C<\n",
      "tensor(4.8004, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x, y, z, w = get_batch('valid', autoregressive_training=True, batch_size=1)\n",
    "print(w.sum())\n",
    "with torch.no_grad():\n",
    "    # model.autoregressive_training(x, y, max_new_tokens=y.shape, attn_mask=z)\n",
    "    model.train()\n",
    "    # outs, loss = model(x, y, attn_mask=z, causal_training=causal_training)\n",
    "    outs, loss = model.autoregressive_training(\n",
    "        x, y, w,  max_new_tokens=y.shape[-1], attn_mask=z)\n",
    "\n",
    "    print(decode(x[:10].flatten().detach().cpu().numpy()))\n",
    "    print(y[:10])\n",
    "    print(decode(y[:10].flatten().detach().cpu().numpy()))\n",
    "    print(decode(outs[:10].argmax(-1).flatten().detach().cpu().numpy()))\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "def load_checkpoint(ckpt_path, \n",
    "                    model_config, \n",
    "                    model_type, \n",
    "                    device='cuda', \n",
    "                    return_config=False, \n",
    "                    return_model=True,\n",
    "                    init=False,\n",
    "                    init_additional_config={},):\n",
    "    # load ckpt into model\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    model_args = checkpoint['model_args']\n",
    "    # for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:\n",
    "    # model_args[k] = checkpoint_model_args[k]\n",
    "    # for k in checkpoint_model_args:\n",
    "    #         model_args[k] = checkpoint_model_args[k]\n",
    "    # create the model\n",
    "    original_gptconf = model_config(**model_args)\n",
    "    gptconf = model_config(**model_args)\n",
    "    if return_model:\n",
    "        if not init:\n",
    "            model = model_type(original_gptconf)\n",
    "            \n",
    "            state_dict = checkpoint['model']\n",
    "            # fix the keys of the state dictionary :(\n",
    "            # honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "            unwanted_prefix = '_orig_mod.'\n",
    "            for k, v in list(state_dict.items()):\n",
    "                if k.startswith(unwanted_prefix):\n",
    "                    state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "            model.load_state_dict(state_dict)\n",
    "        else:\n",
    "            # override with keys\n",
    "            for k in init_additional_config:\n",
    "                original_gptconf.__dict__[k] = init_additional_config[k]\n",
    "            model = model_type(original_gptconf)\n",
    "   \n",
    "    if return_config:\n",
    "        if return_model:\n",
    "            return model, gptconf\n",
    "        else: \n",
    "            return gptconf\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "\n",
    "def generate_output(model, \n",
    "                    prompt, \n",
    "                    max_new_tokens=5, \n",
    "                    attn_mask=None, \n",
    "                    top_k=None):\n",
    "    # temperature = 0.8\n",
    "    # top_k = 200\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    if compile:\n",
    "        model = torch.compile(model)  # requires PyTorch 2.0 (optional)\n",
    "    # run generation\n",
    "\n",
    "    start_ids = encode(prompt)\n",
    "    x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_samples = 1\n",
    "        for k in range(num_samples):\n",
    "\n",
    "            attn_mask = None\n",
    "\n",
    "            y = model.generate(x, max_new_tokens,\n",
    "                               attn_mask=attn_mask, top_k=top_k)\n",
    "\n",
    "    return decode(y[0].tolist())\n",
    "\n",
    "\n",
    "def PCA_analysis(prompt, embs, out_text, config_dir):\n",
    "    pca = PCA(n_components=2)\n",
    "    new_x = pca.fit_transform(embs.cpu().numpy())\n",
    "    data = []\n",
    "    for i, (text, pt) in enumerate(zip(prompt, new_x)):\n",
    "        trace = go.Scatter(\n",
    "            x=[pt[0]],\n",
    "            y=[pt[1]],\n",
    "            mode='markers+text',\n",
    "            marker=dict(size=10),  # Adjust the size of the points\n",
    "            text=[str(i+1)],\n",
    "            textposition='middle center',  # Center the text within the marker\n",
    "            name=text,\n",
    "            textfont=dict(\n",
    "                family='Times New Rotman',  # Specify the font family\n",
    "                size=18,  # Adjust the font size\n",
    "                color='black',  # Adjust the font color\n",
    "            ),\n",
    "        )\n",
    "        data.append(trace)\n",
    "\n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(title='Principal Component 1'),\n",
    "        yaxis=dict(title='Principal Component 2'),\n",
    "        title=f'PCA visualization for {prompt}'\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.show()\n",
    "#   out_num = out_text.split('=')[-1][:-1]\n",
    "#   eqn = out_text.split('=')[0]\n",
    "#   out_text = eqn+'='+out_num[::-1]+out_text[-1]\n",
    "    print(out_text)\n",
    "    # print(new_x)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    import plotly.io as pio\n",
    "    pio.write_html(fig, f'./{config_dir}/{prompt}.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# config_dir = \"out2/addition_reverse/\"\n",
    "\n",
    "# ckpt = f\"{config_dir}/ckpt_10000_final.pt\"\n",
    "# import yaml\n",
    "# with open(f'{config_dir}/addition_reverse/config.yaml') as f:\n",
    "#   config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# gptconf = GPTConfig_nope(**model_args)\n",
    "# model = GPT_nope(gptconf)\n",
    "# model = load_checkpoint(ckpt, GPTConfig_nope, GPT_nope)\n",
    "# model = load_checkpoint(ckpt, GPTConfig, GPT)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "\n",
    "exp_list = []\n",
    "# exp_list\n",
    "# exp_list = glob.glob('./outputs/residual_exp/*') + glob.glob('./outputs/nope_residual_exp/*')\n",
    "# exp_list = glob.glob('./outputs/modp_nope_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/modp_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/modp_nc_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/modp_nc_nope_residual_exp/*') \n",
    "# exp_list = glob.glob('./outputs_ref/modclean_nope_nope/*')\n",
    "\n",
    "\n",
    "# exp_list = glob.glob('./outputs/paridy_nope_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/paridy_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/paridy_nc_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/paridy_nc_nope_residual_exp/*') \n",
    "\n",
    "\n",
    "# exp_list = glob.glob('./outputs/mod3_nope_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/mod3_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/mod3_nc_residual_exp/*') \\\n",
    "#     + glob.glob('./outputs/mod3_nc_nope_residual_exp/*') \n",
    "\n",
    "# exp_list = glob.glob('./outputs/paridy_nope_residual_exp/*')\n",
    "\n",
    "# exp_list = glob.glob('./outputs/residual_exp/*')\n",
    "# exp_list = glob.glob('./outputs_permute/add3_nope*/*') \\\n",
    "#     + glob.glob('./outputs_permute/add3_residual*/*') \\\n",
    "#     + glob.glob('./outputs_permute/add3_shuffle_6_*/*') \n",
    "# exp_list = glob.glob('./outputs_permute/add3_shuffle_6_*/*')\n",
    "\n",
    "# exp_list = glob.glob('./outputs_permute/add3_remove_16_*/*') \\\n",
    "#     + glob.glob('./outputs_permute/add3_remove_16_lwp_residual*/*') \n",
    "# exp_list = glob.glob('./outputs_permute/add3_remove_8_*/*')\n",
    "\n",
    "\n",
    "# ===== removing residual connections\n",
    "# exp_list = glob.glob('./outputs/nope_residual_exp/*')\n",
    "# exp_list = [p for p in exp_list if 'sd222' in p]\n",
    "\n",
    "# exp_list += [p for p in glob.glob('./outputs_permute/add3_remove_8_rotary_rotary/*') if 'lwpTrue' not in p]\n",
    "# exp_list += glob.glob('./outputs_permute/add3_remove_8_T5_T5/*')\n",
    "# exp_list += [p for p in glob.glob('./outputs_permute/add3_remove_8_sin_residual_exp/*') if 'lwpTrue' not in p]\n",
    "# exp_list += glob.glob('./outputs_permute/add3_remove_8_residual_exp/*')\n",
    "\n",
    "\n",
    "# ===== 6-12 layers\n",
    "# exp_list = glob.glob('./outputs_ref_*/rev16*/*') \n",
    "# exp_list = glob.glob('./outputs_ref_6/order*/*') \n",
    "# exp_list = glob.glob('./outputs_ref_6/add*/*') \n",
    "# exp_list = glob.glob('./outputs_ref_*/wherex*/*')\n",
    "exp_list = glob.glob('./outputs_ref_6/identify*/*') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# exp_list = glob.glob('./outputs_ref_2/rev16*/*') \n",
    "\n",
    "# exp_list = glob.glob('./outputs_ref_2/wherex78x7*/*') \n",
    "\n",
    "\n",
    "    # glob.glob('./outputs_ref/wherex*/*')\n",
    "# exp_list = [p for p in exp_list if 'order' in p]\n",
    "# exp_list = [p for p in exp_list if 'rev16' in p]\n",
    "\n",
    "\n",
    "# exp_list = glob.glob('./outputs_permute/add3_lwp_residual_exp/*')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# exp_list = glob.glob('./outputs_permute/add3_remove_8_sin_sin/*')\n",
    "# exp_list = glob.glob('./outputs_permute/add3_remove_8_*/*')\n",
    "# exp_list = exp_list[len(exp_list)//2:]\n",
    "\n",
    "\n",
    "\n",
    "# exp_list = ['./outputs/nope_residual_exp/addition_reverse_sd111_T2401311659_nope_res=[1, 2, 3, 4, 5]']\n",
    "\n",
    "# exp_list = [p for p in exp_list if '[0' not in p]\n",
    "# exp_list  = [p for p in exp_list if 'res=[0, 1, 2, 3, 4, 5]' in p or 'res=[3, 4, 5]' in p]\n",
    "# exp_list  = [p for p in exp_list if 'res=[0, 1, 2, 3, 4, 5]' in p and '246' not in p and '247' not in p]\n",
    "# exp_list  = [p for p in exp_list if 'res=[2, 3, 4, 5]' in p]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exp_list = [[x, x.split('/')[-1]] for x in exp_list] \n",
    "print(len(exp_list))\n",
    "# calc ratio\n",
    "# increase contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36ddfd0d07345bb9c234f2fbc6d2f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeded everything: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeded everything: 20\n",
      "causal_training is True\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"$\" + f\"{i}\"*3 + '+' + f\"{i}\"*3 + '='\n",
    "import glob\n",
    "from IPython.utils import io\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# fixed_length = 10\n",
    "task_type = 'identify'\n",
    "fixed_length = {\n",
    "    'add':9,\n",
    "    'rev16':22,\n",
    "    'order':19,\n",
    "    'wherex7':17,\n",
    "    'wherex9':19,\n",
    "    'identify':22,\n",
    "}[task_type]\n",
    "# fixed_length = 10\n",
    "\n",
    "# total_tokens = 2048\n",
    "total_samples = 256\n",
    "sample_num = 1024\n",
    "all_level_input_act_list = []\n",
    "all_out_list = []\n",
    "\n",
    "rand_perm = False\n",
    "if rand_perm:\n",
    "    print(\"permutation added\")\n",
    "equal_distancing_exp = False\n",
    "use_1_sample = False\n",
    "model_init = False\n",
    "if model_init:\n",
    "    print(\"model init\")\n",
    "    init_additional_config = {\n",
    "        'n_head':1,\n",
    "    }\n",
    "    # put additional configs that needs to be initialized here\n",
    "else:\n",
    "    init_additional_config = {}\n",
    "\n",
    "small_dim = False\n",
    "if small_dim:\n",
    "    print(\"small dim\")\n",
    "\n",
    "\n",
    "ablation_config = {\n",
    "    \"V_out\": False,\n",
    "    \"no_K\": False,\n",
    "    \"no_V\": False,\n",
    "    \"no_Q\": False,\n",
    "    \"shrink_x\": False,\n",
    "    # \"c_proj\": True,\n",
    "    # only one at a time\n",
    "    \"func_config\": {\n",
    "        0: None,\n",
    "        1:\"nodiv\", \n",
    "        2:\"softmax\", \n",
    "        3:\"abs\", \n",
    "        4:\"relu\", \n",
    "        5:\"divsum\", \n",
    "        6:\"gelu\",\n",
    "        7:\"gelu_divabs\",\n",
    "        8:\"sigmoid\",\n",
    "        9:\"same\"}[0],\n",
    "}\n",
    "for k in ablation_config:\n",
    "    if ablation_config[k]:\n",
    "        if k == \"func_config\":\n",
    "            print(f\"{k}: {ablation_config[k]}\")\n",
    "        else:\n",
    "            print(f\"{k} is on\")\n",
    "\n",
    "model_list = []\n",
    "useful_name_list = []\n",
    "for idx, (config_dir, model_config_fold) in enumerate(tqdm(exp_list)):\n",
    "    glob_dir = config_dir.replace(\"[\", \"*\").replace(\"]\", \"*\")\n",
    "    try:\n",
    "        yaml_path = glob.glob(f\"{glob_dir}/**/config.yaml\")[0]\n",
    "        csv_path = glob.glob(f\"{glob_dir}/**/result.csv\")[0]\n",
    "        revised_glob_dir = \"/\".join(yaml_path.split(\"/\")[:-2])\n",
    "        exp_list[idx][0] = revised_glob_dir\n",
    "        exp_list[idx][1] = revised_glob_dir.split(\"/\")[-1]\n",
    "\n",
    "        config_dir = \"/\".join(yaml_path.split(\"/\")[:-2])\n",
    "        with open(yaml_path) as f:\n",
    "            config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # ckpt = f\"{config_dir}/ckpt_10000_acc.pt\"\n",
    "        glob_dir = config_dir.replace(\"[\", \"*\").replace(\"]\", \"*\")\n",
    "        try:\n",
    "            all_ckpts = sorted(glob.glob(f\"{glob_dir}/ckpt_*.pt\"), key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "        except:\n",
    "            all_ckpts = [gdir for gdir in glob.glob(f\"{glob_dir}/ckpt_*.pt\") if '_acc' in gdir]\n",
    "        # ckpt = f\"{config_dir}/ckpt_2000_acc.pt\"\n",
    "    \n",
    "        gptconfig = load_checkpoint(all_ckpts[0], GPTConfig_nope, GPT_nope, device='cuda', return_config=True, return_model=False)\n",
    "        if gptconfig.n_embd != 384: continue\n",
    "        if gptconfig.n_layer != 6 : continue\n",
    "        \n",
    "        # add the initialized model\n",
    "        set_seed(np.random.randint(0,200))\n",
    "        for init_scheme in [\n",
    "                            'default',\n",
    "                            # # \"('normal',0,0.002)\", \n",
    "                            # \"('normal',0,0.02)\",\n",
    "                            # # \"('normal',0,0.2)\",\n",
    "                            # # \"('normal',0,2)\", \n",
    "                            # # \"('normal',4,0.02)\",\n",
    "                            # # \"('normal',8,0.02)\",\n",
    "                            # # \"('normal',100,0.02)\",                        \n",
    "                            # '(\"uniform\",-0.02,0.02)', \n",
    "                            # '(\"uniform\",-0.001,0.001)', \n",
    "\n",
    "                            # '(\"uniform\",-1,1)', \n",
    "                            # '(\"uniform\",-10,10)', \n",
    "\n",
    "                            # '(xavier,1)'\n",
    "                            ]:\n",
    "        # for init_scheme in ['default']:\n",
    "\n",
    "            ckpt = all_ckpts[0]\n",
    "            with io.capture_output() as captured:\n",
    "                model, gptconfig = load_checkpoint(\n",
    "                    ckpt,\n",
    "                    GPTConfig_nope,\n",
    "                    GPT_nope,\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                    return_config=True,\n",
    "                    init=True,\n",
    "                    init_additional_config={\n",
    "                        'init_scheme': init_scheme,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            model_list.append(model)\n",
    "            try:\n",
    "                iter_num = int(ckpt.split('_')[-1].split('.')[0])\n",
    "                convergence = 0\n",
    "                cur_model_name = 'acc='+str(int(convergence))+ '_' \\\n",
    "                    + '/'.join(ckpt.split('/')[3:]).replace(str(iter_num), '0') \\\n",
    "                    + f'_nembd={gptconfig.n_embd}_nlayers={gptconfig.n_layer}' + f'_{init_scheme}'\n",
    "            except:\n",
    "                cur_model_name = 'acc=0'+ '_' \\\n",
    "                    + '/'.join(ckpt.split('/')[3:]) \\\n",
    "                    + f'_nembd={gptconfig.n_embd}_nlayers={gptconfig.n_layer}' + f'_Init_{init_scheme}'\n",
    "            useful_name_list.append(cur_model_name)\n",
    "            \n",
    "        # for ckpt in all_ckpts[len(all_ckpts)//2:len(all_ckpts)//2+1] + all_ckpts[-1:]:\n",
    "\n",
    "        '''get trained model results'''\n",
    "        # for ckpt in all_ckpts[-1:]:\n",
    "\n",
    "        for ckpt in all_ckpts:\n",
    "\n",
    "            with io.capture_output() as captured:\n",
    "                # model = load_checkpoint(ckpt, GPTConfig_nope, GPT_nope, device='cuda')\n",
    "                # model, gptconfig = load_checkpoint(ckpt, GPTConfig_nope, GPT_nope, device='cuda', return_config=True)\n",
    "                model, gptconfig = load_checkpoint(\n",
    "                    ckpt,\n",
    "                    GPTConfig_nope,\n",
    "                    GPT_nope,\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                    return_config=True,\n",
    "                    init=model_init,\n",
    "                    init_additional_config=init_additional_config,\n",
    "                )\n",
    "                if small_dim:\n",
    "                    gptconfig.n_head = 1\n",
    "                    # gptconfig.not_causal = True\n",
    "                    gptconfig.n_embd = 16\n",
    "                    model = GPT_nope(gptconfig)\n",
    "                                \n",
    "                model.eval()\n",
    "                model.to(device)\n",
    "                model_list.append(model)\n",
    "                try:\n",
    "                    iter_num = int(ckpt.split('_')[-1].split('.')[0])\n",
    "                    convergence = df.loc[df['iter']==iter_num, 'test_acc'].values[0]\n",
    "                  \n",
    "                except:\n",
    "                    convergence = df.loc[:, 'test_acc'].values.max()\n",
    "                cur_model_name = 'acc='+str(int(convergence))+ '_' \\\n",
    "                        + '/'.join(ckpt.split('/')[3:]) \\\n",
    "                        + f'_nembd={gptconfig.n_embd}_nlayers={gptconfig.n_layer}' + '_trained'\n",
    "                useful_name_list.append(cur_model_name)\n",
    "\n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"no model {glob_dir}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "n_embd = model_list[0].config.n_embd\n",
    "equation_num = 1\n",
    "causal_training = True # for add3\n",
    "total_tokens = total_samples * 2 * fixed_length * equation_num\n",
    "diviser = 256 if causal_training else fixed_length\n",
    "samples_to_generate = total_tokens//fixed_length + total_tokens%fixed_length\n",
    "fixed_length = equation_num * fixed_length\n",
    "print('causal_training is', causal_training)\n",
    "\n",
    "\n",
    "X = get_batch(\"valid\", batch_size=samples_to_generate)[0]\n",
    "X = \"\\n\".join([decode(X[i].tolist()) for i in range(X.shape[0])])[:total_tokens] # truncate x to lower computation\n",
    "equations = X.split('\\n')\n",
    "X_n = []\n",
    "for eidx in range(0, len(equations), equation_num):\n",
    "    full_eqn = '\\n'.join(equations[eidx:eidx+equation_num])\n",
    "    # print(full_eqn)\n",
    "    if task_type=='add' and not full_eqn.startswith('$'): continue\n",
    "    if len(full_eqn)<fixed_length:\n",
    "        if len(full_eqn) < fixed_length//4: continue\n",
    "        full_eqn = '\\n' * (fixed_length-len(full_eqn))  + full_eqn\n",
    "    full_eqn = full_eqn[:fixed_length]\n",
    "    X_n.append(full_eqn)\n",
    "X_n = X_n[:total_samples]\n",
    "X = torch.tensor(list(map(lambda x: encode(x), X_n)))\n",
    "\n",
    "\n",
    "# X_n = np.array(list(X[:len(X) // fixed_length * fixed_length])).reshape(-1, fixed_length)\n",
    "\n",
    "if rand_perm: # shuffle in input sequence\n",
    "    for xidx in range(X.shape[0]):\n",
    "        X[xidx] = X[xidx, torch.randperm(X[xidx].shape[0])]\n",
    "\n",
    "X = X.to(device)\n",
    "if use_1_sample:\n",
    "    X = X[:1]\n",
    "\n",
    "for level in range(0, 13):\n",
    "    level = level - 1\n",
    "    input_act1_list = [list() for _ in range(len(model_list))]\n",
    "    out_list = [list() for _ in range(len(model_list))]\n",
    "\n",
    "    for midx, model in enumerate(model_list):\n",
    "        if len(model.transformer.h)<=level:\n",
    "            continue\n",
    "\n",
    "        activation = {}\n",
    "\n",
    "        def getActivation(name):\n",
    "            # the hook signature\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "\n",
    "            return hook\n",
    "    \n",
    "\n",
    "        # register forward hooks on the layers of choice\n",
    "        if level >= 0:\n",
    "            # h1 = model.transformer.h[level].register_forward_hook(\n",
    "            #     getActivation(f\"layer_{level}\")\n",
    "            # )\n",
    "            # if hook_location == 'pre_attn':\n",
    "            # h1 = model.transformer.h[level].attn.pre_att_identity.register_forward_hook(\n",
    "            #     getActivation(f\"layer_{level}\")\n",
    "            # )\n",
    "            # elif hook_location == 'post_attn':\n",
    "            h1 = model.transformer.h[level].attn.identity.register_forward_hook(\n",
    "                getActivation(f\"layer_{level}\")\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # if 'nope' in exp_list[midx][0]:\n",
    "            # h1 = model.transformer.drop.register_forward_hook(\n",
    "            #     getActivation(f\"layer_{level}\")\n",
    "            # )\n",
    "            h1 = model.transformer.drop.register_forward_hook(\n",
    "                getActivation(f\"layer_{level}\")\n",
    "            )\n",
    "            # else:\n",
    "            #     h1 = model.transformer.wte.register_forward_hook(\n",
    "            #         getActivation(f\"layer_{level}\")\n",
    "            #     )\n",
    "\n",
    "\n",
    "        h2 = model.transformer.ln_f.register_forward_hook(\n",
    "            getActivation(\"x_out\")\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out0 = model(\n",
    "                X, equal_distancing_exp=equal_distancing_exp, ablation_config=ablation_config,\n",
    "            )[0]\n",
    " \n",
    "        h1.remove()\n",
    "        h2.remove()\n",
    "\n",
    "        acts = activation[f\"layer_{level}\"].detach().cpu().numpy()\n",
    "        \n",
    "        input_act1_list[midx].append(acts)\n",
    "        out_arg = out0.argmax(-1).detach().cpu().numpy()\n",
    "        decoded_out = list(decode(out_arg.flatten()))\n",
    "        \n",
    "        out_list[midx] = decoded_out\n",
    "\n",
    "    for hidx in range(len(input_act1_list)):\n",
    "        if len(input_act1_list[hidx]) == 0:\n",
    "            # input_act1_list[hidx] \n",
    "            pass\n",
    "        else:\n",
    "            cur_input_act1 = np.concatenate(input_act1_list[hidx], axis=0)\n",
    "            bs, l, dim = cur_input_act1.shape\n",
    "            # print(cur_input_act1.shape)\n",
    "            input_act1_list[hidx] = cur_input_act1.reshape(bs, l, dim)\n",
    "            # out_list[hidx] = out_list[hidx]\n",
    "\n",
    "    all_level_input_act_list.append(input_act1_list)\n",
    "    all_out_list.append(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "font_path = './timr45w.ttf'  # Update this path\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams.update({'font.size':10})\n",
    "plt.rcParams['axes.labelsize'] =12  # Axis labels\n",
    "plt.rcParams['xtick.labelsize'] =12  # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] =12  # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] =12  # Legend\n",
    "plt.rcParams['axes.titlesize'] =12  # Ti\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''mean'''\n",
    "\n",
    "# # Data for each set\n",
    "categories = ['Embeddings', 'Layer 1', 'Layer 2', 'Layer 3', 'Layer 4', 'Layer 5', 'Layer 6']\n",
    "mu0_means = [0.39, 0.92, 0.94, 0.95, 0.95, 0.95, 0.95]\n",
    "mu0_stds = [0.10, 0.17, 0.18, 0.17, 0.15, 0.17, 0.17]\n",
    "\n",
    "mu1_means = [0.46, 0.91, 0.95, 0.93, 0.95, 0.95, 0.96]\n",
    "mu1_stds = [0.15, 0.18, 0.10, 0.06, 0.07, 0.08, 0.06]\n",
    "\n",
    "mu2_means = [0.36, 0.91, 0.54, 0.41, 0.46, 0.51, 0.60]\n",
    "mu2_stds = [0.11, 0.18, 0.09, 0.04, 0.06, 0.08, 0.11]\n",
    "\n",
    "# Define the position of the bars on the x-axis\n",
    "x = np.arange(len(categories))\n",
    "width = 0.2  # Width of the bars\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotting the bars with error bars\n",
    "rects1 = ax.bar(x - width, mu0_means, width, label='$\\mu_{init} = 0$', capsize=10, error_kw={'elinewidth': 0.5, 'capsize': 10})\n",
    "rects2 = ax.bar(x, mu1_means, width, label='$\\mu_{init} = 4$', capsize=10, error_kw={'elinewidth': 0.5, 'capsize': 10})\n",
    "rects3 = ax.bar(x + width, mu2_means, width, label='$\\mu_{init} = 8$', capsize=10, error_kw={'elinewidth': 0.5, 'capsize': 10})\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Layer')\n",
    "y_label = 'Mean of Initialization'\n",
    "ax.set_ylabel(y_label)\n",
    "\n",
    "\n",
    "'''std'''\n",
    "# categories = ['Embeddings', 'Layer 1', 'Layer 2', 'Layer 3', 'Layer 4', 'Layer 5', 'Layer 6']\n",
    "# mu0_means = [0.36, 0.93, 0.93, 0.95, 0.94, 0.95, 0.94]\n",
    "# mu0_stds = [0.11, 0.17, 0.19, 0.14, 0.16, 0.16, 0.17]\n",
    "\n",
    "# mu1_means = [0.39, 0.92, 0.94, 0.95, 0.95, 0.95, 0.95]\n",
    "# mu1_stds = [0.10, 0.17, 0.18, 0.17, 0.15, 0.17, 0.17]\n",
    "\n",
    "# mu2_means = [0.35, 0.43, 0.49, 0.54, 0.59, 0.57, 0.65]\n",
    "# mu2_stds = [0.10, 0.09, 0.08, 0.09, 0.12, 0.12, 0.13]\n",
    "\n",
    "# # Define the position of the bars on the x-axis\n",
    "# x = np.arange(len(categories))\n",
    "# width = 0.2  # Width of the bars\n",
    "\n",
    "# # Create the figure and axes\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# # Plotting the bars with error bars\n",
    "# rects1 = ax.bar(x - width, mu0_means, width, yerr=mu0_stds, label='$\\sigma_{init} = 0.002$', capsize=5, error_kw={'elinewidth': 1, 'capsize': 5})\n",
    "# rects2 = ax.bar(x, mu1_means, width, yerr=mu1_stds, label='$\\sigma_{init} = 0.02$', capsize=5, error_kw={'elinewidth': 1, 'capsize': 5})\n",
    "# rects3 = ax.bar(x + width, mu2_means, width, yerr=mu2_stds, label='$\\sigma_{init} = 0.2$', capsize=5, error_kw={'elinewidth': 1, 'capsize': 5})\n",
    "\n",
    "# # Add labels, title, and legend\n",
    "# ax.set_xlabel('Layer')\n",
    "# y_label = 'Standard Deviation'\n",
    "# ax.set_ylabel(y_label)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Function to add labels on bars\n",
    "def add_labels(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Add labels for each set of bars\n",
    "add_labels(rects1)\n",
    "add_labels(rects2)\n",
    "add_labels(rects3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(f'TEMP_{y_label}.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using function cosine_similarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021051f70ec24de79685906ed389db54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='sample_idx', max=255), IntSlider(value=0, description='l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_corr(sample_idx=0, level=0, standard=6, drop_down=[], drop_down2=None, drop_down3=None, plot_type=['dot', 'corr'], all_models=False, individual_sample=True, before_after=['training', False, 'attention'], save=False, abs=False, save_all=False, accumulate_all=False, subplot_layers=True)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from re import T\n",
    "import gc\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "font_path = './timr45w.ttf'  # Update this path\n",
    "from matplotlib import font_manager\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams.update({'font.size':32})\n",
    "plt.rcParams['axes.labelsize'] =32  # Axis labels\n",
    "plt.rcParams['xtick.labelsize'] =32  # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] =32  # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] =32  # Legend\n",
    "plt.rcParams['axes.titlesize'] =32  # Title\n",
    "\n",
    "\n",
    "sim_func = cosine_similarity\n",
    "# sim_func = lambda x, y: np.dot(x, y.T)\n",
    "# sim_func = lambda x, y: (x[None, ...] - y[:, None, ...]).sum(axis=-1)\n",
    "show_vals = False\n",
    "print(f\"using function {repr(sim_func).split(' ')[1]}\")\n",
    "\n",
    "def standardize_rows(matrix):\n",
    "    \"\"\"Standardize each row of the matrix.\"\"\"\n",
    "    mean = matrix.mean(axis=1, keepdims=True)\n",
    "    std = matrix.std(axis=1, keepdims=True)\n",
    "    return (matrix - mean) / std\n",
    "\n",
    "level_corr_mat_accum = []\n",
    "corr_mat = None\n",
    "u1, u2, u1_name, u2_name = None, None, None, None\n",
    "\n",
    "task_name = 'add_'\n",
    "folder_name = f'corr_{task_name}' if not equal_distancing_exp else f'dot_{task_name}'\n",
    "folder_name += '_trained' if not model_init else '_init'\n",
    "\n",
    "for k in ablation_config:\n",
    "    if ablation_config[k]:\n",
    "        if k == 'func_config':\n",
    "            folder_name += f'_{ablation_config[k]}'\n",
    "        else: \n",
    "            folder_name += f'_{k}' \n",
    "from vis_utils import get_PE_tendency, generate_tendency_map\n",
    "\n",
    "all_stats = None\n",
    "\n",
    "def get_corr(sample_idx=0, \n",
    "             level=0, \n",
    "             standard=6,\n",
    "             drop_down=[], \n",
    "             drop_down2=None, \n",
    "             drop_down3=None, \n",
    "             plot_type = ['dot', 'corr'],\n",
    "             all_models = False,\n",
    "             individual_sample = True,\n",
    "             before_after = ['training', False,  'attention'],\n",
    "             save=False,  \n",
    "             abs=False, \n",
    "             save_all=False, \n",
    "             accumulate_all=False, \n",
    "             subplot_layers=True):\n",
    "    global corr_mat, input_act1_list\n",
    "    global u1, u2, u1_name, u2_name\n",
    "    global all_stats\n",
    "    rand_state = 'init_' if model_init else ''\n",
    "\n",
    "    idx1 = useful_name_list.index(drop_down)\n",
    "    idx2 = useful_name_list.index(drop_down2) if drop_down2 is not None else None\n",
    "    idx3 = useful_name_list.index(drop_down3) if drop_down3 is not None else None\n",
    "\n",
    "    # model_layers = [l[idx1] for l in all_level_input_act_list if len(l[idx1])!=0]\n",
    "    # level = min(level, len(model_layers)-1)\n",
    "    # print(level, idx1, useful_name_list[idx1])\n",
    "\n",
    "    for l in all_level_input_act_list:\n",
    "        if l == []:\n",
    "            return\n",
    "\n",
    "    # individual_sample = individual_sample if not save_all else False\n",
    "    if individual_sample :\n",
    "        if not equal_distancing_exp:\n",
    "            print(X_n[sample_idx:sample_idx+1])\n",
    "        else:\n",
    "            print('eqx')\n",
    "    save = True if save_all else save\n",
    "    model_range = range(idx1, idx1+1) if not save_all else range(len(useful_name_list))\n",
    "    all_stats = dict()\n",
    "    for idx1 in tqdm(model_range):\n",
    "        eqn_text = X_n[sample_idx] if not equal_distancing_exp else 'eqx'\n",
    "        \n",
    "        models_corr_mat_list = []\n",
    "        models_cm_tend_list = []\n",
    "        \n",
    "        model_name = useful_name_list[idx1]\n",
    "        acc = model_name.split('_')[0]\n",
    "        rest = '_'.join(model_name.split('_')[1:])\n",
    "        try:\n",
    "            iteration = int(re.search(r'acc_(\\d+).pt', model_name).group(1))\n",
    "        except:\n",
    "            if 'Init' in model_name:\n",
    "                iteration = 0\n",
    "            else:\n",
    "                iteration = 5000\n",
    "        imgname = rest.replace('10000_acc_', '').replace('/', '_').replace('.pt', '') + ' ' + eqn_text\n",
    "\n",
    "        cur_model_act_list1 = [l[idx1] for l in all_level_input_act_list if len(l[idx1])!=0]\n",
    "        models_to_plot = [cur_model_act_list1]\n",
    "        \n",
    "        has_model = True\n",
    "        if before_after=='training':\n",
    "            rest = '_'.join(rest.split('.')[0].split('_')[:-1])\n",
    "            if acc.split('=')[-1]!='0' or iteration!=0:\n",
    "                print(acc, iteration)\n",
    "                has_model = False\n",
    "                continue\n",
    "            trained_model_name = None\n",
    "            for m_idx, m_name in enumerate(useful_name_list):\n",
    "                # if rest in m_name and not (m_name==model_name):\n",
    "                if rest in m_name and 'trained' in m_name:\n",
    "                    trained_model_name = m_name\n",
    "                    # trained_cur_model = model_list[m_idx]\n",
    "                    m_idx = useful_name_list.index(m_name)\n",
    "                    cur_model_act_list2 = [l[m_idx] for l in all_level_input_act_list if len(l[m_idx])!=0]\n",
    "                    break\n",
    "            assert trained_model_name is not None, 'no trained model found'\n",
    "            print(all_out_list[0][midx][sample_idx])\n",
    "            models_to_plot.append(cur_model_act_list2)\n",
    "\n",
    "        elif before_after=='attention':\n",
    "            models_to_plot.append(cur_model_act_list1)\n",
    "\n",
    "        if drop_down2 is not None:\n",
    "            cur_model_act_list2 = [l[idx2] for l in all_level_input_act_list if len(l[idx2])!=0]\n",
    "            models_to_plot.append(cur_model_act_list2)\n",
    "        if drop_down3 is not None:\n",
    "            cur_model_act_list3 = [l[idx3] for l in all_level_input_act_list if len(l[idx3])!=0]\n",
    "            models_to_plot.append(cur_model_act_list3)\n",
    "        \n",
    "\n",
    "        for cur_model_act_list in models_to_plot:\n",
    "            corr_mat_list = []\n",
    "            level_cm_tend_list = []\n",
    "            for level in tqdm(range(len(cur_model_act_list))):\n",
    "                input_act1_list = cur_model_act_list[level]\n",
    "                global level_corr_mat_accum\n",
    "\n",
    "                u1, u2 = cur_model_act_list[level], cur_model_act_list[level]\n",
    "                # u1 = u1.T\n",
    "                # u2 = u2.T\n",
    "                if individual_sample:\n",
    "                    u1, u2 = u1[sample_idx:sample_idx+1], u2[sample_idx:sample_idx+1]\n",
    "             \n",
    "                if plot_type=='corr':\n",
    "                    corr_mat = []\n",
    "                    for b1, b2 in zip(u1, u2):\n",
    "                        u1_standardized = standardize_rows(u1)\n",
    "                        u2_standardized = standardize_rows(u2)\n",
    "                        corr_mat.append(np.dot(u1_standardized, u2_standardized.T) / (u1.shape[1]))\n",
    "                elif plot_type=='dot':\n",
    "                    corr_mat = []\n",
    "                    for b1, b2 in zip(u1, u2):\n",
    "                        corr_mat.append(sim_func(b1, b2))\n",
    "                    corr_mat_all = np.array(corr_mat)\n",
    "                    corr_mat = corr_mat_all.mean(axis=0) \n",
    "\n",
    "                if abs:\n",
    "                    corr_mat = np.abs(corr_mat)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "                cm_tend_list = []\n",
    "                for _sidx in range(len(corr_mat_all)):\n",
    "                    cm_tend_list.append(get_PE_tendency(corr_mat_all[_sidx], as_list=True)[standard])\n",
    "                           \n",
    "                if accumulate_all:\n",
    "                    level_corr_mat_accum.append(corr_mat[None, ...])\n",
    "\n",
    "                \n",
    "                corr_mat_list.append(corr_mat)\n",
    "                level_cm_tend_list.append(cm_tend_list)               \n",
    "\n",
    "\n",
    "                if not subplot_layers:\n",
    "                    vec_dim = corr_mat.shape[0]//fixed_length\n",
    "                    total_sum = np.abs(corr_mat).sum()\n",
    "                    block_sum = 0\n",
    "                    for i in range(0, len(corr_mat), vec_dim):\n",
    "                        block_sum += np.abs(corr_mat[i:i+vec_dim, i:i+vec_dim]).sum()\n",
    "                    ratio = block_sum/(total_sum-block_sum)\n",
    "\n",
    "                    plt.figure(figsize=(6, 5), dpi=120)\n",
    "                    plt.imshow(corr_mat, cmap='Reds') #, interpolation='nearest')\n",
    "\n",
    "                    extra_text = 'Absolute ' if abs else ''\n",
    "                    plt.colorbar(label=f'{extra_text}Correlation Coefficient')\n",
    "\n",
    "                    os.makedirs(f'./saved_plots_{folder_name}/', exist_ok=True)\n",
    "                    plt.savefig(f'./saved_plots_{folder_name}/{useful_name_list[idx1]}_avg_{abs}.pdf')\n",
    "                    plt.close()\n",
    "            models_corr_mat_list.append(corr_mat_list)\n",
    "\n",
    "            models_cm_tend_list.append(level_cm_tend_list)\n",
    "        # corr_mat_list = models_corr_mat_list\n",
    "        \n",
    "        if subplot_layers and has_model:\n",
    "            handel=f'{before_after}_{standard}_indi={individual_sample}/'\n",
    "            folder_dir = f'./saved_plots_sim/{handel}'\n",
    "            # if save:\n",
    "            #     if f'{folder_dir}/{imgname}.pdf' in glob.glob(f'{folder_dir}/{imgname}.pdf'):\n",
    "            #         continue\n",
    "            fig, axs = plt.subplots(len(models_corr_mat_list), len(models_corr_mat_list[0]), figsize=(6*len(models_corr_mat_list[0]), 5.6*len(models_corr_mat_list)))  # 6 subplots in a row, adjust size as needed\n",
    "            \n",
    "            for level in range(len(models_corr_mat_list[0])):\n",
    "\n",
    "                for cm_idx, corr_mat_list in enumerate(models_corr_mat_list):\n",
    "                    try:\n",
    "                        corr_mat = corr_mat_list[level]\n",
    "                    except:\n",
    "                        print(corr_mat_list)\n",
    "                        raise ValueError\n",
    "\n",
    "                    # vec_dim = n_embd\n",
    "                    cm_tend = get_PE_tendency(corr_mat, as_list=True)[standard]\n",
    "\n",
    "                    vec_dim = corr_mat.shape[0]//fixed_length\n",
    "\n",
    "                    total_sum = np.abs(corr_mat).sum()\n",
    "                    block_sum = 0\n",
    "                    for i in range(0, len(corr_mat), vec_dim):\n",
    "                        block_sum += np.abs(corr_mat[i:i+vec_dim, i:i+vec_dim]).sum()\n",
    "                    ratio = block_sum/(total_sum-block_sum)\n",
    "\n",
    "                    axloc = axs[level] if len(models_corr_mat_list)==1 else axs[cm_idx, level]\n",
    "\n",
    "                    cm = axloc.imshow(corr_mat, cmap='Reds') #, interpolation='nearest')\n",
    "                    # show the number on each block\n",
    "                    if show_vals:\n",
    "                        for i in range(0, len(corr_mat), vec_dim):\n",
    "                            for j in range(0, len(corr_mat), vec_dim):\n",
    "                                text = axloc.text(j, i, f'{corr_mat[i:i+vec_dim, j:j+vec_dim].sum():.02f}',\n",
    "                                                    ha=\"center\", va=\"center\", color=\"black\", fontsize=6)\n",
    "\n",
    "                    training_status = ''\n",
    "                    if before_after=='training':\n",
    "                        training_status = 'Trained ' if cm_idx==1 else 'Init '\n",
    "                    title_text = f'{training_status}Layer {level} ({cm_tend})' if level > 0 \\\n",
    "                        else f'Embeddings ({cm_tend})'                  \n",
    "                    axloc.set_title(title_text)\n",
    "                    cbar = plt.colorbar(cm, ax=axloc, orientation='vertical', fraction=0.05, )\n",
    "                    # Get the scalar formatter from the colorbar\n",
    "                    from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n",
    "                    formatter = FormatStrFormatter('%.1f')\n",
    "                    axloc.yaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "                    axloc.yaxis.set_major_locator(MaxNLocator(nbins=5))\n",
    "\n",
    "                    axloc.xaxis.set_major_locator(MaxNLocator(nbins=5))\n",
    "\n",
    "                    # Set the desired format (e.g., rounding to 2 decimal places)\n",
    "                    # formatter.set_useOffset(False)  # Disable offset if necessary\n",
    "\n",
    "                    # Apply the formatter to the colorbar\n",
    "                    cbar.formatter = formatter\n",
    "                    cbar.update_ticks()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            fig.subplots_adjust(left=0.03, right=0.975, top=0.95, bottom=0.06, hspace=0.25)\n",
    "            if save:\n",
    "                os.makedirs(f'{folder_dir}', exist_ok=True)\n",
    "\n",
    "                plt.savefig(f'{folder_dir}/{imgname} sample.pdf', format='pdf')\n",
    "                plt.close()\n",
    "                gc.collect()\n",
    "            else:\n",
    "                plt.show()\n",
    "            \n",
    "            '''Plotting the Distribution'''\n",
    "            \n",
    "            fig, axs = plt.subplots(len(models_corr_mat_list), len(models_corr_mat_list[0]), figsize=(6*len(models_corr_mat_list[0]), 5.6*len(models_corr_mat_list)))  # 6 subplots in a row, adjust size as needed\n",
    "            levels_stats = []\n",
    "            for level in range(len(models_corr_mat_list[0])):\n",
    "                for cm_idx, level_cm_tend_list in enumerate(models_cm_tend_list):\n",
    "                    axloc = axs[level] if len(models_corr_mat_list)==1 else axs[cm_idx, level]\n",
    "                    axloc.hist(level_cm_tend_list[level], bins=32)\n",
    "                    training_status = ''\n",
    "                    if before_after=='training':\n",
    "                        training_status = 'Trained ' if cm_idx==1 else 'Init '\n",
    "                    mean_tend = round(np.mean(level_cm_tend_list[level]), 2)\n",
    "                    std_tend = round(np.std(level_cm_tend_list[level]), 2)\n",
    "                    levels_stats.append(mean_tend)\n",
    "                    title_text = f'{training_status}Layer {level} ({mean_tend}, {std_tend})' if level > 0 \\\n",
    "                        else f'Embeddings ({mean_tend}, {std_tend})'                \n",
    "                    axloc.set_title(title_text)                    \n",
    "                    axloc.set_xlim(-1.05, 1.05)\n",
    "\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            fig.subplots_adjust(left=0.03, right=0.975, top=0.95, bottom=0.06, hspace=0.25)\n",
    "            dist_name = f'{folder_dir}/{imgname} dist.pdf'\n",
    "            if save:\n",
    "                os.makedirs(f'{folder_dir}', exist_ok=True)\n",
    "                plt.savefig(dist_name, format='pdf')\n",
    "                plt.close()\n",
    "                gc.collect()\n",
    "            else:\n",
    "                plt.show()\n",
    "            \n",
    "            all_stats[dist_name]=levels_stats\n",
    "\n",
    "        # if idx1 >=10:\n",
    "        #     raise ValueError\n",
    "        if accumulate_all:\n",
    "            level_corr_mat_accum = np.vstack(level_corr_mat_accum)\n",
    "            print(level_corr_mat_accum.shape)\n",
    "            level_corr_mat_accum = level_corr_mat_accum.mean(axis=0)\n",
    "            # Create a heatmap of corr_mat\n",
    "            if not subplot_layers:\n",
    "                plt.figure(figsize=(6, 5), dpi=120)\n",
    "                # plt.imshow(corr_mat, cmap='seismic') #, interpolation='nearest')\n",
    "                plt.imshow(level_corr_mat_accum, cmap='Reds') #, interpolation='nearest')\n",
    "\n",
    "                extra_text = 'Absolute ' if abs else ''\n",
    "                plt.colorbar(label=f'{extra_text}Correlation Coefficient')\n",
    "                plt.show()\n",
    "            corr_mat  =  level_corr_mat_accum\n",
    "            level_corr_mat_accum = []\n",
    "        \n",
    "           \n",
    "\n",
    "\n",
    "# all_drop_down = [e[1] for e in useful_name_list]\n",
    "\n",
    "widgets.interact(get_corr, \n",
    "                 sample_idx=(0, len(X_n)-1), \n",
    "                 drop_down=useful_name_list, \n",
    "                 drop_down2=[None] + useful_name_list, \n",
    "                 drop_down3=[None] + useful_name_list, \n",
    "                 level=(0,12),\n",
    "                 standard=(0,6))\n",
    "\n",
    "\n",
    "# idxes = [\n",
    "# # [0,0], [0,1], [0,2], [0,3], [0,4],\n",
    "# # [1,1], [2,2], [3,3], [4,4],\n",
    "# # [4,1], [4,2], [4,3], \n",
    "# [1,2], [1,3],c\n",
    "# ]\n",
    "# from tqdm.auto import tqdm\n",
    "# for idx1, idx2 in tqdm(idxes):\n",
    "#     get_corr(idx1, idx2, save=True)\n",
    "    \n",
    "# all residual vs picking ones that are illustrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"./saved_plots_sim/False_6_indi=False//rev16_nope_sd242_T2408100054_nope_ckpt_10000_acc_nembd=384_nlayers=6_Init_('normal',0,0.002) rev(7576288188778391)= dist.pdf\": [0.36,\n",
       "  0.39,\n",
       "  0.35,\n",
       "  0.93,\n",
       "  0.92,\n",
       "  0.43,\n",
       "  0.93,\n",
       "  0.94,\n",
       "  0.49,\n",
       "  0.95,\n",
       "  0.95,\n",
       "  0.54,\n",
       "  0.94,\n",
       "  0.95,\n",
       "  0.59,\n",
       "  0.95,\n",
       "  0.95,\n",
       "  0.57,\n",
       "  0.94,\n",
       "  0.95,\n",
       "  0.65]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the difference in projection for the same vector\n",
    "# # x = torch.rand(1, 1, 384).to(device)\n",
    "# font_path = './timr45w.ttf'  # Update this path\n",
    "# from matplotlib import font_manager\n",
    "# # Add the font to Matplotlib's font manager\n",
    "# font_manager.fontManager.addfont(font_path)\n",
    "# prop = font_manager.FontProperties(fname=font_path)\n",
    "# plt.rcParams['font.family'] = prop.get_name()\n",
    "# plt.rcParams['font.family'] = prop.get_name()\n",
    "# plt.rcParams.update({'font.size': 14})\n",
    "# plt.rcParams['axes.labelsize'] = 14  # Axis labels\n",
    "# plt.rcParams['xtick.labelsize'] = 14  # X-axis tick labels\n",
    "# plt.rcParams['ytick.labelsize'] = 14  # Y-axis tick labels\n",
    "# plt.rcParams['legend.fontsize'] = 14  # Legend\n",
    "# plt.rcParams['axes.titlesize'] = 14  # Title\n",
    "\n",
    "# n_embd = 384\n",
    "# x = torch.zeros(1, 1, n_embd).to(device)\n",
    "# sc = torch.rand(1, 1, n_embd).to(device)\n",
    "\n",
    "# idx = np.random.randint(0, n_embd)\n",
    "\n",
    "# x[0, 0, idx] = 1\n",
    "# x += sc\n",
    "# # y = model_list[17].transformer.h[1].attn.c_attn(x)\n",
    "# # input_idx = torch.tensor(encode('12modp(123)=')).to(device)[None,...]\n",
    "# # input_idx = torch.tensor(encode('$123+456=')).to(device)[None,...]\n",
    "# input_idx = torch.tensor(encode('$123+456=')).to(device)[None,...]\n",
    "\n",
    "\n",
    "# # eqx = torch.tensor(model.create_equal_distancing_vecotrs(8, n_embd, small_component=0.1)[0]).to(device).to(torch.float32)[None,...] * 0.1\n",
    "\n",
    "# eqx = torch.tensor(model.create_equal_distancing_vecotrs(9, n_embd, small_component=0.0)[0]).to(device).to(torch.float32)[None,...] * 0.1\n",
    "\n",
    "# # Specify the path to your Times New Roman font file\n",
    "# font_path = './timr45w.ttf'  # Update this path\n",
    "# from matplotlib import font_manager\n",
    "# # Add the font to Matplotlib's font manager\n",
    "# font_manager.fontManager.addfont(font_path)\n",
    "# prop = font_manager.FontProperties(fname=font_path)\n",
    "# plt.rcParams['font.family'] = prop.get_name()\n",
    "\n",
    "\n",
    "# def plot_att(model_name, layer_idx=0, plot_all=False, save_map=False):\n",
    "\n",
    "#     acc = model_name.split('_')[0]\n",
    "#     rest = '_'.join(model_name.split('_')[1:])\n",
    "#     imgname = rest.replace('10000_acc_', '').replace('/', '_').replace('.pt', '') + '_' + acc\n",
    "\n",
    "#     # cur_model = model_list[12]\n",
    "#     # cur_model = model_list[2]\n",
    "#     model_idx = useful_name_list.index(model_name)\n",
    "#     cur_model = model_list[model_idx]\n",
    "    \n",
    "#     layer_range = range(layer_idx, layer_idx+1) if not plot_all else range(len(cur_model.transformer.h))\n",
    "    \n",
    "\n",
    "#     for level in layer_range:\n",
    "#         activation = {}\n",
    "\n",
    "#         def getActivation(name):\n",
    "#             # the hook signature\n",
    "#             def hook(model, input, output):\n",
    "#                 activation[name] = output.detach()\n",
    "\n",
    "#             return hook\n",
    "\n",
    "#         h1 = cur_model.transformer.h[level].attn.c_attn.register_forward_hook(\n",
    "#             getActivation(f\"layer_{level}\")\n",
    "#         )\n",
    "        \n",
    "\n",
    "#         h2 = cur_model.transformer.h[level].attn.identity.register_forward_hook(\n",
    "#             getActivation(f\"layer_{level}_iden\")\n",
    "#         )\n",
    "\n",
    "#         with torch.no_grad():\n",
    "\n",
    "\n",
    "#             out = cur_model(input_idx)\n",
    "#             # decode and print out\n",
    "#             y = decode([out[0].detach().cpu().numpy().argmax()])\n",
    "#             print(y)\n",
    "#             _ = cur_model(eqx, direct_input_modification=True)\n",
    "#             # _ = cur_model(x, direct_input_modification=True)\n",
    "\n",
    "\n",
    "#         h1.remove()\n",
    "#         h2.remove()\n",
    "#         y = activation[f\"layer_{level}\"]\n",
    "\n",
    "#         q, k, v  = y.split(n_embd, dim=2)\n",
    "#         plt.figure(figsize=(12, 3))\n",
    "#         plt.plot(q.detach().cpu().numpy().flatten())\n",
    "#         plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "#         plt.show()\n",
    "\n",
    "#         fig, ax = plt.subplots(1, cur_model.config.n_head, figsize=(14, 2))\n",
    "#         q_reshape = q.reshape(1, -1, cur_model.config.n_head, n_embd//cur_model.config.n_head)\n",
    "#         k_reshape = k.reshape(1, -1, cur_model.config.n_head, n_embd//cur_model.config.n_head)\n",
    "#         for i in range(cur_model.config.n_head):\n",
    "#             calc = (torch.nn.Softmax(dim=-1)(q_reshape[0, :, i, :]@k_reshape[0, :, i, :].transpose(0,1)))\n",
    "#             calc = torch.ones_like(calc) * calc.mean()\n",
    "#             result = calc.detach().cpu().numpy()\n",
    "\n",
    "#             mat = ax[i].imshow(result, cmap='Reds', interpolation='nearest')\n",
    "#             ax[i].set_title(f'head {i}')\n",
    "#             plt.colorbar(mat, ax=ax[i], orientation='vertical', fraction=0.06, pad=0.04,)\n",
    "#         plt.show()\n",
    "            \n",
    "\n",
    "#         fig, ax = plt.subplots(1, 2, figsize=(5, 2))\n",
    "#         plt.imshow((torch.nn.Softmax(dim=-1)(q@k.transpose(1, 2))).detach().cpu().numpy()[0], cmap='Reds', interpolation='nearest')\n",
    "        \n",
    "#         calc = torch.nn.Softmax(dim=-1)(q@k.transpose(1, 2))\n",
    "#         calc = torch.ones_like(calc) * calc.mean()\n",
    "#         result = calc.detach().cpu().numpy()\n",
    "#         mat = ax[0].imshow(result[0], cmap='Reds', interpolation='nearest')\n",
    "\n",
    "#         plt.colorbar(mat, ax=ax[0], orientation='vertical', fraction=0.06, pad=0.04,)\n",
    "\n",
    "\n",
    "#         q_ = q.detach().cpu().numpy()[0]\n",
    "#         k_ = k.detach().cpu().numpy()[0]\n",
    "#         mat = cosine_similarity(q_, k_)\n",
    "\n",
    "#         mat = ax[1].imshow(mat, cmap='Reds', interpolation='nearest')\n",
    "#         plt.colorbar(mat, ax=ax[1], orientation='vertical', fraction=0.06, pad=0.04,)\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "#         print(x.sum(), q.abs().sum(), k.abs().sum(), v.abs().sum())\n",
    "\n",
    "#         y = activation[f\"layer_{level}_iden\"].detach().cpu().numpy()\n",
    "#         plt.figure(figsize=(12, 3))\n",
    "#         plt.plot(y.flatten())\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(6, 5))\n",
    "#         mat = cosine_similarity(y[0], y[0])\n",
    "#         plt.imshow(mat, cmap='Reds', interpolation='nearest')\n",
    "#         plt.colorbar()\n",
    "                \n",
    "#         # maskout the upper triangle\n",
    "#         calc = torch.nn.Softmax(dim=-1)(q@k.transpose(1, 2))\n",
    "#         calc = torch.ones_like(calc) * calc.mean()\n",
    "#         mask = np.triu(np.ones_like(calc[0].detach().cpu().numpy(), dtype=bool))[None, ...]\n",
    "#         mask = torch.tensor(mask).to(device)\n",
    "\n",
    "#         digit = calc[0, 0, 0].detach().cpu().clone()\n",
    "#         calc[mask] = -np.inf\n",
    "#         calc[0].diagonal().fill_(digit)\n",
    "#         calc = torch.nn.Softmax(dim=-1)(calc)\n",
    "\n",
    "\n",
    "#         fig = plt.figure(figsize=(5.7, 10))\n",
    "#         gs = fig.add_gridspec(2, 1, height_ratios=[1, 1])  # Adjust hspace as needed\n",
    "\n",
    "#         ax1 = fig.add_subplot(gs[0, 0])\n",
    "#         att_map = calc[0].detach().cpu().numpy()\n",
    "#         cm1 = ax1.imshow(att_map, cmap='Reds', interpolation='nearest')\n",
    "\n",
    "#         for i in range(len(att_map)):\n",
    "#             for j in range(len(att_map)):\n",
    "#                 content = f'{att_map[i, j]:.02f}' if att_map[i, j] != 0 else '0'\n",
    "#                 ax1.text(j, i, content, ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
    "#         cbar1 = plt.colorbar(cm1, ax=ax1, orientation='vertical', fraction=0.05, )\n",
    "#         cbar1.ax.tick_params(labelsize=12)\n",
    "#         ax1.set_title('Causal Attention Matrix', fontdict={'fontsize':14})\n",
    "#         ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "#         ax2 = fig.add_subplot(gs[1, 0])\n",
    "#         y = calc.cpu() @ v.cpu()\n",
    "#         y = y.numpy()\n",
    "#         mat = cosine_similarity(y[0], y[0])\n",
    "#         cm2 = ax2.imshow(mat, cmap='Reds', interpolation='nearest')\n",
    "\n",
    "#         for i in range(len(mat)):\n",
    "#             for j in range(len(mat)):\n",
    "#                 ax2.text(j, i, f'{mat[i, j]:.02f}', ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
    "#         cbar2 = plt.colorbar(cm2, ax=ax2, orientation='vertical', fraction=0.05)\n",
    "#         cbar2.ax.tick_params(labelsize=12)\n",
    "#         ax2.set_title('Self-Cosine-Similarity Matrix', fontdict={'fontsize':14})\n",
    "#         ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "#         ax1.annotate('(a)', xy=(0.5, -0.1), xycoords='axes fraction', ha='center', va='center', fontsize=14, fontproperties=prop)\n",
    "#         ax2.annotate('(b)', xy=(0.5, -0.1), xycoords='axes fraction', ha='center', va='center', fontsize=14, fontproperties=prop)\n",
    "\n",
    "#         fig.subplots_adjust(left=0.0, right=0.92, top=0.97, bottom=0.07, hspace=0.2)\n",
    "        \n",
    "#         if save_map:\n",
    "#             os.makedirs(f'./saved_att_plots/', exist_ok=True)\n",
    "#             # fig.savefig(f'./saved_att_plots/{imgname}_layer={layer_idx+1}.svg')\n",
    "#             fig.savefig(f'./saved_att_plots/{imgname}_layer={layer_idx+1}.pdf', format='pdf')\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "#         calc = torch.nn.Softmax(dim=-1)(torch.einsum('bhid,bhjd->bhij', q_reshape, k_reshape))\n",
    "#         calc = torch.ones_like(calc) * calc.mean()\n",
    "#         mask = np.triu(np.ones_like(calc[0].detach().cpu().numpy(), dtype=bool))[None, ...]\n",
    "#         mask = torch.tensor(mask).to(device)\n",
    "\n",
    "#         digit = calc[0, 0, 0,0 ].detach().cpu().clone()\n",
    "#         print(digit)\n",
    "#         calc[mask] = -np.inf \n",
    "#         # for i in range(calc.shape)\n",
    "#         #     calc[0, 0].diagonal().fill_(digit)\n",
    "#         T = calc.shape[-1]\n",
    "#         calc[:,:,np.arange(T),np.arange(T)] = digit\n",
    "#         calc = torch.nn.Softmax(dim=-1)(calc)\n",
    "\n",
    "#         plt.figure(figsize=(6, 5))\n",
    "#         plt.imshow(calc[0,0].detach().cpu().numpy(), cmap='Reds', interpolation='nearest')\n",
    "#         plt.colorbar()\n",
    "#         plt.show()\n",
    "\n",
    "#         # raise ValueError\n",
    "# widgets.interact(plot_att, model_name=useful_name_list, layer_idx=(0, 5), plot_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find most responsible neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb07921cbd1945458f6a0e1cda6fc59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('acc=0_modclean_nope_sd240_T2408060145_nope/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_att(model_name, layer_idx=0, plot_all=0, save_map=False, find_best=True, search_all_heads=False, metric_id=4, bestk=4, clean_plot=True, input_name=['eqx', 'randx', 'sample_1', 'sample_2', 'sample_3'], amp_head=2)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # the difference in projection for the same vector\n",
    "# # x = torch.rand(1, 1, 384).to(device)\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import font_manager\n",
    "# from ast import literal_eval\n",
    "# import ipywidgets as widgets\n",
    "\n",
    "# font_path = './timr45w.ttf'  # Update this path\n",
    "# from matplotlib import font_manager\n",
    "# # Add the font to Matplotlib's font manager\n",
    "# font_manager.fontManager.addfont(font_path)\n",
    "# prop = font_manager.FontProperties(fname=font_path)\n",
    "# plt.rcParams['font.family'] = prop.get_name()\n",
    "# plt.rcParams['font.family'] = prop.get_name()\n",
    "# plt.rcParams.update({'font.size': 12})\n",
    "# plt.rcParams['axes.labelsize'] = 12  # Axis labels\n",
    "# plt.rcParams['xtick.labelsize'] = 12  # X-axis tick labels\n",
    "# plt.rcParams['ytick.labelsize'] = 12  # Y-axis tick labels\n",
    "# plt.rcParams['legend.fontsize'] = 12  # Legend\n",
    "# plt.rcParams['axes.titlesize'] = 12  # Title\n",
    "\n",
    "# n_embd = 384\n",
    "# sz = 12\n",
    "# x = torch.zeros(1, sz, n_embd).to(device)\n",
    "# sc = torch.rand(1, sz, n_embd).to(device)\n",
    "\n",
    "# # idx = np.random.randint(0, n_embd)\n",
    "# idx = np.random.randint(0, n_embd, size=(sz))\n",
    "\n",
    "# x[0, :, idx] = 1\n",
    "# x += sc\n",
    "# # y = model_list[17].transformer.h[1].attn.c_attn(x)\n",
    "# # input_idx = torch.tensor(encode('12modp(123)=')).to(device)[None,...]\n",
    "# # input_idx = torch.tensor(encode('$123+45=')).to(device)[None,...]\n",
    "# input_idx = torch.tensor(encode('$333+444=777$\\n$123+54=')).to(device)[None,...]\n",
    "# input_idx2 = torch.tensor(encode('$123+54=')).to(device)[None,...]\n",
    "# input_idx3 = torch.tensor(encode('$992+299=')).to(device)[None,...]\n",
    "\n",
    "# eqx = torch.tensor(model.create_equal_distancing_vecotrs(sz, n_embd, small_component=0.01)[0]).to(device).to(torch.float32)[None,...] * 0.1\n",
    "\n",
    "# inputs_dict = {\n",
    "#     'sample_1': input_idx,\n",
    "#     'sample_2': input_idx2,\n",
    "#     'sample_3': input_idx3,\n",
    "#     'eqx': eqx,\n",
    "#     'randx': x,\n",
    "# } \n",
    "\n",
    "# # Specify the path to your Times New Roman font file\n",
    "# font_path = './timr45w.ttf'  # Update this path\n",
    "# # Add the font to Matplotlib's font manager\n",
    "# font_manager.fontManager.addfont(font_path)\n",
    "# prop = font_manager.FontProperties(fname=font_path)\n",
    "# plt.rcParams['font.family'] = prop.get_name()\n",
    "\n",
    "# from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# def levenshteinDistance(s1, s2):\n",
    "#     if len(s1) > len(s2):\n",
    "#         s1, s2 = s2, s1\n",
    "\n",
    "#     distances = range(len(s1) + 1)\n",
    "#     for i2, c2 in enumerate(s2):\n",
    "#         distances_ = [i2+1]\n",
    "#         for i1, c1 in enumerate(s1):\n",
    "#             if c1 == c2:\n",
    "#                 distances_.append(distances[i1])\n",
    "#             else:\n",
    "#                 distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "#         distances = distances_\n",
    "#     return distances[-1]\n",
    "\n",
    "# def get_PE_tendency(mat):\n",
    "#     r = 0\n",
    "#     r2 = 0\n",
    "#     r3 = 0\n",
    "#     r4 = 0\n",
    "#     r5 = 0\n",
    "#     r5_counts = 0\n",
    "#     r6 = 0\n",
    "#     r6_count = 0\n",
    "#     mat = mat.detach().cpu().numpy() if isinstance(mat, torch.Tensor) else mat\n",
    "#     for lidx, layer in enumerate(mat[1:]):\n",
    "#         r += (np.diff(layer[:lidx+1], axis=0) > 0).sum()\n",
    "#         r3 += (np.diff(layer[:lidx+1], axis=0) > 0).sum()\n",
    "#         r3 -= (np.diff(layer[:lidx+1], axis=0) <= 0).sum()\n",
    "\n",
    "#         c2p = sum([((layer[j+1:lidx+1]-layer[j]) > 0).sum() for j in range(lidx+1)])\n",
    "#         c2m = sum([((layer[j+1:lidx+1]-layer[j]) <= 0).sum() for j in range(lidx+1)])\n",
    "#         r2 += c2p\n",
    "#         r4 += c2p - c2m\n",
    "\n",
    "#         valid_layer = layer[:lidx+1]\n",
    "#         if len(valid_layer)<3: \n",
    "#             continue\n",
    "\n",
    "#         # cur_order = valid_layer\n",
    "#         # original_order = valid_layer[np.argsort(valid_layer)]\n",
    "#         # corr = spearmanr(original_order, cur_order).correlation\n",
    "#         # if np.isnan(corr):\n",
    "#             # continue\n",
    "#         # r5 += spearmanr(original_order, cur_order).correlation \n",
    "\n",
    "\n",
    "#         right_order = np.argsort(valid_layer-np.arange(len(valid_layer))*1e-5)\n",
    "#         right_right_order = np.argsort(right_order)\n",
    "#         original_order = np.arange(len(valid_layer))\n",
    "#         edit_distance = levenshteinDistance(right_order, original_order)\n",
    "#         r5 += edit_distance\n",
    "#         r5_counts += len(valid_layer)\n",
    "#         r_value = pearsonr(original_order, right_right_order)[0]\n",
    "#         if np.isnan(r_value): continue\n",
    "#         r6 += pearsonr(original_order, right_right_order)[0]\n",
    "#         r6_count += 1\n",
    "#         # r5 += pearsonr(original_order, cur_order)[0]\n",
    "\n",
    "#     max_r = np.arange(mat.shape[0]-1).sum()\n",
    "#     t1 = round(r/max_r, 2)\n",
    "\n",
    "#     max_r2 = sum([ np.arange(n+1).sum() for n in np.arange(mat.shape[0]-1)])\n",
    "#     t2 = round(r2/max_r2, 2)\n",
    "\n",
    "#     t3 = round(r3/max_r, 2)\n",
    "\n",
    "#     t4 = round(r4/max_r2, 2)\n",
    "    \n",
    "#     t5 =  round((r5_counts-r5) / r5_counts, 2)\n",
    "\n",
    "#     t6 = round(r6/r6_count, 2)\n",
    "#     return f'({t1},{t2},{t3},{t4},{t5},{t6})'\n",
    "\n",
    "\n",
    "# def generate_tendency_map(mat):\n",
    "#     mat = mat.detach().cpu().numpy() if isinstance(mat, torch.Tensor) else mat\n",
    "#     empty_mat = np.zeros_like(mat)\n",
    "#     for lidx, layer in enumerate(mat):\n",
    "#         if lidx == 0:\n",
    "#             continue\n",
    "#         counter = 0\n",
    "#         for j in range(1, lidx+1):\n",
    "#             if layer[j]<=layer[j-1]: # weird but worked ...\n",
    "#                 counter = 0\n",
    "#             else:\n",
    "#                 counter += 1\n",
    "#             empty_mat[lidx, j] = counter\n",
    "    \n",
    "#     return empty_mat\n",
    "\n",
    "# def generate_tendency_map(mat):\n",
    "#     mat = mat.detach().cpu().numpy() if isinstance(mat, torch.Tensor) else mat\n",
    "#     empty_mat = np.zeros_like(mat)\n",
    "#     for lidx, layer in enumerate(mat):\n",
    "      \n",
    "#         counter = 0\n",
    "#         for j in range(0, lidx+1):\n",
    "#             if layer[j]<=layer[j-1]: # weird but worked ...\n",
    "#                 counter = 0\n",
    "#             else:\n",
    "#                 counter += 1\n",
    "#             empty_mat[lidx, j] = counter\n",
    "#             # empty_mat[lidx, j] = np.log(mat[lidx, j])\n",
    "    \n",
    "#     return empty_mat\n",
    "\n",
    "    \n",
    "\n",
    "# def plot_att(model_name, \n",
    "#              layer_idx=0, \n",
    "#              plot_all=0, \n",
    "#              save_map=False, \n",
    "#              find_best=True, \n",
    "#              search_all_heads=False,\n",
    "#              metric_id = 4,\n",
    "#              bestk = 4,\n",
    "#              clean_plot = True,\n",
    "#              input_name = sorted(list(inputs_dict.keys())), \n",
    "#              amp_head=2,):\n",
    "\n",
    "#     acc = model_name.split('_')[0]\n",
    "#     rest = '_'.join(model_name.split('_')[1:])\n",
    "#     imgname = rest.replace('10000_acc_', '').replace('/', '_').replace('.pt', '') + '_' + acc\n",
    "\n",
    "#     # cur_model = model_list[12]\n",
    "#     # cur_model = model_list[2]\n",
    "#     model_idx = useful_name_list.index(model_name)\n",
    "#     cur_model = model_list[model_idx]\n",
    "    \n",
    "#     layer_range = range(layer_idx, layer_idx+1) if plot_all==0 else range(plot_all)\n",
    "    \n",
    "#     if len(layer_range) > len(cur_model.transformer.h):\n",
    "#         layer_range = range(len(cur_model.transformer.h))\n",
    "\n",
    "#     for level in layer_range:\n",
    "#         activation = {}\n",
    "\n",
    "#         def getActivation(name):\n",
    "#             # the hook signature\n",
    "#             def hook(model, input, output):\n",
    "#                 activation[name] = output.detach()\n",
    "\n",
    "#             return hook\n",
    "\n",
    "#         h1 = cur_model.transformer.h[level].attn.c_attn.register_forward_hook(\n",
    "#             getActivation(f\"layer_{level}\")\n",
    "#         )\n",
    "        \n",
    "#         h1q = cur_model.transformer.h[level].attn.iq.register_forward_hook(\n",
    "#             getActivation(f\"q{level}\")\n",
    "#         ) \n",
    "#         h1k = cur_model.transformer.h[level].attn.ik.register_forward_hook(\n",
    "#             getActivation(f\"k{level}\")\n",
    "#         ) \n",
    "#         h1v = cur_model.transformer.h[level].attn.iv.register_forward_hook(\n",
    "#             getActivation(f\"v{level}\")\n",
    "#         ) \n",
    "\n",
    "#         h2 = cur_model.transformer.h[level].attn.identity.register_forward_hook(\n",
    "#             getActivation(f\"layer_{level}_iden\")\n",
    "#         )\n",
    "\n",
    "#         with torch.no_grad():\n",
    "\n",
    "#             input_values = inputs_dict[input_name]\n",
    "#             if 'sample' in input_name:\n",
    "#                 out = cur_model(input_values)\n",
    "#                 y = decode([out[0].detach().cpu().numpy().argmax()])\n",
    "#                 print(y)\n",
    "#             else: # eqx or randx\n",
    "#                 _ = cur_model(input_values, direct_input_modification=True)\n",
    "      \n",
    "\n",
    "#         h1.remove()\n",
    "#         h1q.remove()\n",
    "#         h1k.remove()\n",
    "#         h1v.remove()\n",
    "#         h2.remove()\n",
    "\n",
    "\n",
    "#         '''Plot the attention maps'''\n",
    "#         xw = activation[f\"layer_{level}\"]\n",
    "#         q, k, v  = xw.split(n_embd, dim=2)\n",
    "#         q_reshape = activation[f\"q{level}\"]\n",
    "#         k_reshape = activation[f\"k{level}\"]\n",
    "#         v_reshape = activation[f\"v{level}\"]\n",
    "\n",
    "#         if not clean_plot:\n",
    "#             # plt.figure(figsize=(12, 3))\n",
    "#             k_numpy = k_reshape.detach().cpu().numpy()\n",
    "#             bs, T, n_head, head_dim = k_numpy.shape\n",
    "#             k_numpy = k_numpy.reshape(bs, T, -1)\n",
    "#             print(k_numpy.shape)\n",
    "\n",
    "#             fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "#             axes[0].plot(k_numpy[:, 0].flatten())\n",
    "#             axes[0].set_title('key 0')\n",
    "#             axes[1].hist(k_numpy[:, 0].flatten(), bins=100)\n",
    "#             axes[1].set_title('key 0 distribution')\n",
    "#             # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "#             # plt.show()\n",
    "\n",
    "#             # fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "#             k_last = k_numpy[:, -1].flatten()\n",
    "#             axes[2].plot(k_last)\n",
    "#             axes[2].set_title(f'key {T}')\n",
    "#             axes[3].hist(k_last, bins=100)\n",
    "#             axes[3].set_title(f'key {T} distribution')\n",
    "#             # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "#             plt.show()\n",
    "\n",
    "#             v_numpy = v_reshape.detach().cpu().numpy()\n",
    "#             bs, T, n_head, head_dim = v_numpy.shape\n",
    "#             v_numpy = v_numpy.reshape(bs, T, -1)\n",
    "\n",
    "#             fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "#             axes[0].plot(v_numpy[:, 0].flatten())\n",
    "#             axes[0].set_title('value 0')\n",
    "#             axes[1].hist(v_numpy[:, 0].flatten(), bins=100)\n",
    "#             axes[1].set_title('value 0 distribution')\n",
    "#             # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "#             # plt.show()\n",
    "\n",
    "#             # fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "#             v_last = v_numpy[:, -1].flatten()\n",
    "#             axes[2].plot(v_last)\n",
    "#             axes[2].set_title(f'value {T}')\n",
    "#             axes[3].hist(v_last, bins=100)\n",
    "#             axes[3].set_title(f'value {T} distribution')\n",
    "#             # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "#             plt.show()\n",
    "\n",
    "#         from itertools import combinations\n",
    "#         head_dim = n_embd//cur_model.config.n_head\n",
    "#         idx_comb = [np.arange(head_dim)] + [[i] for i in range(head_dim)]\n",
    "\n",
    "#         n_arrays = cur_model.config.n_head\n",
    "#         all_records = [[] for _ in range(n_arrays)] \n",
    "#         all_maps = [[] for _ in range(n_arrays)] \n",
    "#         all_idxsets = [[] for _ in range(n_arrays)] \n",
    "#         original_score = []\n",
    "#         head2 = []\n",
    "\n",
    "#         run_search = True\n",
    "#         for cur_idxset in idx_comb:\n",
    "#             if not run_search:\n",
    "#                 break\n",
    "#             if not find_best:\n",
    "#                 run_search = False\n",
    "#                 cur_idxset = range(head_dim)\n",
    "\n",
    "#             if not run_search:\n",
    "#                 fig, ax = plt.subplots(4, cur_model.config.n_head, figsize=(18, 10))\n",
    "\n",
    "#             for hidx in range(cur_model.config.n_head):\n",
    "                \n",
    "\n",
    "#                 attmap = (torch.nn.Softmax(dim=-1)(q_reshape[0, hidx, :, cur_idxset]@k_reshape[0, hidx, :, cur_idxset].transpose(0,1)))\n",
    "#                 mask = np.triu(np.ones_like(attmap.detach().cpu().numpy(), dtype=bool))\n",
    "#                 mask = torch.tensor(mask).to(device)\n",
    "\n",
    "#                 digit = attmap.flatten()[0].detach().cpu().clone()\n",
    "#                 attmap[mask] = -np.inf \n",
    "#                 T = attmap.shape[-1]\n",
    "#                 attmap[np.arange(T), np.arange(T)] = digit\n",
    "\n",
    "#                 attmap_np = attmap.detach().cpu().numpy()\n",
    "#                 attmap_tend = get_PE_tendency(attmap_np)\n",
    "\n",
    " \n",
    "                \n",
    "#                 s_attmap = torch.nn.Softmax(dim=-1)(attmap)\n",
    "#                 # calc = torch.ones_like(calc) * calc.mean()\n",
    "#                 s_attmap_np = s_attmap.detach().cpu().numpy()\n",
    "#                 tendency_map = generate_tendency_map(s_attmap_np)\n",
    "#                 mat_tend = get_PE_tendency(s_attmap_np)\n",
    "\n",
    "#                 y_out = s_attmap.cpu() @ v_reshape[0, hidx, :, cur_idxset].cpu()\n",
    "#                 sim_map = cosine_similarity(y_out, y_out)\n",
    "\n",
    "\n",
    "#                 if hidx == amp_head or (search_all_heads and find_best):\n",
    "#                     if find_best:\n",
    "#                         adj_score = literal_eval(attmap_tend)[metric_id]\n",
    "                                                \n",
    "#                         if len(cur_idxset) == head_dim:\n",
    "#                             original_score.append(adj_score)\n",
    "#                             head2.append(attmap_np)\n",
    "#                         else:\n",
    "#                             all_records[hidx].append(adj_score)\n",
    "#                             all_maps[hidx].append(attmap_np)\n",
    "#                             all_idxsets[hidx].append(cur_idxset)\n",
    "#                     else:\n",
    "#                         head2.append(attmap_np) \n",
    "\n",
    "\n",
    "#                 if not run_search: \n",
    "#                     mat = ax[0, hidx].imshow(attmap_np, cmap='Reds', interpolation='nearest')\n",
    "#                     ax[0, hidx].set_title(f'head {hidx}={attmap_tend}')\n",
    "#                     plt.colorbar(mat, ax=ax[0, hidx], orientation='vertical', fraction=0.06, )\n",
    "\n",
    "                    \n",
    "#                     mat = ax[1, hidx].imshow(s_attmap_np, cmap='Reds', interpolation='nearest')\n",
    "#                     ax[1, hidx].set_title(f'head {hidx}={mat_tend}')\n",
    "#                     plt.colorbar(mat, ax=ax[1, hidx], orientation='vertical', fraction=0.06, )\n",
    "\n",
    "#                     mat = ax[2, hidx].imshow(tendency_map, cmap='Reds', interpolation='nearest')\n",
    "#                     ax[2, hidx].set_title(f'head {hidx}={mat_tend}')\n",
    "#                     plt.colorbar(mat, ax=ax[2, hidx], orientation='vertical', fraction=0.06, )\n",
    "\n",
    "#                     mat = ax[3, hidx].imshow(sim_map, cmap='Reds', interpolation='nearest')\n",
    "#                     sim_tend = get_PE_tendency(sim_map)\n",
    "\n",
    "#                     ax[3, hidx].set_title(f'head {hidx}={sim_tend}')\n",
    "#                     plt.colorbar(mat, ax=ax[3, hidx], orientation='vertical', fraction=0.06,)\n",
    "\n",
    "#             if not run_search: \n",
    "#                 plt.subplots_adjust(hspace=.4)\n",
    "#                 fig.suptitle(f'{input_name}_{imgname}_layer={level+1}', fontsize=16, y=0.96)\n",
    "#                 if save_map:\n",
    "#                     os.makedirs(f'./saved_heads_plots/', exist_ok=True)\n",
    "#                     fig.savefig(f'./saved_heads_plots/{input_name}_{imgname}_layer={level+1}.svg')\n",
    "#                 plt.show()\n",
    "\n",
    "#         if find_best:\n",
    "#             fig, ax = plt.subplots(2, len(head2), figsize=(3.5*len(head2), 6))\n",
    "#             for amidx, attnmap_np in enumerate(head2):\n",
    "#                 ax_loc_0 = ax[0, amidx] if len(head2)>1 else ax[0]\n",
    "#                 ax_loc_1 = ax[1, amidx] if len(head2)>1 else ax[1]\n",
    "\n",
    "#                 mat = ax_loc_0.imshow(attnmap_np, cmap='Reds', interpolation='nearest')\n",
    "#                 head2_PE_scores = get_PE_tendency(attnmap_np)\n",
    "#                 ax_loc_0.set_title(f'head {amp_head}={head2_PE_scores}')\n",
    "#                 plt.colorbar(mat, ax=ax_loc_0, orientation='vertical', fraction=0.06, )\n",
    "\n",
    "#                 tendmap_head2 = generate_tendency_map(attnmap_np)\n",
    "#                 mat = ax_loc_1.imshow(tendmap_head2, cmap='Reds', interpolation='nearest')\n",
    "#                 original_score[amidx]\n",
    "#                 ax_loc_1.set_title(f'head {amp_head}={original_score[amidx]}')\n",
    "#                 plt.colorbar(mat, ax=ax_loc_1, orientation='vertical', fraction=0.06, )\n",
    "#             plt.show()\n",
    "            \n",
    "#             fig, ax = plt.subplots(2, len(head2), figsize=(3.5*len(head2), 6))\n",
    "\n",
    "#             for hridx, head_rec in enumerate(all_records):\n",
    "\n",
    "#                 if len(head_rec) == 0: \n",
    "#                     continue\n",
    "\n",
    "#                 topk_records_idx = np.argsort(head_rec)[-bestk:]\n",
    "\n",
    "#                 best_maps = np.array([all_maps[hridx][i] for i in topk_records_idx])\n",
    "#                 best_map = best_maps.mean(axis=0)\n",
    "#                 best_score = np.mean([head_rec[i] for i in topk_records_idx])\n",
    "#                 best_idxcomb = [all_idxsets[hridx][i] for i in topk_records_idx]\n",
    "\n",
    "\n",
    "#                 ax_loc_0 = ax[0, hridx] if len(head2)>1 else ax[0]\n",
    "#                 ax_loc_1 = ax[1, hridx] if len(head2)>1 else ax[1]\n",
    "\n",
    "#                 mat = ax_loc_0.imshow(best_map, cmap='Reds', interpolation='nearest')\n",
    "#                 # best_PE_scores = get_PE_tendency(best_map)\n",
    "#                 ax_loc_0.set_title(f'best avg={best_score:.02f}')\n",
    "#                 plt.colorbar(mat, ax=ax_loc_0, orientation='vertical', fraction=0.06, )\n",
    "\n",
    "#                 tendmap_best = generate_tendency_map(best_map)\n",
    "#                 mat = ax_loc_1.imshow(tendmap_best, cmap='Reds', interpolation='nearest')\n",
    "#                 ax_loc_1.set_title(f'best ={best_idxcomb}')\n",
    "#                 plt.colorbar(mat, ax=ax_loc_1, orientation='vertical', fraction=0.06, )\n",
    "            \n",
    "#             plot_name = f'bestk={bestk}_{input_name}_{imgname}_layer={level+1}'\n",
    "#             fig.suptitle(plot_name, fontsize=16, y=0.96)\n",
    "#             if save_map:\n",
    "#                 os.makedirs(f'./saved_heads_plots/', exist_ok=True)\n",
    "#                 fig.savefig(f'./saved_heads_plots/{plot_name}.svg')\n",
    "#             plt.show()\n",
    "                \n",
    "\n",
    "#         # ================================================================\n",
    "        \n",
    "#         # if not clean_plot:\n",
    "\n",
    "#             # fig, ax = plt.subplots(1, 1, figsize=(20, 12.5))\n",
    "\n",
    "\n",
    "#             # # map_to_show = result[0]\n",
    "#             # map_to_show = head2[0]\n",
    "#             # mat = ax.imshow(map_to_show, cmap='Reds', interpolation='nearest')\n",
    "#             # value_amp = 20\n",
    "#             # for hidx in range(len(map_to_show)):\n",
    "#             #     for j in range(len(map_to_show)):\n",
    "#             #         ax.text(j, hidx, f'{map_to_show[hidx, j]*value_amp:.02f}', ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "#             # plt.colorbar(mat, ax=ax, orientation='vertical', fraction=0.06, pad=0.04,)\n",
    "#             # ax.set_title(f'showing head {amp_head}, values × {value_amp}')\n",
    "\n",
    "\n",
    "#             # # q_ = q.detach().cpu().numpy()[0]\n",
    "#             # # k_ = k.detach().cpu().numpy()[0]\n",
    "#             # # sim_map = cosine_similarity(q_, k_)\n",
    "\n",
    "#             # # mat = ax[1].imshow(sim_map, cmap='Reds', interpolation='nearest')\n",
    "\n",
    "#             # # plt.colorbar(mat, ax=ax[1], orientation='vertical', fraction=0.06, pad=0.04,)\n",
    "#             # # plt.show()\n",
    "\n",
    "\n",
    "#             # # print(x.sum(), q.abs().sum(), k.abs().sum(), v.abs().sum())\n",
    "\n",
    "#             # y = activation[f\"layer_{level}_iden\"].detach().cpu().numpy()\n",
    "#             # plt.figure(figsize=(12, 3))\n",
    "#             # plt.plot(y.flatten())\n",
    "#             # plt.show()\n",
    "\n",
    "#             # plt.figure(figsize=(6, 5))\n",
    "#             # mat = cosine_similarity(y[0], y[0])\n",
    "#             # mat_tend = get_PE_tendency(mat)\n",
    "#             # plt.imshow(mat, cmap='Reds', interpolation='nearest')\n",
    "#             # plt.title(f'tendency={mat_tend}')\n",
    "#             # plt.colorbar()\n",
    "            \n",
    "\n",
    "# widgets.interact(plot_att, \n",
    "#                  model_name=useful_name_list, \n",
    "#                  layer_idx=(0, 11), \n",
    "#                  plot_all=(0, 6), \n",
    "#                  amp_head=(0, 5),\n",
    "#                  metric_id = (0, 5),\n",
    "#                  bestk=(1, 16))\n",
    "# # widgets.interact(plot_att, model_name=useful_name_list, layer_idx=(0, 5), plot_all=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PyPDF2 import PdfMerger \n",
    "# import cairosvg\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# def convert_svg_to_pdf(svg_files, output_pdf):\n",
    "#     temp_pdfs = []\n",
    "\n",
    "#     # Convert each SVG to a temporary PDF\n",
    "#     for svg_file in svg_files:\n",
    "#         pdf_file = f\"{svg_file}.pdf\"\n",
    "#         cairosvg.svg2pdf(url=svg_file, write_to=pdf_file)\n",
    "#         temp_pdfs.append(pdf_file)\n",
    "\n",
    "#     # Merge all temporary PDFs into a single PDF\n",
    "#     merger = PdfMerger ()\n",
    "#     for pdf in temp_pdfs:\n",
    "#         merger.append(pdf)\n",
    "\n",
    "#     # Write out the final merged PDF\n",
    "#     merger.write(output_pdf)\n",
    "#     merger.close()\n",
    "\n",
    "#     # Clean up temporary PDF files\n",
    "#     for pdf in temp_pdfs:\n",
    "#         os.remove(pdf)\n",
    "\n",
    "\n",
    "\n",
    "# # Usage example\n",
    "# root_dir = './saved_heads_plots'\n",
    "# svg_files = sorted(glob.glob(root_dir + '/*.svg'))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# f_dict = {}\n",
    "# for fpath in svg_files:\n",
    "#     fname = fpath.split('/')[-1]\n",
    "#     model_name = '_'.join(fname.split('_')[:-1])\n",
    "#     if model_name not in f_dict:\n",
    "#         f_dict[model_name] = []\n",
    "#     f_dict[model_name].append(fpath)\n",
    "# for model_name in tqdm(f_dict):\n",
    "#     sorted_files = sorted(f_dict[model_name])\n",
    "#     output_pdf = f'{root_dir}_pdf/{model_name}.pdf'\n",
    "#     convert_svg_to_pdf(sorted_files, output_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02918831ff549f685211436aa0c34dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('acc=0_rev16_nope_sd241_T2408091940_nope_n12…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.prob_model(model_name, model2_name=None, save_all_models=False, save=False, layer_idx=0, plot_all=False, rand_perm=True, before_after=[False, 'training', 'attention'], total_samples=512, max_epochs=20, fixed_length=4, input_type=['x', 'x1*x2', 'x1-x2', '[x1, x2]'], data_type=['sample', 'same', 'randx', 'eqx'], scaler=0.1, linear_mode=1, loss_type=['MSE', 'Cross Entropy'], hook_location='after_attn', plot_type=['violin', 'both', 'tsne'])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import pearsonr, linregress\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "import re\n",
    "from thop import profile, clever_format\n",
    "\n",
    "\n",
    "# Specify the path to your Times New Roman font file\n",
    "font_path = './timr45w.ttf'  # Update this path\n",
    "from matplotlib import font_manager\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams.update({'font.size': 27})\n",
    "plt.rcParams['axes.labelsize'] = 27  # Axis labels\n",
    "plt.rcParams['xtick.labelsize'] = 27  # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 27  # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] = 27  # Legend\n",
    "plt.rcParams['axes.titlesize'] = 27  # Title\n",
    "# Define the probe model\n",
    "class PositionalProbe(nn.Module):\n",
    "    def __init__(self, embedding_dim, \n",
    "                 linear_mode=0,\n",
    "                 n_outs=1):\n",
    "        super(PositionalProbe, self).__init__()\n",
    "        # Only a single output unit as it predicts one position at a time\n",
    "        if linear_mode==0:\n",
    "            self.linear = nn.Linear(embedding_dim, n_outs)\n",
    "        elif linear_mode in [1, 2]:\n",
    "            self.linear = nn.Linear(embedding_dim, 64)\n",
    "            self.linear2 = nn.Linear(64, n_outs)\n",
    "        elif linear_mode in [3, 4]:\n",
    "            self.linear = nn.Linear(embedding_dim, 256)\n",
    "            self.linear2 = nn.Linear(256, 64)\n",
    "            self.linear3 = nn.Linear(64, n_outs)\n",
    "        elif linear_mode==5:\n",
    "            self.linear = nn.Linear(embedding_dim, 512)\n",
    "            self.linear2 = nn.Linear(512, 384)\n",
    "            self.linear3 = nn.Linear(384, 128)\n",
    "            self.linear4 = nn.Linear(128, n_outs)\n",
    "    \n",
    "                \n",
    "        self.n_outs = n_outs\n",
    "        self.linear_mode = linear_mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the output to match the target dimension which is [batch_size * seq_len]\n",
    "        if self.linear_mode==0:\n",
    "            x = self.linear(x)\n",
    "        elif self.linear_mode==1:\n",
    "            x = self.linear(x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.linear2(x)\n",
    "        elif self.linear_mode==2:\n",
    "            x = self.linear(x)\n",
    "            x = torch.exp(x)  \n",
    "            x = self.linear2(x)\n",
    "        elif self.linear_mode==3:\n",
    "            x = self.linear(x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.linear2(x)\n",
    "            x = torch.exp(x) # make it so that the coef is meaningful\n",
    "            x = self.linear3(x)\n",
    "\n",
    "        elif self.linear_mode==4:\n",
    "            x = self.linear(x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.linear2(x)\n",
    "            # x = torch.log(x) # make it so that the coef is meaningful\n",
    "            # log_x = torch.where(x > 0, torch.log(x), 0)\n",
    "            x = self.linear3(x)\n",
    "\n",
    "        elif self.linear_mode==5:\n",
    "            x = self.linear(x)\n",
    "            x = torch.selu(x)\n",
    "            x = self.linear2(x)\n",
    "            x = torch.exp(x) # make it so that the coef is meaningful\n",
    "            x = self.linear3(x)\n",
    "            x = torch.selu(x)\n",
    "            x = self.linear4(x)\n",
    "\n",
    "        if self.n_outs!=1:\n",
    "            x = torch.nn.functional.softmax(x, dim=-1)\n",
    "            return x\n",
    "        else:\n",
    "            return x.squeeze(-1)\n",
    "\n",
    "# Register hooks to capture the outputs from the transformer layer\n",
    "def get_activation_hook(activations, name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def set_ticks(num_ticks, min_value=0):\n",
    "    if 20 > num_ticks-min_value > 10:\n",
    "        step = 2\n",
    "    elif 40>num_ticks-min_value > 20:\n",
    "        step = 5\n",
    "    elif num_ticks-min_value > 40:\n",
    "        step = 10\n",
    "    else:\n",
    "        step = 1\n",
    "\n",
    "    if min_value !=0:\n",
    "        min_value = (int(min_value/step))*step\n",
    "\n",
    "    return np.arange(min_value, num_ticks, step)\n",
    "    \n",
    "causal_training=True # set this global variable to true so that get batch will return (bs, 256) \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_tsne_colored_by_position(embeddings, labels, ax=None, training_status='',\n",
    "                                  perplexity=32):\n",
    "    \"\"\"\n",
    "    Takes a numpy array of embeddings of shape (bs, T, d) and plots the TSNE visualization,\n",
    "    with colors representing the position index within each sequence before reshaping and a detailed legend.\n",
    "    If an axis (ax) is provided, the plot will be drawn on it.\n",
    "    \"\"\"\n",
    "    # Reshape the embeddings from (bs, T, d) to (-1, d)\n",
    "    bs, T, d = embeddings.shape\n",
    "    flat_embeddings = embeddings.reshape(-1, d)\n",
    "    flat_embeddings = (flat_embeddings - flat_embeddings.mean(axis=0)) / flat_embeddings.std(axis=0)\n",
    "    labels = labels.reshape(-1)\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, perplexity=perplexity, n_iter=500, n_jobs=-1)\n",
    "    tsne_results = tsne_model.fit_transform(flat_embeddings)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # tsne_results = tsne_results.reshape(bs, T, 2)\n",
    "    # for t in range(T):\n",
    "        # ax.scatter(tsne_results[:, t, 0], tsne_results[:, t, 1], marker='o', s=8, alpha=0.5)\n",
    "    # scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels.astype(int), cmap='tab10', marker='o', s=8, alpha=0.5)\n",
    "    scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels.astype(int), cmap='tab10', marker='o', s=8, alpha=0.5)\n",
    "\n",
    "    ax.set_title(f'{training_status}TSNE Plot')\n",
    "    ax.set_xlabel('Component 1')\n",
    "    ax.set_ylabel('Component 2')\n",
    "\n",
    "    # Create a legend with exact color for each index\n",
    "    legend_elements = []\n",
    "    cmap = plt.cm.viridis\n",
    "    for idx in range(T):\n",
    "        legend_elements.append(\n",
    "            plt.Line2D([0], [0], marker='o', color=cmap(idx / (T - 1)), label=str(idx + 1), markersize=2, linestyle='')\n",
    "        )\n",
    "    \n",
    "    ax.legend(handles=legend_elements, title_fontsize=10, fontsize=10, loc='upper right', framealpha=0.5)\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def prob_model(model_name, \n",
    "    model2_name=None, \n",
    "    save_all_models=False,\n",
    "    save = False,\n",
    "    layer_idx=0, \n",
    "    plot_all=False, \n",
    "    rand_perm = True,\n",
    "    before_after=[False, 'training', 'attention'],\n",
    "    total_samples = 512,\n",
    "    max_epochs = 20,\n",
    "    fixed_length = 4,\n",
    "    input_type = ['x', 'x1*x2', 'x1-x2', '[x1, x2]'],\n",
    "    # data_type = ['sample', 'eqx'],\n",
    "    data_type = ['sample', 'same', 'randx', 'eqx', ],\n",
    "    scaler = 0.1,\n",
    "    linear_mode = 1,\n",
    "    loss_type = ['MSE', 'Cross Entropy'],\n",
    "    hook_location = 'after_attn',\n",
    "    plot_type = [ 'violin', 'both', 'tsne'],\n",
    "    ):\n",
    "\n",
    "\n",
    "    total_tokens = total_samples * fixed_length\n",
    "    samples_to_generate = total_tokens//256 + total_tokens%256\n",
    "\n",
    "    probe_dim = 384\n",
    "    probe = PositionalProbe(embedding_dim=384,\n",
    "                            linear_mode=linear_mode,\n",
    "                            n_outs=1)\n",
    "                \n",
    "    # count n params\n",
    "    n_params = sum(p.numel() for p in probe.parameters() if p.requires_grad)\n",
    "    print('probe n params:', n_params, end=' ')\n",
    "    probe.eval()\n",
    "    with torch.no_grad():\n",
    "        flops, params = profile(probe, inputs=(torch.rand(1,1,probe_dim),), verbose=False)\n",
    "        flops, params = clever_format([flops, params], \"%.3f\")\n",
    "        print(f'FLOPS: {flops}, params: {params}')\n",
    "\n",
    "\n",
    "    if save_all_models:\n",
    "        models_to_show = useful_name_list\n",
    "    else:\n",
    "        models_to_show = [model_name]\n",
    "\n",
    "    \n",
    "    for model_name in tqdm(models_to_show):\n",
    "        \n",
    "        acc = model_name.split('_')[0]\n",
    "        try:\n",
    "            iteration = int(re.search(r'acc_(\\d+).pt', model_name).group(1))\n",
    "        except:\n",
    "            if 'untrained' in model_name:\n",
    "                iteration = 0\n",
    "            else:\n",
    "                iteration = 2000\n",
    "        rest = '_'.join(model_name.split('_')[1:])\n",
    "        \n",
    "        model_idx = useful_name_list.index(model_name)\n",
    "        cur_model = model_list[model_idx]\n",
    "        if model2_name is not None:\n",
    "            model2_idx = useful_name_list.index(model2_name)\n",
    "            cur_model2 = model_list[model2_idx]\n",
    "            \n",
    "        cur_models = [cur_model]\n",
    "\n",
    "        if before_after=='training':\n",
    "            rest = '_'.join(rest.split('.')[0].split('_')[:-1])\n",
    "            if acc.split('=')[-1]!='0' or iteration!=0:\n",
    "                print(acc, iteration)\n",
    "                continue\n",
    "            trained_model_name = None\n",
    "            trained_cur_model = None\n",
    "            for m_idx, m_name in enumerate(useful_name_list):\n",
    "                if rest in m_name and not (m_name==model_name):\n",
    "                    trained_model_name = m_name\n",
    "                    trained_cur_model = model_list[m_idx]\n",
    "                    break\n",
    "\n",
    "            assert trained_model_name is not None, 'no trained model found'\n",
    "            cur_models.append(trained_cur_model)\n",
    "\n",
    "        elif before_after=='attention':\n",
    "            cur_models.append(cur_model)\n",
    "\n",
    "        addons = '_' + acc if not before_after=='training' else ''\n",
    "        imgname = rest.replace('10000_acc_', '').replace('/', '_').replace('.pt', '') + addons\n",
    "        dir_name = f'./saved_probe_plots_{before_after}/{plot_type}-{hook_location}-{data_type}/{input_type}_{total_samples}_{fixed_length}_{linear_mode}'\n",
    "        if save_all_models:\n",
    "            if f'{dir_name}/{imgname}.pdf' in glob.glob( f'{dir_name}/{imgname}.pdf'):\n",
    "                continue        \n",
    "\n",
    "        \n",
    "        layer_range = range(layer_idx, layer_idx+1) if not (plot_all or save_all_models) \\\n",
    "            else range(len(cur_model.transformer.h))\n",
    "        \n",
    "        plot_height = 2 if plot_type == 'both' else 1\n",
    "        nrows = 1 if not before_after else 2\n",
    "        fig, axs = plt.subplots(nrows*plot_height, len(layer_range), figsize=(6 * len(layer_range), 12.3/2*nrows*plot_height))\n",
    "\n",
    "        \n",
    "        for cm_idx, cur_model in enumerate(cur_models):\n",
    "            for lidx, layer in enumerate(tqdm(layer_range)):\n",
    "                if data_type == 'sample':\n",
    "                    # # X = get_batch(\"train\", batch_size=4096)[0]\n",
    "                    # # X_test = get_batch(\"valid\", batch_size=4096)[0]\n",
    "                    # X = get_batch(\"train\", batch_size=samples_to_generate)[0]\n",
    "                    # X_test = get_batch(\"valid\", batch_size=samples_to_generate//4)[0] # use a bit less for testing in order to plot QAQA\n",
    "                    # X = \"\".join([decode(X[i].tolist())\n",
    "                    #             for i in range(X.shape[0])])[:total_tokens] # truncate x to lower computation\n",
    "                    # X_test = \"\".join([decode(X_test[i].tolist())\n",
    "                    #             for i in range(X_test.shape[0])])[:total_tokens]\n",
    "                    # X_n = np.array(list(X[:len(X) // fixed_length * fixed_length])).reshape(\n",
    "                    #     -1, fixed_length\n",
    "                    # )\n",
    "                    # X = torch.tensor(list(map(lambda x: encode(x), X_n)))\n",
    "                    # X_n = np.array(list(X_test[:len(X_test) // fixed_length * fixed_length])).reshape(\n",
    "                    #     -1, fixed_length\n",
    "                    # )\n",
    "                    # X_test = torch.tensor(list(map(lambda x: encode(x), X_n)))\n",
    "\n",
    "                    # if rand_perm: # shuffle in input sequence\n",
    "                    #     for xidx in range(X.shape[0]):\n",
    "                    #         X[xidx] = X[xidx, torch.randperm(X[xidx].shape[0])]\n",
    "                    #     for xidx in range(X_test.shape[0]):\n",
    "                    #         X_test[xidx] = X_test[xidx, torch.randperm(X_test[xidx].shape[0])]\n",
    "                    choice_list = np.array(list('5678'))\n",
    "                    X = [encode(choice_list[np.random.randint(0, len(choice_list), (fixed_length))])\\\n",
    "                        for _ in range(total_tokens//fixed_length)]\n",
    "                    X = torch.tensor(X).long()\n",
    "                    \n",
    "                    choice_list = np.array(list('1234'))\n",
    "                    X_test = [encode(choice_list[np.random.randint(0, len(choice_list), (fixed_length))]) \\\n",
    "                            for _ in range(total_tokens//fixed_length)]\n",
    "                    X_test = torch.tensor(X_test).long()\n",
    "                    # print(X.shape, X_test.shape)\n",
    "                elif data_type=='eqx':\n",
    "                    X = [cur_model.create_equal_distancing_vecotrs(fixed_length, 384, small_component=0.1)[0] *0.05\\\n",
    "                        for _ in range(total_tokens//fixed_length)]\n",
    "                    X = torch.tensor(X).float()\n",
    "                    X_test = [cur_model.create_equal_distancing_vecotrs(fixed_length, 384, small_component=0.1)[0] *0.05\\\n",
    "                            for _ in range(total_tokens//fixed_length)]\n",
    "                    X_test = torch.tensor(X_test).float()\n",
    "\n",
    "                elif data_type=='randx':\n",
    "                    # X = [np.random.rand(fixed_length, 384) * scaler\\\n",
    "                    #     for _ in range(total_tokens//fixed_length)]\n",
    "                    X = np.random.rand(total_tokens//fixed_length, fixed_length, 384)* scaler\n",
    "                    X = torch.tensor(X).float()\n",
    "                    X_test = np.random.rand(total_tokens//fixed_length, fixed_length, 384)* scaler\n",
    "                    X_test = torch.tensor(X_test).float()\n",
    "                elif data_type == 'same':\n",
    "                    X = [np.ones((fixed_length, 384)) * scaler\\\n",
    "                        for _ in range(total_tokens//fixed_length)]\n",
    "                    X = torch.tensor(X).float()\n",
    "                    X_test = [np.ones((fixed_length, 384)) * scaler\\\n",
    "                            for _ in range(total_tokens//fixed_length)]\n",
    "                    X_test = torch.tensor(X_test).float()\n",
    "\n",
    "                \n",
    "\n",
    "                # X = X.to(device)\n",
    "                if before_after=='attention':\n",
    "                    hook_location = 'before_attn' if cm_idx==0 else 'after_attn'\n",
    "\n",
    "                # Function to create a dataset with position labels\n",
    "                layer_activations = {}\n",
    "                def create_position_dataset(model, inputs, layer, loss_type):\n",
    "                \n",
    "                    if hook_location == 'after_attn':\n",
    "                        hook = model.transformer.h[layer].attn.identity.register_forward_hook(\n",
    "                            get_activation_hook(layer_activations, f\"layer_{layer}\")\n",
    "                        )\n",
    "                    elif hook_location == 'before_attn':\n",
    "                        hook = model.transformer.h[layer].attn.pre_att_identity.register_forward_hook(\n",
    "                            get_activation_hook(layer_activations, f\"layer_{layer}\")\n",
    "                        )\n",
    "                    elif hook_location == 'mlp':\n",
    "                        hook = model.transformer.h[layer].layer_identity.register_forward_hook(\n",
    "                            get_activation_hook(layer_activations, f\"layer_{layer}\")\n",
    "                        )\n",
    "\n",
    "\n",
    "                    if hook_location != 'raw':\n",
    "                        with torch.no_grad():\n",
    "                            if data_type == 'sample':\n",
    "                                _ = model(inputs.to(device))\n",
    "                            elif data_type in ['eqx', 'randx', 'same']:\n",
    "                                _ = model(inputs.to(device), direct_input_modification=True)\n",
    "                        hook.remove()\n",
    "                    else:\n",
    "                        layer_activations[f\"layer_{layer}\"] = inputs\n",
    "\n",
    "                    \n",
    "                    # inputs.size(1) is the sequence length\n",
    "                    # if input_type == 'x':\n",
    "                    positions = torch.arange(inputs.size(1)).repeat(inputs.size(0), 1).to(inputs.device)\n",
    "                    activation_tensor = layer_activations[f\"layer_{layer}\"] # Adjust shape if necessary\n",
    "                    if input_type in ['x1*x2', 'x1-x2'] :\n",
    "                        new_positions = []\n",
    "                        new_activation_tensor = []\n",
    "                        for sidx, x1 in enumerate(activation_tensor):\n",
    "                            # pair_idx = np.random.randint(0, len(activation_tensor))\n",
    "                            # pair_odering = np.random.permutation(len(x1))\n",
    "                            # x2 = x1[pair_odering]\n",
    "                            # p1, p2 = positions[sidx], positions[sidx][pair_odering]\n",
    "\n",
    "                            x2 = x1[-1]\n",
    "                            \n",
    "                            p1, p2 = positions[sidx], positions[sidx, -1]\n",
    "                            if input_type == 'x1*x2':  # maybe normalize by their norms\n",
    "                                new_activation_tensor.append((x1*x2)[None, ...]/(x1.norm()*x2.norm()))\n",
    "                            elif input_type == 'x1-x2':\n",
    "                                new_activation_tensor.append((x1-x2).abs()[None, ...])\n",
    "                            elif input_type == '[x1, x2]':\n",
    "                                new_activation_tensor.append((np.hstack([x1,x2])).abs()[None, ...])\n",
    "                            new_positions.append((p1-p2).abs()[None, ...])\n",
    "                        # print((p1-p2).abs()[None, ...].shape, (p1-p2).abs())\n",
    "                        # print(x1.shape, x2.shape, (x1*x2).shape)\n",
    "                        positions = torch.vstack(new_positions)\n",
    "                        activation_tensor = torch.vstack(new_activation_tensor)\n",
    "                        # print('Pshape:', positions)\n",
    "                        # print('Ashape:', activation_tensor.shape)\n",
    "                        # print(': )', positions.shape, activation_tensor.shape)\n",
    "\n",
    "                    # print(inputs.shape, activation_tensor.shape, positions.shape, len(layer_activations))\n",
    "\n",
    "                    # return TensorDataset(activation_tensor, positions)\n",
    "                    if loss_type == 'Cross Entropy':\n",
    "                        positions = positions.long()\n",
    "                    elif loss_type == 'MSE':\n",
    "                        positions = positions.float()\n",
    "                    activation_tensor = activation_tensor.squeeze(0)\n",
    "                    return activation_tensor, positions\n",
    "\n",
    "                # Assuming `input_idx` and `cur_model` are defined\n",
    "                \n",
    "                train_activation_tensor, train_positions = create_position_dataset(cur_model,  X,  layer, loss_type)\n",
    "                dataset = TensorDataset(train_activation_tensor, train_positions)\n",
    "                \n",
    "\n",
    "                test_model = cur_model if model2_name is None else cur_model2\n",
    "                test_activation_tensor, test_positions =  create_position_dataset(test_model, X_test, layer, loss_type)\n",
    "                test_dataset = TensorDataset(test_activation_tensor, test_positions) \n",
    "\n",
    "                dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "                # Initialize the probe\n",
    "                \n",
    "                bs, T, probe_dim = layer_activations[f\"layer_{layer}\"].shape\n",
    "                n_outs = T if loss_type == 'Cross Entropy' else 1\n",
    "                probe = PositionalProbe(embedding_dim=probe_dim,\n",
    "                            linear_mode=linear_mode,\n",
    "                            n_outs=n_outs).to(device)\n",
    "                \n",
    "             \n",
    "\n",
    "                optimizer = torch.optim.AdamW(probe.parameters())\n",
    "\n",
    "                if loss_type == 'MSE':\n",
    "                    criterion = nn.MSELoss()  # Using Mean Squared Error Loss for regression\n",
    "                elif loss_type == 'Cross Entropy':\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                # Train the probe and evaluate Pearson correlation\n",
    "                # print(len(dataset), len(test_dataset))\n",
    "                # best_loss = float('inf')\n",
    "                # best_weights = None\n",
    "                for epoch in range(max_epochs):\n",
    "                    cur_loss = []\n",
    "                    for data, targets in dataloader:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = probe(data.to(device))\n",
    "                        loss = criterion(outputs, targets.to(device))  # Ensure targets are float for MSE calculation\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        cur_loss.append(loss.item())\n",
    "                    cur_loss = np.mean(cur_loss)\n",
    "                    # if cur_loss < best_loss:\n",
    "                    #     best_loss = cur_loss\n",
    "                    #     best_weights = probe.state_dict()\n",
    "                    # if epoch % 15 == 0 or epoch == 0 or epoch == max_epochs-1:\n",
    "                        # print(f\"Epoch {epoch}, Loss: {cur_loss.item():.02f}\", end='\\t')\n",
    "                # print()\n",
    "\n",
    "                # probe.load_state_dict(best_weights)\n",
    "                \n",
    "                all_outputs = []\n",
    "                all_targets = []\n",
    "                all_test_loss = []\n",
    "                probe.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for data, targets in test_loader:\n",
    "                        outputs = probe(data.to(device))\n",
    "                        test_loss = criterion(outputs, targets.to(device))\n",
    "                        all_test_loss.append(test_loss.item())\n",
    "                        if loss_type == 'Cross Entropy':\n",
    "                            outputs = torch.argmax(outputs, dim=-1)\n",
    "                        all_outputs.append(outputs.detach().cpu().numpy())\n",
    "                        all_targets.append(targets.detach().cpu().numpy())\n",
    "                \n",
    "                # print(f\"Test Loss: {np.mean(all_test_loss)}\", end = '\\t')\n",
    "\n",
    "                # Concatenate all collected data\n",
    "                all_outputs = np.concatenate(all_outputs).flatten()\n",
    "                all_targets = np.concatenate(all_targets).flatten()\n",
    "\n",
    "                # Compute the Pearson correlation coefficient\n",
    "                correlation, _ = pearsonr(all_outputs, all_targets)\n",
    "                # print(f'Pearson correlation coefficient: {correlation}')\n",
    "                \n",
    "                slope, intercept, r_value, p_value, std_err = linregress(all_targets, all_outputs)\n",
    "                best_fit_line = slope * np.array(all_targets) + intercept\n",
    "\n",
    "\n",
    "                data = pd.DataFrame({\n",
    "                    'Predicted Positions': all_outputs,\n",
    "                    'True Positions': all_targets.astype(int), \n",
    "                })  \n",
    "\n",
    "                data['Counts'] = data.groupby(['Predicted Positions', 'True Positions'])['Predicted Positions'].transform('count')\n",
    "                # Scatter plot on the first subplot\n",
    "                # if not before_after_training:\n",
    "\n",
    "                #     ax0loc = axs[0, lidx] if len(layer_range) > 1 else axs[0]\n",
    "                #     ax0loc.scatter(all_targets, all_outputs, alpha=0.4, s=5)\n",
    "                #     ax0loc.set_title(f'Layer {layer+1} (r={correlation:.2f}, loss={np.mean(all_test_loss):.2f})')\n",
    "                #     ax0loc.set_xlabel('True Positions')\n",
    "                #     ax0loc.set_ylabel('Predicted Positions')\n",
    "                #     ax0loc.grid(True)\n",
    "                #     ax0loc.set_ylim(min(all_outputs)-5, max(all_outputs)+5)\n",
    "                #     ax0loc.plot(all_targets, best_fit_line, 'r', label=f'y={slope:.2f}x+{intercept:.2f}')\n",
    "                #     # ax0loc.legend()\n",
    "                    \n",
    "                #     max_value = max(all_targets)\n",
    "                #     ax0loc.set_xticks(set_ticks(max_value+1))\n",
    "\n",
    "                # Violin plot on the second subplot\n",
    "\n",
    "                training_status = ''\n",
    "                if before_after=='training':\n",
    "                    training_status = 'Init ' if cm_idx==0 else 'Trained '\n",
    "\n",
    "                if plot_type in ['both', 'violin', 'scatter']:\n",
    "                    if len(layer_range) > 1 and before_after:\n",
    "                        ax1loc = axs[cm_idx*plot_height, lidx] \n",
    "                    elif len(layer_range) > 1:\n",
    "                        ax1loc = axs[lidx]\n",
    "                    else:\n",
    "                        ax1loc = axs[cm_idx*plot_height]\n",
    "                    \n",
    "                    if plot_type == 'violin':\n",
    "                        sns.violinplot(x='True Positions', y='Predicted Positions', \n",
    "                                data=data, ax=ax1loc, width=0.8, linewidth=0.5)\n",
    "                    if plot_type == 'scatter':\n",
    "                        ax1loc.scatter(all_targets, all_outputs, alpha=0.4, s=5)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    ax1loc.set_title(f'{training_status}Layer {layer+1} (r={correlation:.2f}, loss={np.mean(all_test_loss):.2f})')\n",
    "                    ax1loc.set_xlabel('True Positions')\n",
    "                    ax1loc.set_ylabel('Predicted Positions')\n",
    "                    ax1loc.grid(True)\n",
    "                    ax1loc.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                    ax1loc.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "                    # print(max(all_targets))\n",
    "                    extension = int(max(all_targets)*0.1)\n",
    "                    # ax1loc.set_ylim(min(all_targets)-extension, max(all_targets)+extension)\n",
    "                    ax1loc.set_xlim(int(min(all_targets))-extension, int(max(all_targets))+extension)\n",
    "                    ax1loc.plot(all_targets, best_fit_line, 'r', label=f'y={slope:.2f}x+{intercept:.2f}')\n",
    "                    # ax1loc.legend()\n",
    "\n",
    "                    max_value = max(all_targets)\n",
    "                    ax1loc.set_xticks(set_ticks(max_value+1).astype(int))\n",
    "                    max_value = max(all_outputs); min_value = min(all_outputs)\n",
    "                    ax1loc.set_yticks(set_ticks(max_value+1, min_value=int(min_value)).astype(int))\n",
    "                    \n",
    "\n",
    "                if plot_type in ['both', 'tsne']:\n",
    "                    add1 = 1 if plot_type == 'both' else 0\n",
    "\n",
    "                    # ax2loc = axs[cm_idx*plot_height + add1, lidx] if len(layer_range) > 1 else axs[cm_idx*plot_height]\n",
    "                    if len(layer_range) > 1 and before_after:\n",
    "                        ax2loc = axs[cm_idx*plot_height + add1, lidx] \n",
    "                    elif len(layer_range) > 1:\n",
    "                        ax2loc = axs[lidx]\n",
    "                    else:\n",
    "                        ax2loc = axs[cm_idx*plot_height + add1]\n",
    "                    embeddings = test_activation_tensor.detach().cpu().numpy()\n",
    "                    labels = test_positions.detach().cpu().numpy()\n",
    "                    seletion = np.arange(len(labels))[::2]\n",
    "                    embeddings = embeddings[seletion]\n",
    "                    labels = labels[seletion]\n",
    "\n",
    "                    print(embeddings.shape)\n",
    "                    plot_tsne_colored_by_position(embeddings, labels, ax2loc, training_status)\n",
    "\n",
    "\n",
    "                # if before_after_training:\n",
    "                #     annos = 'ab'\n",
    "                #     ax1loc.annotate(f'({annos[cm_idx]})', xy=(0.5, -0.1), xycoords='axes fraction', ha='center', va='center', fontsize=14, fontproperties=prop)\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(left=0.03, right=0.975, top=0.97, bottom=0.07, hspace=0.3)\n",
    "\n",
    "        \n",
    "        if save_all_models or save:\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "            fig.savefig(f'{dir_name}/{imgname}.pdf', format='pdf')\n",
    "\n",
    "            plt.close()\n",
    "            del fig, axs, data, probe, optimizer, criterion, dataloader, test_loader\n",
    "            gc.collect()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "widgets.interact(prob_model, \n",
    "                 model_name=useful_name_list, \n",
    "                 model2_name=[None] + useful_name_list,\n",
    "                 save=False,\n",
    "                 before_after_training = False,\n",
    "                 layer_idx=(0, 5), \n",
    "                 plot_all=True, \n",
    "                 rand_perm=True, \n",
    "                 fixed_length=(4,128),\n",
    "                 total_samples=(1000, 5000),\n",
    "                 linear_mode=(0, 5),\n",
    "                 hook_location=['after_attn', 'before_attn', 'mlp', 'raw'],\n",
    "                 plot_type=['violin', 'tsne', 'scatter', 'both'],\n",
    "                 scaler=(0.001, 0.5, 0.001),)\n",
    "\n",
    "                # hook_location=['before_attn', 'after_attn'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity\n",
    "\n",
    "1. It is the averaging effect of the softmax attention weights that generates the adjacency pattern.\n",
    "2. It requires the model weights to be with small variance.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the distribution of $ Vx $ when $ x $ and $ V $ are independent and identically distributed (iid) with a normal distribution $ N(\\mu, \\sigma^2) $, where $ x $ is a $ d \\times 1 $ vector and $ V $ is a $ d \\times d $ matrix, we proceed as follows:\n",
    "\n",
    "**Step 1: Understand the Components**\n",
    "- **Vector $ x $**: Each element $ x_i $ of $ x $ is distributed as $ N(\\mu, \\sigma^2) $.\n",
    "- **Matrix $ V $**: Each element $ V_{ij} $ of $ V $ is also distributed as $ N(\\mu, \\sigma^2) $.\n",
    "\n",
    "**Step 2: Multiplication $ Vx $**\n",
    "When $ V $ is multiplied by $ x $, the resulting vector $ y = Vx $ will have each element $ y_i $ given by:\n",
    "$ y_i = \\sum_{j=1}^d V_{ij} x_j $\n",
    "\n",
    "**Step 3: Distribution of Each $ y_i $**\n",
    "Since each $ V_{ij} $ and $ x_j $ are independent and normally distributed, the product $ V_{ij} x_j $ is not normally distributed. However, the sum of these products (i.e., the dot product forming each $ y_i $) could be approximated or analyzed further if $ V $ and $ x $ were linear transformations of Gaussian random variables.\n",
    "\n",
    "**Step 4: Central Limit Theorem (CLT)**\n",
    "When $ d $ (the dimension) is large, the sum of a large number of independent random variables (as is the case in the components of $ y_i $) will tend towards a normal distribution according to the Central Limit Theorem. Thus, each $ y_i $ can be approximated as normally distributed.\n",
    "\n",
    "**Step 5: Calculate Mean and Variance**\n",
    "The mean $ E[y_i] $ is:\n",
    "\n",
    "$ E[y_i] = E\\left[\\sum_{j=1}^d V_{ij} x_j\\right] = \\sum_{j=1}^d E[V_{ij}] E[x_j] = d \\mu^2 $\n",
    "\n",
    "The variance $ \\text{Var}(y_i) $ involves calculating:\n",
    "\n",
    "$ \\text{Var}(y_i) = \\sum_{j=1}^d \\text{Var}(V_{ij} x_j) $\n",
    "\n",
    "Given $ V_{ij} $ and $ x_j $ are independent, each product's variance $ \\text{Var}(V_{ij} x_j) $ will be:\n",
    "\n",
    "$ \\text{Var}(V_{ij} x_j) = E[(V_{ij} x_j)^2] - (E[V_{ij} x_j])^2 $\n",
    "\n",
    "This simplifies to:\n",
    "\n",
    "$ \\text{Var}(V_{ij} x_j) = E[V_{ij}^2] E[x_j^2] - (E[V_{ij}] E[x_j])^2 $\n",
    "$ \\text{Var}(V_{ij} x_j) = (\\mu^2 + \\sigma^2)^2 - \\mu^4 $\n",
    "\n",
    "Adding these variances together (since the products are independent for different $ j $):\n",
    "\n",
    "$ \\text{Var}(y_i) = d((\\mu^2 + \\sigma^2)^2 - \\mu^4) $\n",
    "\n",
    "**Conclusion**\n",
    "If $ d $ is large enough for the Central Limit Theorem to apply, then each element of the vector $ y = Vx $ is approximately normally distributed, $ y_i \\approx N(d\\mu^2, d((\\mu^2 + \\sigma^2)^2 - \\mu^4)) $. This approach assumes that the elements of $ V $ and $ x $ are iid, and $ d $ is sufficiently large for the CLT approximation. If the matrix and vector dimensions or distributions differ, further adjustments would be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43dfda7a5d54ecfb2c4b9c32862bf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='seq_len', max=4096, min=10), FloatSlider(value=0.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_attention(seq_len=20, mu_v=0, sig_v=1, mu_A=0, sig_A=1, shift=0, dimension=100, sim_func='cos', dist_type='normal', v_n=0)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# def causal_softmax(x):\n",
    "#     \"\"\"Compute causal softmax values for the vector 'x'.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / e_x.sum()\n",
    "font_path = './timr45w.ttf'  # Update this path\n",
    "from matplotlib import font_manager\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['axes.labelsize'] = 12  # Axis labels\n",
    "plt.rcParams['xtick.labelsize'] = 12  # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 12  # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] = 12  # Legend\n",
    "plt.rcParams['axes.titlesize'] = 12  # Title\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def plot_attention(\n",
    "    seq_len = 20,   # Number of vectors\n",
    "    mu_v = 0,\n",
    "    sig_v = 1,\n",
    "    mu_A = 0,\n",
    "    sig_A = 1,\n",
    "    shift = 0,\n",
    "    dimension = 100,  # Dimensionality of each vector\n",
    "    sim_func = 'cos',\n",
    "    dist_type = 'normal',\n",
    "    v_n = 0,\n",
    "):\n",
    "    v_n = min(v_n, seq_len-1)\n",
    "    sim_func_name = 'Dot Product' if sim_func == 'dot' else 'Cosine Similarity'\n",
    "    # Parameters\n",
    "\n",
    "\n",
    "    # Initialize e vectors from index 0 to n-1\n",
    "    # v_vectors = np.array([np.random.normal(mu_v, sig_v, dimension) for _ in range(seq_len)])\n",
    "    v_vectors = np.random.normal(mu_v, sig_v, (seq_len, dimension))\n",
    "\n",
    "    # Initialize A coefficients from index 0 to n-1 and apply causal softmax\n",
    "    # A = np.zeros((n, n))\n",
    "    # A = np.random.normal(0, np.sqrt(n), (n, n))\n",
    "    if dist_type == 'normal':\n",
    "        A = np.random.normal(mu_A, sig_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'gemma':\n",
    "        A = np.random.gamma(1, sig_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'uniform':\n",
    "        A = np.random.uniform(mu_A, sig_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'possion':\n",
    "        A = np.random.poisson(mu_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'chi':\n",
    "        A = np.random.chisquare()\n",
    "\n",
    "    # A = np.random.normal(10, 1, (n, n))\n",
    "    # A = np.random.gamma(0, 0.1, (n, n))\n",
    "    # A = np.random.chisquare(0.001, (n, n))\n",
    "    # A = np.random.uniform(0, 0.01, (n, n))\n",
    "\n",
    "    A = A * (1.0 / math.sqrt(v_vectors.shape[-1]))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    _A = np.tril(A, 0)\n",
    "    axes[0].hist(_A[np.where(_A!=0)].flatten(), bins=200)\n",
    "    _A_std_row_wise = _A[np.where(_A!=0)].flatten().std(axis=-1).mean()\n",
    "    axes[0].set_title(f'A distribution before softmax (std_row-wise: {_A_std_row_wise:.3f})')\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        # A[i, :i+1] = softmax(A[i, :i+1]) + 1 # amazing : )\n",
    "        A[i, :i+1] = softmax(A[i, :i+1]) + shift\n",
    "\n",
    "\n",
    "    A = np.tril(A, 0)\n",
    "\n",
    "    non_zero_A = A[np.where(A!=0)].flatten()\n",
    "    len_A = len(non_zero_A)\n",
    "    sorted_non_zero_A = sorted(non_zero_A)\n",
    "    axes[1].hist(non_zero_A, bins=200)\n",
    "    axes[1].set_title(f'A distribution after softmax (Abs_Avg = {np.abs(sorted_non_zero_A)[:len_A//4].mean():.06f})')\n",
    "\n",
    "    axes[2].plot(A[-1])\n",
    "    axes[2].set_title(f'The last row')\n",
    "\n",
    "    plt.show()\n",
    "    # Compute y vectors using matrix multiplication with a lower triangular matrix of A\n",
    "    y_vectors = A @ v_vectors\n",
    "    norms = np.linalg.norm(y_vectors, axis=1)\n",
    "    print(y_vectors.shape, norms.shape)\n",
    "\n",
    "    # plt.figure(figsize=(6, 5))\n",
    "    fig, axes = plt.subplots(1,4, figsize=(28, 5))\n",
    "    axes[0].hist(y_vectors[v_n], bins=200)\n",
    "    axes[0].set_title(f'Output Vector {v_n+1}, norm={np.linalg.norm(norms[v_n]):.3f}')\n",
    "    axes[1].hist(y_vectors[-1], bins=200)\n",
    "    axes[1].set_title(f'Output Vector {len(y_vectors)}, norm={np.linalg.norm(norms[-1]):.3f}')\n",
    "\n",
    "\n",
    "    # Compute cosine similarities using vector operations\n",
    "    # cosine_similarities = np.dot(y_vectors, y_vectors.T) / np.outer(norms, norms)\n",
    "    cosine_similarities = np.dot(y_vectors, y_vectors.T) \n",
    "    divisor = 1 if sim_func=='dot' else np.outer(norms, norms)\n",
    "    if sim_func == 'dot':\n",
    "        cosine_similarities = cosine_similarities / divisor\n",
    "    else:\n",
    "        cosine_similarities = cosine_similarity(y_vectors, y_vectors)\n",
    "\n",
    "\n",
    "    axes[2].plot(cosine_similarities[-1])\n",
    "    axes[2].set_title(f'Last Vector {sim_func_name}')\n",
    "    axes[3].plot(np.outer(norms, norms)[-1])\n",
    "    axes[3].set_title(f'Last Norm Divisor')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Extracting upper triangular part of cosine similarities matrix, excluding diagonal\n",
    "    results = np.zeros((seq_len, seq_len))\n",
    "    for i in range(seq_len):\n",
    "        for j in range(i + 1, seq_len):\n",
    "            results[i, j] = cosine_similarities[i, j]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    cm = axes[0].imshow(A, cmap='Reds')\n",
    "    axes[0].set_title('Attention Map')\n",
    "    plt.colorbar(cm)\n",
    "\n",
    "    cm = axes[1].imshow(cosine_similarities, cmap='Reds')\n",
    "    # cm = axes[1].imshow(cosine_similarities, )1````\n",
    "    axes[1].set_title(f'{sim_func_name} Matrix')\n",
    "    plt.colorbar(cm)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "interact(plot_attention, \n",
    "         seq_len=(10, 4096), \n",
    "         mu_v = (-10, 10, 0.01), \n",
    "         sig_v = (0, 2, 0.0001),\n",
    "         mu_A = (-20, 20, 0.01), \n",
    "         sig_A = (0, 10, 0.0001),  \n",
    "         shift=(-2, 2, 0.001), \n",
    "         dimension=(4, 384),\n",
    "         sim_func = ['cos', 'dot'],\n",
    "         dist_type = ['normal', 'gemma', 'uniform', 'possion'],\n",
    "         v_n = (0, 2048)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cc870f181b4d7982f44434110144e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=(\"acc=0_rev16_nope_sd242_T2408100054_nope/ckp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_att(model_name, layer_idx=0, plot_all=0, save_map=False, find_best=True, search_all_heads=False, metric_id=4, bestk=4, clean_plot=False, input_name=['eqx', 'randx', 'sample_1', 'sample_2', 'sample_3'], amp_head=2)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the difference in projection for the same vector\n",
    "# x = torch.rand(1, 1, 384).to(device)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from ast import literal_eval\n",
    "import ipywidgets as widgets\n",
    "\n",
    "font_path = './timr45w.ttf'  # Update this path\n",
    "from matplotlib import font_manager\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['axes.labelsize'] = 12  # Axis labels\n",
    "plt.rcParams['xtick.labelsize'] = 12  # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 12  # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] = 12  # Legend\n",
    "plt.rcParams['axes.titlesize'] = 12  # Title\n",
    "\n",
    "n_embd = 384\n",
    "sz = 64\n",
    "# x = torch.zeros(1, sz, n_embd).to(device)\n",
    "# sc = torch.rand(1, sz, n_embd).to(device)\n",
    "\n",
    "# # idx = np.random.randint(0, n_embd)\n",
    "# idx = np.random.randint(0, n_embd, size=(sz))\n",
    "\n",
    "# x[0, :, idx] = 1\n",
    "# x += sc\n",
    "x = np.random.normal(0, 0.01, (1, sz, n_embd))\n",
    "x = torch.tensor(x).float().to(device)\n",
    "\n",
    "# y = model_list[17].transformer.h[1].attn.c_attn(x)\n",
    "# input_idx = torch.tensor(encode('12modp(123)=')).to(device)[None,...]\n",
    "# input_idx = torch.tensor(encode('$123+45=')).to(device)[None,...]\n",
    "# input_idx = torch.tensor(encode('$333+444=777$\\n$123+54=')).to(device)[None,...]\n",
    "# input_idx2 = torch.tensor(encode('$33333333333333')).to(device)[None,...]\n",
    "# input_idx3 = torch.tensor(encode('$992+299=')).to(device)[None,...]\n",
    "# input_idx = torch.tensor(encode('where(0917328,7)=')).to(device)[None,...]\n",
    "input_idx = torch.tensor(encode('rev(0917328938453)=')).to(device)[None,...]\n",
    "\n",
    "# input_idx2 = torch.tensor(encode('rev(54321)=')).to(device)[None,...]\n",
    "input_idx2 = torch.tensor(encode('56310=')).to(device)[None,...]\n",
    "# input_idx3 = torch.tensor(encode('$992+299=')).to(device)[None,...]\n",
    "rand_nums =  list(np.random.randint(0, 10, (sz)))\n",
    "rand_nums = ''.join(map(str, rand_nums))\n",
    "\n",
    "input_idx3 = torch.tensor(encode(f'rev({rand_nums}')).to(device)[None,...]\n",
    "\n",
    "\n",
    "eqx = torch.tensor(model.create_equal_distancing_vecotrs(sz, n_embd, small_component=0.01)[0]).to(device).to(torch.float32)[None,...] * 0.01\n",
    "\n",
    "inputs_dict = {\n",
    "    'sample_1': input_idx,\n",
    "    'sample_2': input_idx2,\n",
    "    'sample_3': input_idx3,\n",
    "    'eqx': eqx,\n",
    "    'randx': x,\n",
    "} \n",
    "\n",
    "# Specify the path to your Times New Roman font file\n",
    "font_path = './timr45w.ttf'  # Update this path\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# def levenshteinDistance(s1, s2):\n",
    "#     if len(s1) > len(s2):\n",
    "#         s1, s2 = s2, s1\n",
    "\n",
    "#     distances = range(len(s1) + 1)\n",
    "#     for i2, c2 in enumerate(s2):\n",
    "#         distances_ = [i2+1]\n",
    "#         for i1, c1 in enumerate(s1):\n",
    "#             if c1 == c2:\n",
    "#                 distances_.append(distances[i1])\n",
    "#             else:\n",
    "#                 distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "#         distances = distances_\n",
    "#     return distances[-1]\n",
    "\n",
    "# def get_PE_tendency(mat):\n",
    "#     r = 0\n",
    "#     r2 = 0\n",
    "#     r3 = 0\n",
    "#     r4 = 0\n",
    "#     r5 = 0\n",
    "#     r5_counts = 0\n",
    "#     r6 = 0\n",
    "#     r6_count = 0\n",
    "#     mat = mat.detach().cpu().numpy() if isinstance(mat, torch.Tensor) else mat\n",
    "#     for lidx, layer in enumerate(mat[1:]):\n",
    "#         r += (np.diff(layer[:lidx+1], axis=0) > 0).sum()\n",
    "#         r3 += (np.diff(layer[:lidx+1], axis=0) > 0).sum()\n",
    "#         r3 -= (np.diff(layer[:lidx+1], axis=0) <= 0).sum()\n",
    "\n",
    "#         c2p = sum([((layer[j+1:lidx+1]-layer[j]) > 0).sum() for j in range(lidx+1)])\n",
    "#         c2m = sum([((layer[j+1:lidx+1]-layer[j]) <= 0).sum() for j in range(lidx+1)])\n",
    "#         r2 += c2p\n",
    "#         r4 += c2p - c2m\n",
    "\n",
    "#         valid_layer = layer[:lidx+1]\n",
    "#         if len(valid_layer)<3: \n",
    "#             continue\n",
    "\n",
    "#         # cur_order = valid_layer\n",
    "#         # original_order = valid_layer[np.argsort(valid_layer)]\n",
    "#         # corr = spearmanr(original_order, cur_order).correlation\n",
    "#         # if np.isnan(corr):\n",
    "#             # continue\n",
    "#         # r5 += spearmanr(original_order, cur_order).correlation \n",
    "\n",
    "\n",
    "#         right_order = np.argsort(valid_layer-np.arange(len(valid_layer))*1e-5)\n",
    "#         right_right_order = np.argsort(right_order)\n",
    "#         original_order = np.arange(len(valid_layer))\n",
    "#         edit_distance = levenshteinDistance(right_order, original_order)\n",
    "#         r5 += edit_distance\n",
    "#         r5_counts += len(valid_layer)\n",
    "#         r_value = pearsonr(original_order, right_right_order)[0]\n",
    "#         if np.isnan(r_value): continue\n",
    "#         r6 += pearsonr(original_order, right_right_order)[0]\n",
    "#         r6_count += 1\n",
    "#         # r5 += pearsonr(original_order, cur_order)[0]\n",
    "\n",
    "#     max_r = np.arange(mat.shape[0]-1).sum()\n",
    "#     t1 = round(r/max_r, 2)\n",
    "\n",
    "#     max_r2 = sum([ np.arange(n+1).sum() for n in np.arange(mat.shape[0]-1)])\n",
    "#     t2 = round(r2/max_r2, 2)\n",
    "\n",
    "#     t3 = round(r3/max_r, 2)\n",
    "\n",
    "#     t4 = round(r4/max_r2, 2)\n",
    "    \n",
    "#     t5 =  round((r5_counts-r5) / r5_counts, 2)\n",
    "\n",
    "#     t6 = round(r6/r6_count, 2)\n",
    "#     return f'({t1},{t2},{t3},{t4},{t5},{t6})'\n",
    "\n",
    "\n",
    "# def generate_tendency_map(mat):\n",
    "#     mat = mat.detach().cpu().numpy() if isinstance(mat, torch.Tensor) else mat\n",
    "#     empty_mat = np.zeros_like(mat)\n",
    "#     for lidx, layer in enumerate(mat):\n",
    "#         if lidx == 0:\n",
    "#             continue\n",
    "#         counter = 0\n",
    "#         for j in range(1, lidx+1):\n",
    "#             if layer[j]<=layer[j-1]: # weird but worked ...\n",
    "#                 counter = 0\n",
    "#             else:\n",
    "#                 counter += 1\n",
    "#             empty_mat[lidx, j] = counter\n",
    "    \n",
    "#     return empty_mat\n",
    "\n",
    "# def generate_tendency_map(mat):\n",
    "#     mat = mat.detach().cpu().numpy() if isinstance(mat, torch.Tensor) else mat\n",
    "#     empty_mat = np.zeros_like(mat)\n",
    "#     for lidx, layer in enumerate(mat):\n",
    "      \n",
    "#         counter = 0\n",
    "#         for j in range(0, lidx+1):\n",
    "#             if layer[j]<=layer[j-1]: # weird but worked ...\n",
    "#                 counter = 0\n",
    "#             else:\n",
    "#                 counter += 1\n",
    "#             empty_mat[lidx, j] = counter\n",
    "#             # empty_mat[lidx, j] = np.log(mat[lidx, j])\n",
    "    \n",
    "#     return empty_mat\n",
    "\n",
    "    \n",
    "\n",
    "def plot_att(model_name, \n",
    "             layer_idx=0, \n",
    "             plot_all=0, \n",
    "             save_map=False, \n",
    "             find_best=True, \n",
    "             search_all_heads=False,\n",
    "             metric_id = 4,\n",
    "             bestk = 4,\n",
    "             clean_plot = False,\n",
    "             input_name = sorted(list(inputs_dict.keys())), \n",
    "             amp_head=2,):\n",
    "    total_std = []\n",
    "    total_scores = []\n",
    "    next_att_scores = []\n",
    "\n",
    "    acc = model_name.split('_')[0]\n",
    "    rest = '_'.join(model_name.split('_')[1:])\n",
    "    imgname = rest.replace('10000_acc_', '').replace('/', '_').replace('.pt', '') + '_' + acc\n",
    "\n",
    "    # cur_model = model_list[12]\n",
    "    # cur_model = model_list[2]\n",
    "    model_idx = useful_name_list.index(model_name)\n",
    "    cur_model = model_list[model_idx]\n",
    "\n",
    "    \n",
    "    layer_range = range(layer_idx, layer_idx+1) if plot_all==0 else range(plot_all)\n",
    "    \n",
    "    if len(layer_range) > len(cur_model.transformer.h):\n",
    "        layer_range = range(len(cur_model.transformer.h))\n",
    "\n",
    "    for level in layer_range:\n",
    "        activation = {}\n",
    "\n",
    "        def getActivation(name):\n",
    "            # the hook signature\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "\n",
    "            return hook\n",
    "\n",
    "        h1 = cur_model.transformer.h[level].attn.c_attn.register_forward_hook(\n",
    "            getActivation(f\"layer_{level}\")\n",
    "        )\n",
    "        \n",
    "        h1q = cur_model.transformer.h[level].attn.iq.register_forward_hook(\n",
    "            getActivation(f\"q{level}\")\n",
    "        ) \n",
    "        h1k = cur_model.transformer.h[level].attn.ik.register_forward_hook(\n",
    "            getActivation(f\"k{level}\")\n",
    "        ) \n",
    "        h1v = cur_model.transformer.h[level].attn.iv.register_forward_hook(\n",
    "            getActivation(f\"v{level}\")\n",
    "        ) \n",
    "\n",
    "        h2 = cur_model.transformer.h[level].attn.identity.register_forward_hook(\n",
    "            getActivation(f\"layer_{level}_iden\")\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            input_values = inputs_dict[input_name].cuda()\n",
    "            cur_model = cur_model.cuda()\n",
    "            if 'sample' in input_name:\n",
    "                out = cur_model(input_values)\n",
    "                y = decode([out[0].detach().cpu().numpy().argmax()])\n",
    "                print(y)\n",
    "            else: # eqx or randx\n",
    "                _ = cur_model(input_values, direct_input_modification=True)\n",
    "            # cur_model = cur_model.cpu()\n",
    "      \n",
    "\n",
    "        h1.remove()\n",
    "        h1q.remove()\n",
    "        h1k.remove()\n",
    "        h1v.remove()\n",
    "        h2.remove()\n",
    "\n",
    "\n",
    "        '''Plot the attention maps'''\n",
    "        xw = activation[f\"layer_{level}\"]\n",
    "        q, k, v  = xw.split(n_embd, dim=2)\n",
    "        q_reshape = activation[f\"q{level}\"]\n",
    "        k_reshape = activation[f\"k{level}\"]\n",
    "        v_reshape = activation[f\"v{level}\"]\n",
    "\n",
    "        # plt.figure(figsize=(12, 3))\n",
    "        k_numpy = k_reshape.detach().cpu().numpy()\n",
    "        k_numpy = k_numpy.transpose(0, 2, 1, 3)\n",
    "        bs, T, n_head, head_dim = k_numpy.shape\n",
    "        k_numpy = k_numpy.reshape(bs, T, -1)\n",
    "        # print(k_numpy.shape)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "        axes[0].plot(k_numpy[:, 0].flatten())\n",
    "        axes[0].set_title('key 0')\n",
    "        axes[1].hist(k_numpy[:, 0].flatten(), bins=300)\n",
    "        axes[1].set_title('key 0 distribution')\n",
    "        # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "        # plt.show()\n",
    "\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "        k_last = k_numpy[:, -1].flatten()\n",
    "        axes[2].plot(k_last)\n",
    "        axes[2].set_title(f'key vector {T}')\n",
    "        axes[3].hist(k_last, bins=300)\n",
    "        axes[3].set_title(f'key vector {T} distribution')\n",
    "        # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "        plt.show()\n",
    "\n",
    "        v_numpy = v_reshape.detach().cpu().numpy()\n",
    "        v_numpy = v_numpy.transpose(0, 2, 1, 3)\n",
    "        bs, T, n_head, head_dim = v_numpy.shape\n",
    "        v_numpy = v_numpy.reshape(bs, T, -1)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "        axes[0].plot(v_numpy[:, 0].flatten())\n",
    "        axes[0].set_title('value 0')\n",
    "        axes[1].hist(v_numpy[:, 0].flatten(), bins=300)\n",
    "        axes[1].set_title('value 0 distribution')\n",
    "        # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "        # plt.show()\n",
    "\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "        v_last = v_numpy[:, -1].flatten()\n",
    "        axes[2].plot(v_last)\n",
    "        axes[2].set_title(f'value vector {T}')\n",
    "        axes[3].hist(v_last, bins=300)\n",
    "        axes[3].set_title(f'value vector {T} distribution')\n",
    "        # plt.plot(k.detach().cpu().numpy().flatten()-1)\n",
    "        plt.show()\n",
    "\n",
    "        from itertools import combinations\n",
    "        head_dim = n_embd//cur_model.config.n_head\n",
    "        idx_comb = [np.arange(head_dim)] + [[i] for i in range(head_dim)]\n",
    "\n",
    "        n_arrays = cur_model.config.n_head\n",
    "        all_records = [[] for _ in range(n_arrays)] \n",
    "        all_maps = [[] for _ in range(n_arrays)] \n",
    "        all_idxsets = [[] for _ in range(n_arrays)] \n",
    "        original_score = []\n",
    "        head2 = []\n",
    "        s_head2 = []\n",
    "        sim_head2 = []\n",
    "\n",
    "        run_search = True\n",
    "        # for cur_idxset in tqdm(idx_comb):\n",
    "        for cur_idxset in idx_comb[:1]:\n",
    "\n",
    "            if not run_search:\n",
    "                break\n",
    "            if not find_best:\n",
    "                run_search = False\n",
    "                cur_idxset = range(head_dim)\n",
    "\n",
    "            if not run_search:\n",
    "                fig, ax = plt.subplots(4, cur_model.config.n_head, figsize=(18, 10))\n",
    "\n",
    "            for hidx in range(cur_model.config.n_head):\n",
    "                \n",
    "                attmap = q_reshape[0, hidx, :, cur_idxset].cuda()@k_reshape[0, hidx, :, cur_idxset].cuda().transpose(0,1)\n",
    "                attmap = attmap / math.sqrt(q_reshape.shape[-1])\n",
    "                mask = np.triu(np.ones_like(attmap.detach().cpu().numpy(), dtype=bool), 1)\n",
    "                # mask = np.triu(np.ones_like(attmap.detach().cpu().numpy(), dtype=bool), )\n",
    "                mask = torch.tensor(mask).to(device)\n",
    "\n",
    "                # digit = attmap.flatten()[0].detach().cpu().clone()\n",
    "                attmap[mask] = -np.inf \n",
    "                # T = attmap.shape[-1]\n",
    "                # attmap[np.arange(T), np.arange(T)] = digit\n",
    "\n",
    "                attmap_np = attmap.detach().cpu().numpy()\n",
    "                attmap_tend = get_PE_tendency(attmap_np)\n",
    "\n",
    " \n",
    "                \n",
    "                s_attmap = torch.nn.Softmax(dim=-1)(attmap)\n",
    "                # calc = torch.ones_like(calc) * calc.mean()\n",
    "                s_attmap_np = s_attmap.detach().cpu().numpy()\n",
    "                tendency_map = generate_tendency_map(s_attmap_np)\n",
    "                mat_tend = get_PE_tendency(s_attmap_np)\n",
    "\n",
    "                y_out = s_attmap.cpu() @ v_reshape[0, hidx, :, cur_idxset].cpu()\n",
    "                # print(y_out.shape)\n",
    "                y_out = activation[f\"layer_{level}_iden\"].detach().cpu().numpy()\n",
    "                B, T, hd = y_out.shape\n",
    "                y_out = y_out.reshape(B, T, cur_model.config.n_head, -1)\n",
    "                y_out = y_out[..., hidx, :]\n",
    "\n",
    "                # print(y_out.shape)\n",
    "                y_out = y_out.sum(axis=0)\n",
    "                # print(y_out.shape)\n",
    "\n",
    "                sim_map = cosine_similarity(y_out, y_out)\n",
    "\n",
    "\n",
    "                if hidx == amp_head or (search_all_heads and find_best):\n",
    "                    if find_best:\n",
    "                        adj_score = literal_eval(attmap_tend)[metric_id]\n",
    "\n",
    "                        \n",
    "                        if len(cur_idxset) == head_dim:\n",
    "                            original_score.append(adj_score)\n",
    "                            head2.append(attmap_np)\n",
    "                            s_head2.append(s_attmap_np)\n",
    "                            sim_head2.append(sim_map)\n",
    "                        else:\n",
    "                            all_records[hidx].append(adj_score)\n",
    "                            all_maps[hidx].append(attmap_np)\n",
    "                            all_idxsets[hidx].append(cur_idxset)\n",
    "                    else:\n",
    "                        head2.append(attmap_np) \n",
    "                        s_head2.append(s_attmap_np)\n",
    "                        sim_head2.append(sim_map)\n",
    "\n",
    "\n",
    "\n",
    "                if not run_search: \n",
    "                    mat = ax[0, hidx].imshow(attmap_np, cmap='Reds', interpolation='nearest')\n",
    "                    ax[0, hidx].set_title(f'head {hidx}={attmap_tend}')\n",
    "                    plt.colorbar(mat, ax=ax[0, hidx], orientation='vertical', fraction=0.06, )\n",
    "\n",
    "                    mat = ax[1, hidx].imshow(s_attmap_np, cmap='Reds', interpolation='nearest')\n",
    "                    ax[1, hidx].set_title(f'head {hidx}={mat_tend}')\n",
    "                    plt.colorbar(mat, ax=ax[1, hidx], orientation='vertical', fraction=0.06, )\n",
    "\n",
    "                    mat = ax[2, hidx].imshow(tendency_map, cmap='Reds', interpolation='nearest')\n",
    "                    ax[2, hidx].set_title(f'head {hidx}={mat_tend}')\n",
    "                    plt.colorbar(mat, ax=ax[2, hidx], orientation='vertical', fraction=0.06, )\n",
    "\n",
    "                    mat = ax[3, hidx].imshow(sim_map, cmap='Reds', interpolation='nearest')\n",
    "                    sim_tend = get_PE_tendency(sim_map)\n",
    "\n",
    "                    ax[3, hidx].set_title(f'head {hidx}={sim_tend}')\n",
    "                    plt.colorbar(mat, ax=ax[3, hidx], orientation='vertical', fraction=0.06,)\n",
    "\n",
    "            if not run_search: \n",
    "                plt.subplots_adjust(hspace=.4)\n",
    "                fig.suptitle(f'{input_name}_{imgname}_layer={level+1}', fontsize=16, y=0.96)\n",
    "                if save_map:\n",
    "                    os.makedirs(f'./saved_heads_plots/', exist_ok=True)\n",
    "                    fig.savefig(f'./saved_heads_plots/{input_name}_{imgname}_layer={level+1}.svg')\n",
    "                plt.show()\n",
    "\n",
    "        if find_best:\n",
    "            fig, ax = plt.subplots(8, len(head2), figsize=(3.5*len(head2), 27))\n",
    "            for amidx, attnmap_np in enumerate(head2):\n",
    "                ax_loc_0 = ax[0, amidx] if len(head2)>1 else ax[0]\n",
    "                ax_loc_1 = ax[1, amidx] if len(head2)>1 else ax[1]\n",
    "                ax_loc_2 = ax[2, amidx] if len(head2)>1 else ax[2]\n",
    "                ax_loc_3 = ax[3, amidx] if len(head2)>1 else ax[3]\n",
    "                ax_loc_4 = ax[4, amidx] if len(head2)>1 else ax[4]\n",
    "                ax_loc_5 = ax[5, amidx] if len(head2)>1 else ax[5]\n",
    "                ax_loc_6 = ax[6, amidx] if len(head2)>1 else ax[6]\n",
    "                ax_loc_7 = ax[7, amidx] if len(head2)>1 else ax[7]\n",
    "\n",
    "\n",
    "                mat = ax_loc_0.imshow(attnmap_np, cmap='Reds', interpolation='nearest')\n",
    "                head2_PE_scores = get_PE_tendency(attnmap_np)\n",
    "                ax_loc_0.set_title(f'head {amidx}={head2_PE_scores}')\n",
    "                plt.colorbar(mat, ax=ax_loc_0, orientation='vertical', fraction=0.06, )\n",
    "\n",
    "                tendmap_head2 = generate_tendency_map(attnmap_np)\n",
    "                mat = ax_loc_1.imshow(tendmap_head2, cmap='Reds', interpolation='nearest')\n",
    "                ax_loc_1.set_title(f'head {amidx}={original_score[amidx]}')\n",
    "                plt.colorbar(mat, ax=ax_loc_1, orientation='vertical', fraction=0.06, )\n",
    "                next_att_scores.append(original_score[amidx])\n",
    "\n",
    "\n",
    "                lower_tril_attnmap_np = attnmap_np[np.tril_indices_from(attnmap_np)]\n",
    "                std_val = lower_tril_attnmap_np.std()\n",
    "                std_val_last_row = attnmap_np[-1].std()\n",
    "                print(attnmap_np.shape)\n",
    "\n",
    "                total_std.append(std_val)\n",
    "\n",
    "                n_zeros = (lower_tril_attnmap_np==0).sum()\n",
    "                ax_loc_2.hist(lower_tril_attnmap_np.flatten(), bins=100)\n",
    "                ax_loc_2.set_title(f'h-{amp_head} A_mat distr ({std_val:.3f} vs {std_val_last_row:.3f})')\n",
    "                # ax_loc_2.set_xlim(-0.01, 0.01)\n",
    "                \n",
    "                ax_loc_3.plot(attnmap_np[-1])\n",
    "                ax_loc_3.set_title(f'head {amidx} last row')\n",
    "\n",
    "                s_attmap_np = s_head2[amidx]\n",
    "                                    \n",
    "                lower_tril_s_attnmap_np = s_attmap_np[np.tril_indices_from(s_attmap_np)]\n",
    "                std_val_sa = lower_tril_s_attnmap_np.std()\n",
    "\n",
    "                n_zeros = (lower_tril_s_attnmap_np==0).sum()\n",
    "                ax_loc_4.hist(lower_tril_s_attnmap_np, bins=100)\n",
    "                # zero_map = np.zeros_like(s_attmap_np)\n",
    "                # zero_map[np.where(s_attmap_np==0)] = 1\n",
    "                # cm = ax_loc_4.imshow(zero_map)\n",
    "                # plt.colorbar(cm, ax=ax_loc_4, orientation='vertical', fraction=0.06, )\n",
    "\n",
    "\n",
    "                ax_loc_4.set_title(f'head {amidx} SA_mat distribution ({std_val_sa:.3f})')\n",
    "\n",
    "                \n",
    "                \n",
    "                ax_loc_5.plot(s_attmap_np[-1])\n",
    "                ax_loc_5.set_title(f'head {amidx} last row')\n",
    "\n",
    "\n",
    "                ax_loc_6.hist(s_attmap_np[-1], bins=32)\n",
    "                ax_loc_6.set_title(f'head {amidx} last row dist')\n",
    "\n",
    "\n",
    "                sim_map = sim_head2[amidx]\n",
    "                sim_map_tend = literal_eval(get_PE_tendency(sim_map))[4]\n",
    "                mat = ax_loc_7.imshow(sim_map, cmap='Reds', interpolation='nearest')\n",
    "                ax_loc_7.set_title(f'cosine_similarity ({sim_map_tend})')\n",
    "\n",
    "                total_scores.append(sim_map_tend)\n",
    "\n",
    "                plt.colorbar(mat, ax=ax_loc_7, orientation='vertical', fraction=0.06, )\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "            # fig, ax = plt.subplots(2, len(head2), figsize=(3.5*len(head2), 6))\n",
    "\n",
    "            # for hridx, head_rec in enumerate(all_records):\n",
    "\n",
    "            #     if len(head_rec) == 0: \n",
    "            #         continue\n",
    "\n",
    "            #     topk_records_idx = np.argsort(head_rec)[-bestk:]\n",
    "\n",
    "            #     best_maps = np.array([all_maps[hridx][i] for i in topk_records_idx])\n",
    "            #     best_map = best_maps.mean(axis=0)\n",
    "            #     best_score = np.mean([head_rec[i] for i in topk_records_idx])\n",
    "            #     best_idxcomb = [all_idxsets[hridx][i] for i in topk_records_idx]\n",
    "\n",
    "\n",
    "            #     ax_loc_0 = ax[0, hridx] if len(head2)>1 else ax[0]\n",
    "            #     ax_loc_1 = ax[1, hridx] if len(head2)>1 else ax[1]\n",
    "\n",
    "            #     mat = ax_loc_0.imshow(best_map, cmap='Reds', interpolation='nearest')\n",
    "            #     # best_PE_scores = get_PE_tendency(best_map)\n",
    "            #     ax_loc_0.set_title(f'best avg={best_score:.02f}')\n",
    "            #     plt.colorbar(mat, ax=ax_loc_0, orientation='vertical', fraction=0.06, )\n",
    "\n",
    "            #     tendmap_best = generate_tendency_map(best_map)\n",
    "            #     mat = ax_loc_1.imshow(tendmap_best, cmap='Reds', interpolation='nearest')\n",
    "            #     ax_loc_1.set_title(f'best ={best_idxcomb}')\n",
    "            #     plt.colorbar(mat, ax=ax_loc_1, orientation='vertical', fraction=0.06, )\n",
    "            \n",
    "            plot_name = f'bestk={bestk}_{input_name}_{imgname}_layer={level+1}'\n",
    "            # fig.suptitle(plot_name, fontsize=16, y=0.96)\n",
    "            if save_map:\n",
    "                os.makedirs(f'./saved_dist_heads_plots/', exist_ok=True)\n",
    "                fig.savefig(f'./saved_dist_heads_plots/{plot_name}.svg')\n",
    "            plt.show()\n",
    "            \n",
    "    print(np.mean(total_std))\n",
    "    if len(total_std) > 1:\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.scatter(total_std, total_scores)\n",
    "        r, p = pearsonr(total_std, total_scores, )\n",
    "        plt.title(f'Pearson Correlation={r:.3f}, p={p:.3f}')\n",
    "        plt.xlabel('attmap_std')\n",
    "        plt.ylabel('cos_adj_score')\n",
    "        plt.show()\n",
    "    \n",
    "    if len(total_scores)>6:\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.scatter(total_scores[:-6], next_att_scores[6:])\n",
    "        r, p = pearsonr(total_scores[:-6], next_att_scores[6:], )\n",
    "        plt.title(f'Pearson Correlation={r:.3f}, p={p:.3f}')\n",
    "        plt.xlabel('cos_adj_score')\n",
    "        plt.ylabel('att_adj_score')\n",
    "        plt.show()\n",
    "\n",
    "widgets.interact(plot_att, \n",
    "                 model_name=useful_name_list, \n",
    "                 layer_idx=(0, 11), \n",
    "                 plot_all=(0, 11), \n",
    "                 amp_head=(0, 5),\n",
    "                 metric_id = (0, 5),\n",
    "                 bestk=(1, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of $y_n$ and the distribution of the dot product $y_n \\cdot y_i$ for a sequence of iid normal vectors $x_0, x_1, \\ldots, x_n$ can be derived through the properties of normal distributions and linear transformations of these distributions.\n",
    "\n",
    "**Distribution of $y_n$**\n",
    "\n",
    "1. **Distribution of Each $x_i$**:\n",
    "   Assume each $x_i$ is a vector of independent and identically distributed (iid) standard normal random variables, say $x_i \\sim N(0, I)$, where $I$ is the identity matrix. This implies that each component of $x_i$ is $N(0,1)$.\n",
    "\n",
    "2. **Sum of Normal Vectors**:\n",
    "   The sum $S_k = x_0 + x_1 + \\ldots + x_k$ of iid normal vectors is also normally distributed. The mean of $S_k$ will be the sum of the means of each $x_i$, which is $0$, and the covariance matrix will be $(k+1)I$ because the covariance matrix of each $x_i$ is $I$.\n",
    "\n",
    "3. **Mean of Normal Vectors**:\n",
    "   $y_n = \\frac{1}{n+1} S_n = \\frac{1}{n+1}(x_0 + x_1 + \\ldots + x_n)$ is also normally distributed as a linear transformation of normal vectors. The mean of $y_n$ remains $0$, and the covariance matrix is scaled by $\\frac{1}{(n+1)^2}$ of $S_n$'s covariance, resulting in $\\frac{1}{n+1} I$.\n",
    "\n",
    "   Hence, $y_n \\sim N(0, \\frac{1}{n+1} I)$.\n",
    "\n",
    "**Distribution of $y_n \\cdot y_i$**\n",
    "\n",
    "1. **Vectors Involved**:\n",
    "   We know $y_i = \\frac{1}{i+1} S_i$ for $i \\leq n$. Thus, $y_i$ and $y_n$ are both linear transformations of sums of the normal vectors $x_0, \\ldots, x_i$ and $x_0, \\ldots, x_n$ respectively.\n",
    "\n",
    "2. **Dot Product**:\n",
    "   The dot product $y_n \\cdot y_i$ is a bilinear form of the Gaussian vectors. This product $y_n \\cdot y_i$ is a scalar random variable.\n",
    "\n",
    "   The expected value of $y_n \\cdot y_i$ can be computed considering $E[y_n \\cdot y_i] = \\frac{1}{(n+1)(i+1)} E[S_n \\cdot S_i]$. Since $S_i$ is a part of $S_n$ when $i \\leq n$, we have $E[S_n \\cdot S_i] = (i+1)$, hence $E[y_n \\cdot y_i] = \\frac{i+1}{(n+1)(i+1)} = \\frac{1}{n+1}$.\n",
    "\n",
    "3. **Distribution**:\n",
    "   Being a linear combination of Gaussian variables, $y_n \\cdot y_i$ is itself Gaussian. Its variance needs further calculation, usually involving expanding $(y_n \\cdot y_i)^2$ and using independence and variances of components of $y_n$ and $y_i$.\n",
    "\n",
    "In summary, $y_n$ is normally distributed with mean zero and covariance matrix $\\frac{1}{n+1} I$, and $y_n \\cdot y_i$ is a normally distributed scalar with mean $\\frac{1}{n+1}$ and a variance that needs further calculation involving their components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae766867f0b4ec4b78fb647f8e0d35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfMerger \n",
    "import cairosvg\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def convert_svg_to_pdf(svg_files, output_pdf):\n",
    "    temp_pdfs = []\n",
    "\n",
    "    # Convert each SVG to a temporary PDF\n",
    "    for svg_file in svg_files:\n",
    "        pdf_file = f\"{svg_file}.pdf\"\n",
    "        cairosvg.svg2pdf(url=svg_file, write_to=pdf_file)\n",
    "        temp_pdfs.append(pdf_file)\n",
    "\n",
    "    # Merge all temporary PDFs into a single PDF\n",
    "    merger = PdfMerger ()\n",
    "    for pdf in temp_pdfs:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    # Write out the final merged PDF\n",
    "    merger.write(output_pdf)\n",
    "    merger.close()\n",
    "\n",
    "    # Clean up temporary PDF files\n",
    "    for pdf in temp_pdfs:\n",
    "        os.remove(pdf)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "root_dir = './saved_dist_heads_plots'\n",
    "svg_files = sorted(glob.glob(root_dir + '/*.svg'))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "f_dict = {}\n",
    "for fpath in svg_files:\n",
    "    fname = fpath.split('/')[-1]\n",
    "    model_name = '_'.join(fname.split('_')[:-1])\n",
    "    if model_name not in f_dict:\n",
    "        f_dict[model_name] = []\n",
    "    f_dict[model_name].append(fpath)\n",
    "\n",
    "for model_name in tqdm(f_dict):\n",
    "    sorted_files = sorted(f_dict[model_name])\n",
    "    os.makedirs(f'{root_dir}_pdf', exist_ok=True)\n",
    "    output_pdf = f'{root_dir}_pdf/{model_name}.pdf'\n",
    "    convert_svg_to_pdf(sorted_files, output_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate matrix for different scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcb28f310134361acf276e27bdee7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='seq_len', max=4096, min=10), FloatSlider(value=0.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_attention(seq_len=20, mu_v=0, sig_v=1, mu_A=0, sig_A=1, shift=0, dimension=100, sim_func='cos', dist_type='normal', v_n=0)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# def causal_softmax(x):\n",
    "#     \"\"\"Compute causal softmax values for the vector 'x'.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / e_x.sum()\n",
    "font_path = './timr45w.ttf'  # Update this path\n",
    "from matplotlib import font_manager\n",
    "# Add the font to Matplotlib's font manager\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "plt.rcParams['axes.labelsize'] = 28  # Axis labels\n",
    "plt.rcParams['xtick.labelsize'] = 28  # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 28  # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] = 28  # Legend\n",
    "plt.rcParams['axes.titlesize'] = 28  # Title\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def plot_attention(\n",
    "    seq_len = 20,   # Number of vectors\n",
    "    mu_v = 0,\n",
    "    sig_v = 1,\n",
    "    mu_A = 0,\n",
    "    sig_A = 1,\n",
    "    shift = 0,\n",
    "    dimension = 100,  # Dimensionality of each vector\n",
    "    sim_func = 'cos',\n",
    "    dist_type = 'normal',\n",
    "    v_n = 0,\n",
    "):\n",
    "    v_n = min(v_n, seq_len-1)\n",
    "    sim_func_name = 'Dot Product' if sim_func == 'dot' else 'Cosine Similarity'\n",
    "    # Parameters\n",
    "\n",
    "\n",
    "    # Initialize e vectors from index 0 to n-1\n",
    "    # v_vectors = np.array([np.random.normal(mu_v, sig_v, dimension) for _ in range(seq_len)])\n",
    "    v_vectors = np.random.normal(mu_v, sig_v, (seq_len, dimension))\n",
    "\n",
    "    # Initialize A coefficients from index 0 to n-1 and apply causal softmax\n",
    "    # A = np.zeros((n, n))\n",
    "    # A = np.random.normal(0, np.sqrt(n), (n, n))\n",
    "\n",
    "\n",
    "    if dist_type == 'normal':\n",
    "        A = np.random.normal(mu_A, sig_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'gemma':\n",
    "        A = np.random.gamma(1, sig_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'uniform':\n",
    "        A = np.random.uniform(mu_A, sig_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'possion':\n",
    "        A = np.random.poisson(mu_A, (seq_len, seq_len))\n",
    "    elif dist_type == 'chi':\n",
    "        A = np.random.chisquare()\n",
    "\n",
    "    # A = np.random.normal(10, 1, (n, n))\n",
    "    # A = np.random.gamma(0, 0.1, (n, n))\n",
    "    # A = np.random.chisquare(0.001, (n, n))\n",
    "    # A = np.random.uniform(0, 0.01, (n, n))\n",
    "\n",
    "    A = A * (1.0 / math.sqrt(v_vectors.shape[-1]))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    _A = np.tril(A, 0)\n",
    "    axes[0].hist(_A[np.where(_A!=0)].flatten(), bins=200)\n",
    "    _A_std_row_wise = _A[np.where(_A!=0)].flatten().std(axis=-1).mean()\n",
    "    axes[0].set_title(f'A distribution before softmax (std_row-wise: {_A_std_row_wise:.3f})')\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        # A[i, :i+1] = softmax(A[i, :i+1]) + 1 # amazing : )\n",
    "        A[i, :i+1] = softmax(A[i, :i+1]) + shift\n",
    "\n",
    "\n",
    "    A = np.tril(A, 0)\n",
    "\n",
    "    non_zero_A = A[np.where(A!=0)].flatten()\n",
    "    len_A = len(non_zero_A)\n",
    "    sorted_non_zero_A = sorted(non_zero_A)\n",
    "    axes[1].hist(non_zero_A, bins=200)\n",
    "    axes[1].set_title(f'A distribution after softmax (Abs_Avg = {np.abs(sorted_non_zero_A)[:len_A//4].mean():.06f})')\n",
    "\n",
    "    axes[2].plot(A[-1])\n",
    "    axes[2].set_title(f'The last row')\n",
    "\n",
    "    plt.show()\n",
    "    # Compute y vectors using matrix multiplication with a lower triangular matrix of A\n",
    "    y_vectors = A @ v_vectors\n",
    "    norms = np.linalg.norm(y_vectors, axis=1)\n",
    "    print(y_vectors.shape, norms.shape)\n",
    "\n",
    "    # plt.figure(figsize=(6, 5))\n",
    "    fig, axes = plt.subplots(1,4, figsize=(28, 5))\n",
    "    axes[0].hist(y_vectors[v_n], bins=200)\n",
    "    axes[0].set_title(f'Output Vector {v_n+1}, norm={np.linalg.norm(norms[v_n]):.3f}')\n",
    "    axes[1].hist(y_vectors[-1], bins=200)\n",
    "    axes[1].set_title(f'Output Vector {len(y_vectors)}, norm={np.linalg.norm(norms[-1]):.3f}')\n",
    "\n",
    "\n",
    "    # Compute cosine similarities using vector operations\n",
    "    # cosine_similarities = np.dot(y_vectors, y_vectors.T) / np.outer(norms, norms)\n",
    "    cosine_similarities = np.dot(y_vectors, y_vectors.T) \n",
    "    divisor = 1 if sim_func=='dot' else np.outer(norms, norms)\n",
    "    if sim_func == 'dot':\n",
    "        cosine_similarities = cosine_similarities / divisor\n",
    "    else:\n",
    "        cosine_similarities = cosine_similarity(y_vectors, y_vectors)\n",
    "\n",
    "\n",
    "    axes[2].plot(cosine_similarities[-1])\n",
    "    axes[2].set_title(f'Last Vector {sim_func_name}')\n",
    "    axes[3].plot(np.outer(norms, norms)[-1])\n",
    "    axes[3].set_title(f'Last Norm Divisor')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Extracting upper triangular part of cosine similarities matrix, excluding diagonal\n",
    "    results = np.zeros((seq_len, seq_len))\n",
    "    for i in range(seq_len):\n",
    "        for j in range(i + 1, seq_len):\n",
    "            results[i, j] = cosine_similarities[i, j]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(5.*8, 4))\n",
    "    v_vectors = np.random.normal(mu_v, sig_v, (seq_len, dimension))\n",
    "\n",
    "    prob = [1, 0.83, 0.72, 0.59, 0.40, 0.25, 0.1, 0.000]\n",
    "\n",
    "\n",
    "    A = np.random.normal(mu_A, 0.5, (seq_len, seq_len))\n",
    "    A = A * (1.0 / math.sqrt(v_vectors.shape[-1]))\n",
    "    for j in range(seq_len):\n",
    "        # A[i, :i+1] = softmax(A[i, :i+1]) + 1 # amazing : )\n",
    "        A[j, :j+1] = softmax(A[j, :j+1]) + shift\n",
    "    A = np.tril(A, 0)\n",
    "    y_vectors = A @ v_vectors\n",
    "    original_cosine_similarities = cosine_similarity(y_vectors, y_vectors)\n",
    "    for i in range(8):\n",
    "\n",
    "        cosine_similarities = original_cosine_similarities.copy()\n",
    "        \n",
    "        for r in range(seq_len):\n",
    "            idx_to_shuffle = sorted(np.random.permutation(np.arange(r+1))[:int((1-prob[i]) * (r+1))])\n",
    "            # shuffled_idx = np.random.permutation(idx_to_shuffle)\n",
    "            shuffled_idx = idx_to_shuffle[::-1]\n",
    "            cosine_similarities[r, idx_to_shuffle] = cosine_similarities[r, shuffled_idx]\n",
    "            cosine_similarities[idx_to_shuffle, r] = cosine_similarities[shuffled_idx, r]\n",
    "        # # copy the matrix symmectrically over the diagonal\n",
    "        # for r in range(seq_len):\n",
    "        #     for c in range(r, seq_len):\n",
    "        #         cosine_similarities[r, c] = cosine_similarities[c, r]\n",
    "\n",
    "\n",
    "        tend = get_PE_tendency(cosine_similarities, as_list=True)[6]\n",
    "\n",
    "        cm = axes[i].imshow(cosine_similarities, cmap='Reds')\n",
    "        # cm = axes[1].imshow(cosine_similarities, )1````\n",
    "        axes[i].set_title(f\"Score={tend}\")\n",
    "        plt.colorbar(cm, ax=axes[i], orientation='vertical', fraction=0.06, )\n",
    "    # save to pdf\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(left=0.03, right=0.975, top=0.9, bottom=0.1, hspace=0.25)\n",
    "    fig.savefig(f'spectrum.pdf', format='pdf') \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "interact(plot_attention, \n",
    "         seq_len=(10, 4096), \n",
    "         mu_v = (-10, 10, 0.01), \n",
    "         sig_v = (0, 2, 0.0001),\n",
    "         mu_A = (-20, 20, 0.01), \n",
    "         sig_A = (0, 10, 0.0001),  \n",
    "         shift=(-2, 2, 0.001), \n",
    "         dimension=(4, 384),\n",
    "         sim_func = ['cos', 'dot'],\n",
    "         dist_type = ['normal', 'gemma', 'uniform', 'possion'],\n",
    "         v_n = (0, 2048)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1], [1, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r = 2\n",
    "\n",
    "idx_to_shuffle = sorted(np.random.permutation(np.arange(r))[:int((1-0.00) * (r+1))])\n",
    "idx_to_shuffle, idx_to_shuffle[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class RelativePositionBias(nn.Module):\n",
    "    def __init__(self, bidirectional=True, num_buckets=32, max_distance=128, n_heads=2):\n",
    "        super(RelativePositionBias, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_buckets = num_buckets\n",
    "        self.max_distance = max_distance\n",
    "        self.n_heads = n_heads\n",
    "        self.relative_attention_bias = nn.Embedding(self.num_buckets, self.n_heads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_position_bucket(relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        \"\"\"\n",
    "        Adapted from Mesh Tensorflow:\n",
    "        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n",
    "        Translate relative position to a bucket number for relative attention.\n",
    "        The relative position is defined as memory_position - query_position, i.e.\n",
    "        the distance in tokens from the attending position to the attended-to\n",
    "        position.  If bidirectional=False, then positive relative positions are\n",
    "        invalid.\n",
    "        We use smaller buckets for small absolute relative_position and larger buckets\n",
    "        for larger absolute relative_positions.  All relative positions >=max_distance\n",
    "        map to the same bucket.  All relative positions <=-max_distance map to the\n",
    "        same bucket.  This should allow for more graceful generalization to longer\n",
    "        sequences than the model has been trained on.\n",
    "        Args:\n",
    "            relative_position: an int32 Tensor\n",
    "            bidirectional: a boolean - whether the attention is bidirectional\n",
    "            num_buckets: an integer\n",
    "            max_distance: an integer\n",
    "        Returns:\n",
    "            a Tensor with the same shape as relative_position, containing int32\n",
    "            values in the range [0, num_buckets)\n",
    "        \"\"\"\n",
    "        ret = 0\n",
    "        n = -relative_position\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            ret += (n < 0).to(torch.long) * num_buckets  # mtf.to_int32(mtf.less(n, 0)) * num_buckets\n",
    "            n = torch.abs(n)\n",
    "        else:\n",
    "            n = torch.max(n, torch.zeros_like(n))\n",
    "        # now n is in the range [0, inf)\n",
    "\n",
    "        # half of the buckets are for exact increments in positions\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = n < max_exact\n",
    "\n",
    "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "        val_if_large = max_exact + (\n",
    "            torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)\n",
    "        ).to(torch.long)\n",
    "        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n",
    "\n",
    "        ret += torch.where(is_small, n, val_if_large)\n",
    "        return ret\n",
    "\n",
    "    def compute_bias(self, qlen, klen):\n",
    "        \"\"\" Compute binned relative position bias \"\"\"\n",
    "        context_position = torch.arange(qlen, dtype=torch.long,\n",
    "                                        device=self.relative_attention_bias.weight.device)[:, None]\n",
    "        memory_position = torch.arange(klen, dtype=torch.long,\n",
    "                                       device=self.relative_attention_bias.weight.device)[None, :]\n",
    "        relative_position = memory_position - context_position  # shape (qlen, klen)\n",
    "        \"\"\"\n",
    "                   k\n",
    "             0   1   2   3\n",
    "        q   -1   0   1   2\n",
    "            -2  -1   0   1\n",
    "            -3  -2  -1   0\n",
    "        \"\"\"\n",
    "        rp_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (qlen, klen)\n",
    "            bidirectional=self.bidirectional,\n",
    "            num_buckets=self.num_buckets,\n",
    "        )\n",
    "        rp_bucket = rp_bucket.to(self.relative_attention_bias.weight.device)\n",
    "        values = self.relative_attention_bias(rp_bucket)  # shape (qlen, klen, num_heads)\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(0)  # shape (1, num_heads, qlen, klen)\n",
    "        return values\n",
    "\n",
    "    def forward(self, qlen, klen):\n",
    "        return self.compute_bias(qlen, klen)  # shape (1, num_heads, qlen, klen)\n",
    "\n",
    "\n",
    "rb = RelativePositionBias(False, num_buckets=32, max_distance=20, n_heads=1)\n",
    "print(rb(256,256).shape)\n",
    "plt.imshow(rb(256,256)[0,0].detach())\n",
    "plt.colorbar( orientation='vertical', fraction=0.06, pad=0.04,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositionBias(nn.Module):\n",
    "    def __init__(self, bidirectional=True, num_buckets=32, max_distance=128, n_heads=2):\n",
    "        super(RelativePositionBias, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_buckets = num_buckets\n",
    "        self.max_distance = max_distance\n",
    "        self.n_heads = n_heads\n",
    "        self.relative_attention_bias = nn.Embedding(self.num_buckets, self.n_heads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_position_bucket(relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        \"\"\"\n",
    "        Adapted from Mesh Tensorflow:\n",
    "        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n",
    "\n",
    "        Translate relative position to a bucket number for relative attention. The relative position is defined as\n",
    "        memory_position - query_position, i.e. the distance in tokens from the attending position to the attended-to\n",
    "        position. If bidirectional=False, then positive relative positions are invalid. We use smaller buckets for\n",
    "        small absolute relative_position and larger buckets for larger absolute relative_positions. All relative\n",
    "        positions >=max_distance map to the same bucket. All relative positions <=-max_distance map to the same bucket.\n",
    "        This should allow for more graceful generalization to longer sequences than the model has been trained on\n",
    "\n",
    "        Args:\n",
    "            relative_position: an int32 Tensor\n",
    "            bidirectional: a boolean - whether the attention is bidirectional\n",
    "            num_buckets: an integer\n",
    "            max_distance: an integer\n",
    "\n",
    "        Returns:\n",
    "            a Tensor with the same shape as relative_position, containing int32 values in the range [0, num_buckets)\n",
    "        \"\"\"\n",
    "        relative_buckets = 0\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            relative_buckets += (relative_position > 0).to(torch.long) * num_buckets\n",
    "            relative_position = torch.abs(relative_position)\n",
    "        else:\n",
    "            relative_position = -torch.min(relative_position, torch.zeros_like(relative_position))\n",
    "        # now relative_position is in the range [0, inf)\n",
    "\n",
    "        # half of the buckets are for exact increments in positions\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = relative_position < max_exact\n",
    "\n",
    "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "        relative_postion_if_large = max_exact + (\n",
    "            torch.log(relative_position.float() / max_exact)\n",
    "            / math.log(max_distance / max_exact)\n",
    "            * (num_buckets - max_exact)\n",
    "        ).to(torch.long)\n",
    "        relative_postion_if_large = torch.min(\n",
    "            relative_postion_if_large, torch.full_like(relative_postion_if_large, num_buckets - 1)\n",
    "        )\n",
    "\n",
    "        relative_buckets += torch.where(is_small, relative_position, relative_postion_if_large)\n",
    "        return relative_buckets\n",
    "\n",
    "    def compute_bias(self, query_length, key_length):\n",
    "        \"\"\"Compute binned relative position bias\"\"\"\n",
    "        context_position = torch.arange(\n",
    "            query_length, dtype=torch.long, device=self.relative_attention_bias.weight.device\n",
    "        )[:, None]\n",
    "        memory_position = torch.arange(\n",
    "            key_length, dtype=torch.long, device=self.relative_attention_bias.weight.device\n",
    "        )[None, :]\n",
    "        relative_position = memory_position - context_position  # shape (query_length, key_length)\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=self.bidirectional,\n",
    "            num_buckets=self.num_buckets,\n",
    "        )\n",
    "        values = self.relative_attention_bias(relative_position_bucket)  # shape (query_length, key_length, num_heads)\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(0)  # shape (1, num_heads, query_length, key_length)\n",
    "        return values\n",
    "\n",
    "    def forward(self, qlen, klen):\n",
    "        return self.compute_bias(qlen, klen)  # shape (1, num_heads, qlen, klen)\n",
    "    \n",
    "rb = RelativePositionBias(False, num_buckets=32, max_distance=20, n_heads=1)\n",
    "print(rb(256,256).shape)\n",
    "plt.imshow(rb(256,256)[0,0].detach())\n",
    "plt.colorbar( orientation='vertical', fraction=0.06, pad=0.04,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "T = 10\n",
    "\n",
    "attn_mask = torch.ones(1, 1, T, T, dtype=torch.bool)\n",
    "# attn_mask = rb(T,T).detach().cpu()\n",
    "temp_mask = torch.ones(1, 1, T, T, dtype=torch.bool).tril(diagonal=0)\n",
    "diag_mask = torch.diag_embed(torch.ones(T, dtype=torch.bool)).unsqueeze(0).unsqueeze(0)\n",
    "plt.imshow(temp_mask[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(diag_mask[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(attn_mask[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# attn_mask = attn_mask.masked_fill(temp_mask == 0, float('-inf'))\n",
    "attn_mask = attn_mask & temp_mask\n",
    "\n",
    "plt.imshow(attn_mask[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "attn_mask = attn_mask | diag_mask\n",
    "\n",
    "plt.imshow(attn_mask[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight distributuion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kqv_weights = model.transformer.h[0].attn.c_attn.weight.detach().cpu().numpy()\n",
    "q_weights = kqv_weights[:kqv_weights.shape[0]//3]\n",
    "k_weights = kqv_weights[kqv_weights.shape[0]//3:2*kqv_weights.shape[0]//3]\n",
    "v_weights = kqv_weights[2*kqv_weights.shape[0]//3:]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(k_weights.flatten(), bins=100)\n",
    "plt.show()\n",
    "plt.hist(v_weights.flatten(), bins=100)\n",
    "plt.show()\n",
    "plt.hist(q_weights.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs, dists = GPT_nope.create_equal_distancing_vecotrs(12, 384,)\n",
    "dists[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvecs = vecs@k_weights\n",
    "kdists = kvecs@kvecs.T\n",
    "vvecs = vecs@v_weights\n",
    "vdists = vvecs@vvecs.T\n",
    "qvecs = vecs@q_weights\n",
    "qdists = qvecs@qvecs.T\n",
    "# subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axs[0].imshow(kdists, cmap='coolwarm', interpolation='nearest')\n",
    "axs[0].set_title('K')\n",
    "axs[1].imshow(vdists, cmap='coolwarm', interpolation='nearest')\n",
    "axs[1].set_title('V')\n",
    "axs[2].imshow(qdists, cmap='coolwarm', interpolation='nearest')\n",
    "axs[2].set_title('Q')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = kdists.shape[0]\n",
    "bias = torch.tril(torch.ones(T, T)).numpy()\n",
    "kvmap = qvecs@kvecs.T\n",
    "kvmap_causal = kvmap.copy()\n",
    "kvmap_causal[bias==0] = 0\n",
    "\n",
    "plt.imshow(kvmap_causal, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvmap_softmax = kvmap.copy()\n",
    "kvmap_softmax[bias==0] = -np.inf\n",
    "kvmap_softmax = np.exp(kvmap_softmax)\n",
    "kvmap_softmax /= kvmap_softmax.sum(axis=1, keepdims=True)\n",
    "plt.imshow(kvmap_softmax, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "for hidx in range(kvmap_softmax.shape[0]):\n",
    "    for j in range(kvmap_softmax.shape[1]):\n",
    "        plt.text(j, hidx, f'{kvmap_softmax[hidx, j]:.02f}', ha='center', va='center', color='black', fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_out = kvmap_softmax@vvecs\n",
    "self_dot_prod = att_out@att_out.T\n",
    "plt.imshow(self_dot_prod, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THEORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, simplify\n",
    "\n",
    "# Define symbols\n",
    "m, seq_len = symbols('m n')\n",
    "\n",
    "# Given values for dot products\n",
    "v1_v1 = v2_v2 = v3_v3 = seq_len\n",
    "v1_v2 = v1_v3 = v2_v3 = m\n",
    "\n",
    "# z.x\n",
    "zx = (1/4)*v1_v1 + (1/4)*v1_v2 + (1/2)*v1_v3\n",
    "# z.y\n",
    "zy = (1/4)*(1/3)*v1_v1 + (1/4)*(2/3)*v1_v2 + (1/4)*(1/3)*v1_v2 + (1/4)*(2/3)*v2_v2 + (1/2)*(1/3)*v1_v3 + (1/2)*(2/3)*v2_v3\n",
    "# z.zz\n",
    "zz = (1/4)**2*v1_v1 + 2*(1/4)**2*v1_v2 + (1/2)**2*v1_v3 + (1/4)**2*v2_v2 + 2*(1/4)*(1/2)*v2_v3 + (1/2)**2*v3_v3\n",
    "\n",
    "# Simplify expressions\n",
    "zx_simplified = simplify(zx)\n",
    "zy_simplified = simplify(zy)\n",
    "zz_simplified = simplify(zz)\n",
    "\n",
    "zx_simplified, zy_simplified, zz_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import exp, simplify\n",
    "\n",
    "# Define e as the base of the natural logarithm\n",
    "# e = exp(1)\n",
    "e = 2.718281828459045\n",
    "\n",
    "# Calculate a1, a2, b1, b2, b3\n",
    "a1 = e**(1/2) / (e**(1/2) + e**1)\n",
    "a2 = 1 - a1\n",
    "b1 = b2 = e**(1/2) / (e**(1/2) + e**(1/2) + e**1)\n",
    "b3 = 1 - b1 - b2\n",
    "\n",
    "# Define symbols\n",
    "m, seq_len = symbols('m n')\n",
    "\n",
    "# Given values for dot products\n",
    "v1_v1 = v2_v2 = v3_v3 = seq_len\n",
    "v1_v2 = v1_v3 = v2_v3 = m\n",
    "\n",
    "# z.x\n",
    "zx = b1*v1_v1 + b2*v1_v2 + b3*v1_v3\n",
    "# z.y\n",
    "zy = (b1*a1 + b2*a2)*v1_v1 + (b1*a2)*v1_v2 + (b2*a1)*v1_v2 + (b2*a2)*v2_v2 + b3*a1*v1_v3 + b3*a2*v2_v3\n",
    "# z.z\n",
    "zz = (b1**2 + b2**2)*v1_v1 + 2*(b1*b2)*v1_v2 + 2*(b1*b3 + b2*b3)*v1_v3 + b3**2*v3_v3 + (b2**2)*v2_v2 + 2*(b2*b3)*v2_v3\n",
    "\n",
    "# Simplify expressions\n",
    "a1_val, a2_val, b1_val, b2_val, b3_val = [simplify(val) for val in [a1, a2, b1, b2, b3]]\n",
    "zx_simplified = simplify(zx.subs({v1_v1: seq_len, v1_v2: m, v1_v3: m}))\n",
    "zy_simplified = simplify(zy.subs({v1_v1: seq_len, v1_v2: m, v1_v3: m, v2_v2: seq_len, v2_v3: m}))\n",
    "zz_simplified = simplify(zz.subs({v1_v1: seq_len, v1_v2: m, v1_v3: m, v2_v2: seq_len, v2_v3: m, v3_v3: seq_len}))\n",
    "\n",
    "a1_val, a2_val, b1_val, b2_val, b3_val, zx_simplified, zy_simplified, zz_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_value = 1\n",
    "n_value = 2  # Example values where n > m\n",
    "\n",
    "# Evaluate zx, zy, zz with substituted values of m and n\n",
    "zx_value = zx_simplified.subs({m: m_value, seq_len: n_value,})\n",
    "zy_value = zy_simplified.subs({m: m_value, seq_len: n_value,})\n",
    "zz_value = zz_simplified.subs({m: m_value, seq_len: n_value,})\n",
    "\n",
    "zx_value, zy_value, zz_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA visualizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"$\" + f\"{i}\"*3 + '+' + f\"{i}\"*3 + '='\n",
    "import glob\n",
    "from IPython.utils import io\n",
    "\n",
    "\n",
    "input_act1_list = []\n",
    "# for config_dir, model_config_fold in exp_list:\n",
    "#   with open(f'{config_dir}/{model_config_fold}/config.yaml') as f:\n",
    "#     config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "#   ckpt = f\"{config_dir}/ckpt_10000_final.pt\"\n",
    "#   model = load_checkpoint(ckpt, GPTConfig_nope, GPT_nope, device='cuda')\n",
    "\n",
    "for config_dir, model_config_fold in exp_list:\n",
    "    glob_dir = config_dir.replace('[', '*').replace(']', '*')\n",
    "    yaml_path = glob.glob(f'{glob_dir}/**/config.yaml')[0]\n",
    "    config_dir = '/'.join(yaml_path.split('/')[:-2])\n",
    "    with open(yaml_path) as f:\n",
    "        config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    # ckpt = glob.glob(f\"{config_dir}/ckpt_**_acc.pt\", recursive=True)[0]\n",
    "    # ckpt = glob.glob(f'{glob_dir}/ckpt_**_acc.pt')[0]\n",
    "    ckpt = glob.glob(f'{glob_dir}/ckpt_**.pt')[0]\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        # model, gptconfig = load_checkpoint(ckpt, GPTConfig_nope, GPT_nope, device='cuda', return_config=True)\n",
    "        model, gptconfig = load_checkpoint(\n",
    "            ckpt, GPTConfig_nope, GPT_nope, device='cuda', return_config=True)\n",
    "        # gptconfig.use_pe = 'sin'\n",
    "        # model = GPT_nope(gptconfig)\n",
    "\n",
    "    cur_input_act1_list = []\n",
    "    # for i in range(0, 3):\n",
    "    # model.transformer.h[0].permute = False\n",
    "    # prompts = [\n",
    "    #   f\"${823}\" + '+' + f\"{8}\"*3 + '=',\n",
    "    #   f\"${238}\" + '+' + f\"{8}\"*3 + '='\n",
    "    # ]\n",
    "    zs = np.zeros(12).astype(np.int64)\n",
    "    n_1s = 3\n",
    "    zs[np.random.permutation(12)[:n_1s]] = 1\n",
    "    str_zs = ''.join(map(str, zs))\n",
    "\n",
    "    prompts = [\n",
    "        # f'\\nparity({str_zs})=',\n",
    "        # '\\nparity(100101010000)='\n",
    "        # '\\nparity(010101000101)='\n",
    "        # 'parity(000010101001)=',\n",
    "        # '    $331+=',\n",
    "        'paridy(110001101010)=',\n",
    "        # '123+456'\n",
    "    ]\n",
    "    # prompts = [\n",
    "    #   f\"${623}\" + '+' + f\"{5}\"*3 + '=',\n",
    "    #   f\"${632}\" + '+' + f\"{5}\"*3 + '='\n",
    "    # ]\n",
    "    for hidx in range(0, 1):  # try 10 batches\n",
    "\n",
    "        # prompt = \"$\" + f\"{i}\"*3 + f\"{i}\"*6\n",
    "        # prompt = \"$\" + f\"{i}\"*3 + '+' + f\"{i}\"*3 + '='\n",
    "        # prompt = \"$\" + f\"{i}\"*3 + '+' + f\"{i}\"*3 + '='\n",
    "        prompt = prompts[hidx]\n",
    "\n",
    "        activation = {}\n",
    "\n",
    "        def getActivation(name):\n",
    "            # the hook signature\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        # register forward hooks on the layers of choice\n",
    "        h1 = model.transformer.h[1].register_forward_hook(\n",
    "            getActivation('layer_1'))\n",
    "        h2 = model.transformer.ln_f.register_forward_hook(\n",
    "            getActivation('x_out'))\n",
    "        # out_text = generate_output(model, prompt, max_new_tokens=5)\n",
    "        out_text = generate_output(model, prompt, max_new_tokens=4,)\n",
    "\n",
    "        h1.remove()\n",
    "        h2.remove()\n",
    "        model_name = config_dir.split('/')[-1]\n",
    "        print(model_name)\n",
    "        PCA_analysis(prompt, activation['x_out'][0], out_text, config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paridy(x):\n",
    "    x_trunc = str(x)\n",
    "    start_1 = x_trunc.find('1')\n",
    "    end_1 = x_trunc.rfind('1')\n",
    "    y_trunc = x_trunc[start_1:end_1+1].count('0') % 2\n",
    "    return y_trunc\n",
    "\n",
    "\n",
    "paridy(110001101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import main_thread\n",
    "import main_utils\n",
    "# start_train = None\n",
    "reverse_ab = False\n",
    "reverse_c = True\n",
    "zero_pad = False\n",
    "algo_reason = False\n",
    "add_space = False\n",
    "config['causal_training'] = True\n",
    "\n",
    "\n",
    "\n",
    "config['start'] = start\n",
    "\n",
    "model, gptconfig = load_checkpoint(\n",
    "                \"./outputs_permute/add3_remove_8_nope_residual_exp/add3_remove_8_sd240_T2405280721_nope_lwpTrue_pmremove00000/ckpt_10000_acc_5000.pt\",\n",
    "                GPTConfig_nope,\n",
    "                GPT_nope,\n",
    "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                return_config=True,\n",
    "                init=False,\n",
    "                init_additional_config={},\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "main_utils.evaluate_addition_batch(config, model, ctx, encode, decode, verbose=True, num_digit=num_digit, zero_pad=zero_pad,\n",
    "                                   reverse_ab=reverse_ab, reverse_c=reverse_c, algo_reason=algo_reason,\n",
    "                                   binary=binary, data_type=data_type, operator=operator, data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interesting: for a causal model with pe, with or without \"\\n\" makes a 180 degree difference in outcome !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original_model_pe_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.transformer.wpe.weight.cpu().detach().numpy()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "x = model.transformer.wpe.weight.cpu().detach().numpy()\n",
    "# select sample maybe from test set\n",
    "# but if, different digits seems to be encoded the same way, than it has a patter\n",
    "pca = PCA(n_components=2)\n",
    "new_x = pca.fit_transform(x)\n",
    "new_x = new_x[::16]\n",
    "for text, pt in zip(range(len(new_x)), new_x, ):\n",
    "    plt.scatter(pt[0], pt[1], label=text)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(new_x)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import U\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_measure = lambda u1, u2: np.dot(u1, u2.T)\n",
    "# sim_measure = cosine_similarity\n",
    "\n",
    "\n",
    "def standardize_rows(matrix):\n",
    "    \"\"\"Standardize each row of the matrix.\"\"\"\n",
    "    mean = matrix.mean(axis=1, keepdims=True)\n",
    "    std = matrix.std(axis=1, keepdims=True)\n",
    "    return (matrix - mean) / std\n",
    "\n",
    "\n",
    "def plot_corr_mat(corr_mat, vec_dim, is_corr=True, absval=True):\n",
    "\n",
    "    show_text = False if not is_corr else True\n",
    "\n",
    "    # Create a heatmap of corr_mat\n",
    "    plt.figure(figsize=(6, 5), dpi=120)\n",
    "    # plt.imshow(corr_mat, cmap='seismic', interpolation='nearest')\n",
    "    plt.imshow(corr_mat, cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "\n",
    "    extra_text = \"Absolute\" if is_corr else \"\"\n",
    "    plot_type = f\"{extra_text} Correlation Coefficient\" if is_corr else \"Dot Product\"\n",
    "\n",
    "    plt.colorbar(\n",
    "        label=plot_type,\n",
    "        # fraction=0.01,\n",
    "        # pad=0.04,\n",
    "    )\n",
    "    if show_text:\n",
    "        for i in range(0, len(corr_mat), vec_dim):\n",
    "            for j in range(0, len(corr_mat), vec_dim):\n",
    "                plt.text(\n",
    "                    j + vec_dim // 2,\n",
    "                    i + vec_dim // 2,\n",
    "                    f\"{corr_mat[i:i+vec_dim, j:j+vec_dim].sum():.02f}\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"black\",\n",
    "                )\n",
    "\n",
    "\n",
    "level_corr_mat_accum = []\n",
    "corr_mat = None\n",
    "u1, u2, u1_name, u2_name = None, None, None, None\n",
    "\n",
    "task_name = \"mod_\"\n",
    "folder_name = f\"corr_{task_name}\" if not equal_distancing_exp else f\"dot_{task_name}\"\n",
    "folder_name += \"_trained\" if not model_init else \"_init\"\n",
    "\n",
    "\n",
    "@widgets.interact(\n",
    "    idx1=(0, len(input_act1_list) - 1), idx2=(0, len(input_act1_list) - 1), level=(0, 5)\n",
    ")\n",
    "def get_corr(\n",
    "    idx1,\n",
    "    level=0,\n",
    "    save=False,\n",
    "    absval=True,\n",
    "    save_all=False,\n",
    "    accumulate_all=False,\n",
    "    is_rand_init=False,\n",
    "    subplot_layers=False,\n",
    "):\n",
    "    global corr_mat\n",
    "    global u1, u2, u1_name, u2_name\n",
    "    rand_state = \"init_\" if is_rand_init else \"\"\n",
    "    if not (save_all or accumulate_all):\n",
    "        if not subplot_layers:\n",
    "            idx2 = idx1\n",
    "            input_act1_list = all_level_input_act_list[level]\n",
    "            u1, u2 = input_act1_list[idx1], input_act1_list[idx2]\n",
    "\n",
    "            u1 = u1.T\n",
    "            u2 = u2.T\n",
    "            print(exp_list[idx1][0].split(\"sd\")[-1], exp_list[idx2][0].split(\"sd\")[-1])\n",
    "            print(u2.shape)\n",
    "\n",
    "            is_corr = False\n",
    "            if u2.shape[1] != 1:\n",
    "                # Standardize each row of u1 and u2\n",
    "                u1_standardized = standardize_rows(u1)\n",
    "                u2_standardized = standardize_rows(u2)\n",
    "                # u1_standardized = u1\n",
    "                # u2_standardized = u2\n",
    "\n",
    "                # Compute the correlation matrix\n",
    "                corr_mat = np.dot(u1_standardized, u2_standardized.T) / (u1.shape[1])\n",
    "            else:\n",
    "                u1 = u1.reshape(-1, 384)\n",
    "                u2 = u2.reshape(-1, 384)\n",
    "                # corr_mat = np.dot(u1, u2.T)\n",
    "                corr_mat = sim_measure(u1, u2)\n",
    "\n",
    "            if absval:\n",
    "                corr_mat = np.abs(corr_mat)\n",
    "            else:\n",
    "                pass\n",
    "            vec_dim = corr_mat.shape[0] // 8\n",
    "            total_sum = np.abs(corr_mat).sum()\n",
    "            block_sum = 0\n",
    "            for i in range(0, len(corr_mat), vec_dim):\n",
    "                block_sum += np.abs(corr_mat[i : i + vec_dim, i : i + vec_dim]).sum()\n",
    "            ratio = block_sum / (total_sum - block_sum)\n",
    "\n",
    "            plot_corr_mat(corr_mat, vec_dim, is_corr=is_corr, absval=absval)\n",
    "\n",
    "            nope2 = \"nope_\" if \"nope\" in exp_list[idx1][1] else \"\"\n",
    "            u2_name = \"_\".join(exp_list[idx2][1].split(\"_\")[2:])\n",
    "            u2_name = (\n",
    "                nope2 + u2_name.split(\"_\")[-1] + \"_\" + \"_\".join(u2_name.split(\"_\")[:-1])\n",
    "            )\n",
    "\n",
    "            if save:\n",
    "                os.makedirs(f\"./saved_plots_{folder_name}/\", exist_ok=True)\n",
    "                plt.savefig(\n",
    "                    f\"./saved_plots_{folder_name}/{task_name+folder_name}_{rand_state}_{u2_name}_layer{level}_{ratio:.03f}_{abs}.svg\"\n",
    "                )\n",
    "\n",
    "            # close img\n",
    "            # plt.close()\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig, axs = plt.subplots(\n",
    "                1, 6, figsize=(36, 5)\n",
    "            )  # 6 subplots in a row, adjust size as needed\n",
    "\n",
    "            global_min, global_max = float(\"inf\"), float(\"-inf\")\n",
    "            corr_mat_list = []\n",
    "            for level in range(6):\n",
    "                idx2 = idx1\n",
    "                input_act1_list = all_level_input_act_list[level]\n",
    "                u1, u2 = input_act1_list[idx1], input_act1_list[idx2]\n",
    "\n",
    "                u1 = u1.T\n",
    "                u2 = u2.T\n",
    "\n",
    "                if u2.shape[1] != 1:\n",
    "                    u1_standardized = standardize_rows(u1)\n",
    "                    u2_standardized = standardize_rows(u2)\n",
    "                    corr_mat = np.dot(u1_standardized, u2_standardized.T) / (\n",
    "                        u1.shape[1]\n",
    "                    )\n",
    "                else:\n",
    "                    u1 = u1.reshape(-1, 384)\n",
    "                    u2 = u2.reshape(-1, 384)\n",
    "                    # corr_mat = np.dot(u1, u2.T)\n",
    "                    corr_mat = sim_measure(u1, u2)\n",
    "\n",
    "                if absval:\n",
    "                    corr_mat = np.abs(corr_mat)\n",
    "                corr_mat_list.append(corr_mat)\n",
    "\n",
    "                global_min = min(global_min, corr_mat.min())\n",
    "                global_max = max(global_max, corr_mat.max())\n",
    "\n",
    "            for level in range(6):\n",
    "\n",
    "                corr_mat = corr_mat_list[level]\n",
    "\n",
    "                # vec_dim = 384\n",
    "                vec_dim = corr_mat.shape[0] // fixed_length\n",
    "\n",
    "                total_sum = np.abs(corr_mat).sum()\n",
    "                block_sum = 0\n",
    "                for i in range(0, len(corr_mat), vec_dim):\n",
    "                    block_sum += np.abs(\n",
    "                        corr_mat[i : i + vec_dim, i : i + vec_dim]\n",
    "                    ).sum()\n",
    "                ratio = block_sum / (total_sum - block_sum)\n",
    "\n",
    "                cm = axs[level].imshow(\n",
    "                    corr_mat, cmap=\"coolwarm\", interpolation=\"nearest\"\n",
    "                )\n",
    "                #   , vmin=global_min, vmax=global_max)\n",
    "                axs[level].set_title(f\"Layer {level}\")\n",
    "                plt.colorbar(\n",
    "                    cm,\n",
    "                    ax=axs[level],\n",
    "                    orientation=\"vertical\",\n",
    "                    fraction=0.06,\n",
    "                    pad=0.04,\n",
    "                )\n",
    "\n",
    "            extra_text = \"Absolute \" if absval else \"\"\n",
    "            # fig.colorbar(cbar_ax, ax=axs, orientation='vertical', label=f'{extra_text}Correlation Coefficient')\n",
    "\n",
    "            # Set axis labels and title\n",
    "            # plt.xlabel('U2 Entries')\n",
    "            # plt.ylabel('U1 Entries')\n",
    "\n",
    "            # Show the plot\n",
    "            nope1 = \"nope_\" if \"nope\" in exp_list[idx1][1] else \"\"\n",
    "            u1_name = \"_\".join(exp_list[idx1][1].split(\"_\")[2:])\n",
    "            u1_name = (\n",
    "                nope1 + u1_name.split(\"_\")[-1] + \"_\" + \"_\".join(u1_name.split(\"_\")[:-1])\n",
    "            )\n",
    "            nope2 = \"nope_\" if \"nope\" in exp_list[idx1][1] else \"\"\n",
    "            u2_name = \"_\".join(exp_list[idx2][1].split(\"_\")[2:])\n",
    "            u2_name = (\n",
    "                nope2 + u2_name.split(\"_\")[-1] + \"_\" + \"_\".join(u2_name.split(\"_\")[:-1])\n",
    "            )\n",
    "\n",
    "            extra_self = \"Self\" if u1_name == u2_name else \"\"\n",
    "            # plt.title(f'{extra_self} Correlation Matrix for  {ratio:.2f}')\n",
    "            print(u2_name)\n",
    "            if save:\n",
    "                os.makedirs(f\"./saved_plots_{folder_name}/\", exist_ok=True)\n",
    "                plt.savefig(\n",
    "                    f\"./saved_plots_{folder_name}/{task_name+folder_name}_{len(all_level_input_act_list)}layers_{rand_state}_{u2_name}_{ratio:.03f}_{abs}.svg\"\n",
    "                )\n",
    "\n",
    "            # close img\n",
    "            # plt.close()\n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        corr_mat_list = []\n",
    "        for level in range(len(all_level_input_act_list)):\n",
    "            input_act1_list = all_level_input_act_list[level]\n",
    "            global level_corr_mat_accum\n",
    "            for idx1 in tqdm(range(len(input_act1_list))):\n",
    "                idx2 = idx1\n",
    "                u1, u2 = input_act1_list[idx1], input_act1_list[idx2]\n",
    "                u1 = u1.T\n",
    "                u2 = u2.T\n",
    "\n",
    "                if u2.shape[1] != 1: # calculate correlation coefficient\n",
    "                    u1_standardized = standardize_rows(u1)\n",
    "                    u2_standardized = standardize_rows(u2)\n",
    "                    # u1_standardized = u1\n",
    "                    # u2_standardized = u2\n",
    "\n",
    "                    # Compute the correlation matrix\n",
    "                    corr_mat = np.dot(u1_standardized, u2_standardized.T) / (\n",
    "                        u1.shape[1]\n",
    "                    )\n",
    "                else:\n",
    "                    u1 = u1.reshape(-1, 384)\n",
    "                    u2 = u2.reshape(-1, 384)\n",
    "                    # corr_mat = np.dot(u1, u2.T)\n",
    "                    corr_mat = sim_measure(u1, u2)\n",
    "\n",
    "                if absval:\n",
    "                    corr_mat = np.abs(corr_mat)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if accumulate_all:\n",
    "                    level_corr_mat_accum.append(corr_mat[None, ...])\n",
    "                if not save_all:\n",
    "                    continue\n",
    "\n",
    "                if not subplot_layers:\n",
    "                    vec_dim = corr_mat.shape[0] // 8\n",
    "                    total_sum = np.abs(corr_mat).sum()\n",
    "                    block_sum = 0\n",
    "                    for i in range(0, len(corr_mat), vec_dim):\n",
    "                        block_sum += np.abs(\n",
    "                            corr_mat[i : i + vec_dim, i : i + vec_dim]\n",
    "                        ).sum()\n",
    "                    ratio = block_sum / (total_sum - block_sum)\n",
    "\n",
    "                    # Assuming you have calculated 'corr_mat' as described in the previous answer\n",
    "\n",
    "                    # Create a heatmap of corr_mat\n",
    "                    plt.figure(figsize=(6, 5), dpi=120)\n",
    "                    # plt.imshow(corr_mat, cmap='seismic', interpolation='nearest')\n",
    "                    plt.imshow(corr_mat, cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "\n",
    "                    extra_text = \"Absolute \" if absval else \"\"\n",
    "                    plt.colorbar(label=f\"{extra_text}Correlation Coefficient\")\n",
    "\n",
    "                    # Set axis labels and title\n",
    "                    # plt.xlabel('U2 Entries')\n",
    "                    # plt.ylabel('U1 Entries')\n",
    "\n",
    "                    # Show the plot\n",
    "                    nope1 = \"nope_\" if \"nope\" in exp_list[idx1][1] else \"\"\n",
    "                    u1_name = \"_\".join(exp_list[idx1][1].split(\"_\")[2:])\n",
    "                    u1_name = (\n",
    "                        nope1\n",
    "                        + u1_name.split(\"_\")[-1]\n",
    "                        + \"_\"\n",
    "                        + \"_\".join(u1_name.split(\"_\")[:-1])\n",
    "                    )\n",
    "                    nope2 = \"nope_\" if \"nope\" in exp_list[idx1][1] else \"\"\n",
    "                    u2_name = \"_\".join(exp_list[idx2][1].split(\"_\")[2:])\n",
    "                    u2_name = (\n",
    "                        nope2\n",
    "                        + u2_name.split(\"_\")[-1]\n",
    "                        + \"_\"\n",
    "                        + \"_\".join(u2_name.split(\"_\")[:-1])\n",
    "                    )\n",
    "\n",
    "                    extra_self = \"Self\" if u1_name == u2_name else \"\"\n",
    "                    # plt.title(f'{extra_self} Correlation Matrix for  {ratio:.2f}')\n",
    "                    # print(ratio)\n",
    "                    # print(u1_name, u2_name)\n",
    "                    os.makedirs(f\"./saved_plots_{folder_name}/\", exist_ok=True)\n",
    "                    plt.savefig(\n",
    "                        f\"./saved_plots_{folder_name}/{task_name+folder_name}_{rand_state}_{u2_name}_layer{level}_{ratio:.03f}_{abs}.svg\"\n",
    "                    )\n",
    "\n",
    "                    # close img\n",
    "                    plt.close()\n",
    "                # plt.show()\n",
    "\n",
    "            if accumulate_all:\n",
    "                level_corr_mat_accum = np.vstack(level_corr_mat_accum)\n",
    "                print(level_corr_mat_accum.shape)\n",
    "                level_corr_mat_accum = level_corr_mat_accum.mean(axis=0)\n",
    "                # Create a heatmap of corr_mat\n",
    "                if not subplot_layers:\n",
    "                    plt.figure(figsize=(6, 5), dpi=120)\n",
    "                    # plt.imshow(corr_mat, cmap='seismic', interpolation='nearest')\n",
    "                    plt.imshow(\n",
    "                        level_corr_mat_accum, cmap=\"coolwarm\", interpolation=\"nearest\"\n",
    "                    )\n",
    "\n",
    "                    extra_text = \"Absolute \" if absval else \"\"\n",
    "                    plt.colorbar(label=f\"{extra_text}Correlation Coefficient\")\n",
    "                    plt.show()\n",
    "                corr_mat = level_corr_mat_accum\n",
    "                level_corr_mat_accum = []\n",
    "            corr_mat_list.append(corr_mat)\n",
    "        if subplot_layers:\n",
    "            fig, axs = plt.subplots(\n",
    "                1, 6, figsize=(36, 5)\n",
    "            )  # 6 subplots in a row, adjust size as needed\n",
    "            for level in range(len(all_level_input_act_list)):\n",
    "\n",
    "                corr_mat = corr_mat_list[level]\n",
    "\n",
    "                # vec_dim = 384\n",
    "                vec_dim = corr_mat.shape[0] // 8\n",
    "\n",
    "                total_sum = np.abs(corr_mat).sum()\n",
    "                block_sum = 0\n",
    "                for i in range(0, len(corr_mat), vec_dim):\n",
    "                    block_sum += np.abs(\n",
    "                        corr_mat[i : i + vec_dim, i : i + vec_dim]\n",
    "                    ).sum()\n",
    "                ratio = block_sum / (total_sum - block_sum)\n",
    "\n",
    "                cm = axs[level].imshow(\n",
    "                    corr_mat, cmap=\"coolwarm\", interpolation=\"nearest\"\n",
    "                )\n",
    "                #   , vmin=global_min, vmax=global_max)\n",
    "                axs[level].set_title(f\"Layer {level}\")\n",
    "                plt.colorbar(\n",
    "                    cm,\n",
    "                    ax=axs[level],\n",
    "                    orientation=\"vertical\",\n",
    "                    fraction=0.06,\n",
    "                    pad=0.04,\n",
    "                )\n",
    "\n",
    "            print(u2_name)\n",
    "            if save:\n",
    "                os.makedirs(f\"./saved_plots_{folder_name}/\", exist_ok=True)\n",
    "                plt.savefig(\n",
    "                    f\"./saved_plots_{folder_name}/{task_name+folder_name}_avg_{abs}.svg\"\n",
    "                )\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"$\" + f\"{i}\"*3 + '+' + f\"{i}\"*3 + '='\n",
    "import glob\n",
    "fixed_length = 9\n",
    "all_level_input_act_list = []\n",
    "sample_num = 1024\n",
    "\n",
    "# model_list = []\n",
    "# for idx, (config_dir, model_config_fold) in enumerate(exp_list):\n",
    "#     glob_dir = config_dir.replace('[', '[[]')\n",
    "#     yaml_path = glob.glob(f'{glob_dir}/**/config.yaml')[0]\n",
    "#     revised_glob_dir = '/'.join(yaml_path.split('/')[:-2])\n",
    "#     exp_list[idx][0] = revised_glob_dir\n",
    "#     exp_list[idx][1] = revised_glob_dir.split('/')[-1]\n",
    "\n",
    "#     with open(yaml_path) as f:\n",
    "#         config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "#     ckpt = f\"{revised_glob_dir}/ckpt_10000_acc.pt\"\n",
    "#     model, gptconfig = load_checkpoint(\n",
    "#         ckpt, GPTConfig_nope, GPT_nope, device='cuda', return_config=True)\n",
    "\n",
    "#     # gptconfig.not_causal = [1]*6\n",
    "#     # model = GPT_nope(GPTConfig_nope())\n",
    "#     # model = GPT_nope(gptconfig)\n",
    "\n",
    "#     # for i in range(len(model.transformer.h)):\n",
    "#     #   model.transformer.h[i].attn._reset_parameters()\n",
    "#     #   model.transformer.h[i].mlp._reset_parameters()\n",
    "#     # model.apply(model._init_weights)\n",
    "\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     model_list.append(model)\n",
    "\n",
    "\n",
    "for level in range(0, 8):\n",
    "    level = level - 1\n",
    "    input_act1_list = [list() for _ in range(len(model_list))]\n",
    "\n",
    "    for hidx in range(0, 1):  # try 5 batches\n",
    "        X, Y = get_batch('train')\n",
    "        X = decode(X[0].tolist())\n",
    "        X_8 = list(map(lambda x: x[:fixed_length], filter(lambda x: len(\n",
    "            x) >= fixed_length and x[fixed_length-1] == '=', X.split('\\n'))))\n",
    "        X_8 = [''.join(list(np.array(list(x))[np.random.permutation(len(x))]))\n",
    "               for x in X_8]\n",
    "        X = torch.tensor(list(map(lambda x: encode(x), X_8)))\n",
    "        # X = X.reshape(-1, fixed_length)\n",
    "        # X = X[:sample_num]\n",
    "        X = X.to(device)\n",
    "\n",
    "        for midx, model in enumerate(model_list):\n",
    "            activation = {}\n",
    "\n",
    "            def getActivation(name):\n",
    "                # the hook signature\n",
    "                def hook(model, input, output):\n",
    "                    activation[name] = output.detach()\n",
    "                return hook\n",
    "            # register forward hooks on the layers of choice\n",
    "\n",
    "            if level == 6:\n",
    "                h1 = model.transformer.ln_f.register_forward_hook(\n",
    "                    getActivation(f'layer_{level}'))\n",
    "            elif level == -1:\n",
    "                h1 = model.transformer.wte.register_forward_hook(\n",
    "                    getActivation(f'layer_{level}'))\n",
    "            else:\n",
    "                h1 = model.transformer.h[level].ln_1.register_forward_hook(\n",
    "                    getActivation(f'layer_{level}'))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _ = model(X)\n",
    "\n",
    "            h1.remove()\n",
    "\n",
    "            acts = activation[f'layer_{level}'].detach().cpu().numpy()\n",
    "            input_act1_list[midx].append(acts)\n",
    "            # outs = activation['x_out'].detach().cpu().numpy()\n",
    "            # input_act1_list[midx].append(outs)\n",
    "\n",
    "    for hidx in range(len(input_act1_list)):\n",
    "        print(len(input_act1_list[hidx]))\n",
    "        cur_input_act1 = np.concatenate(input_act1_list[hidx], axis=0)\n",
    "        bs, l, dim = cur_input_act1.shape\n",
    "        targets = np.zeros((bs, l)) + np.arange(l)[None, ...]\n",
    "        print(cur_input_act1.shape)\n",
    "        input_act1_list[hidx] = (cur_input_act1, targets)\n",
    "\n",
    "    all_level_input_act_list.append(input_act1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "len(all_level_input_act_list[0][1][1])\n",
    "\n",
    "# do a scklearn linear regression\n",
    "\n",
    "\n",
    "def crossing(X, y):\n",
    "    X_cross = []\n",
    "    y_cross = []\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X)):\n",
    "            if i != j:\n",
    "                X_cross.append(X[i] * X[j])\n",
    "                y_cross.append(np.abs(y[i] - y[j]))\n",
    "    X = np.array(X_cross)\n",
    "    y = np.array(y_cross)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "@widgets.interact(layer=(-1, 6), model_idx=(0, len(all_level_input_act_list[0])-1))\n",
    "def probe_layer(layer=-1, model_idx=0):\n",
    "    layer = layer + 1\n",
    "    print(exp_list[model_idx][0])\n",
    "    X = all_level_input_act_list[layer][model_idx][0]\n",
    "    y = all_level_input_act_list[layer][model_idx][1]\n",
    "\n",
    "    # X = np.random.rand(*y.shape,10)\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    y = y.reshape(-1)\n",
    "    X_train, X_test = X[:int(len(X)*0.8)], X[int(len(X)*0.8):]\n",
    "    y_train, y_test = y[:int(len(X)*0.8)], y[int(len(X)*0.8):]\n",
    "\n",
    "    # X_train, y_train = crossing(X, y)\n",
    "    # X_test, y_test = crossing(X, y)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    # X_test = X_train\n",
    "    # y_test = y_train\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred))\n",
    "    print(reg.score(X_test, y_test))\n",
    "    print(y_test[:10])\n",
    "    print(y_pred[:10])\n",
    "\n",
    "    # print('coef:', reg.coef_)\n",
    "    plt.plot(reg.coef_)\n",
    "    plt.show()\n",
    "\n",
    "    mav = []\n",
    "    for i in range(10):\n",
    "        plt.plot(X_test[i])\n",
    "        mav.append(np.abs(X_test[i]).mean())\n",
    "    plt.show()\n",
    "\n",
    "    print(list(zip(y_test[:10], mav)))\n",
    "\n",
    "    mav = []\n",
    "    for i in range(len(y_test)):\n",
    "        mav.append(np.abs(X_test[i]).mean())\n",
    "\n",
    "    # plt.scatter(y_test, mav, s=20, alpha=0.2)\n",
    "    # plt.show()\n",
    "    print(y_test.shape)\n",
    "\n",
    "    plt.scatter(y_test, y_pred, s=20, alpha=0.2)\n",
    "\n",
    "# normalize the input and do again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Nope and original behaves differently\n",
    "2. When organized and unorganized, the activation output from the trained model is different, meaning that the model somehow also semantically managed the position of numbers and symbos \n",
    "3. For original pe, the regression model must be memorizing the absvalvalolute position initialized randomly at the start of the model. But that didn't explain why NOPE can also get positions right? Then there must be something permanent inside the model that indicates the positions, emm, such as a fixed bias?\n",
    "4. If looking closely at the activations from layers without skip \n",
    "\n",
    "\n",
    "Maybe check why noncausal still doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check random initialization problem\n",
    "\n",
    "* Want to actually check that empirically Qx \\cdot Ky is maximized\n",
    "(usually) when x\\approx y\n",
    "    - could be Wk making W_ky more similar to W_kx\n",
    "    - \\sum a_i b_i (W_Q Z_i) (W_k Z_i) where Z_i can be the pca basis / or any other spectral decomposition\n",
    "\n",
    "... an evidence that residual connection is preserving the locality of r.vec. x\n",
    "\n",
    "... Hypothesis: signs tend to be the same for z1=z2 and different otherwise\n",
    "\n",
    "* Want to compute the rank of\n",
    "    - with\n",
    "        - (1) Transformers with random initialization\n",
    "        - (2) Transformers at convergence\n",
    "\n",
    "    - for\n",
    "       - (a) full residual connections\n",
    "       - (b) no residual connections\n",
    "       - (c) some residual connections\n",
    "\n",
    "check rank degeneration: PCA -> compute the ratio \n",
    "- i.e. a1^2 / sum(ai^2) \n",
    "- plz see how the paper measures the rank degeneration \n",
    "\n",
    "* Want to check what happens when the residual connections we ablate\n",
    "are not consecutive (both non-consecutive layers, and when things\n",
    "taken out are pre-MLP/post-MLP)\n",
    "\n",
    "\n",
    "* Fix the description of the correlation img\n",
    "    - Collect the ratio from the graph and put into a table\n",
    "    - generate the image for all experiments we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- emperically validate qk, if vectors points in the same direction, othen kx dot qy should be high (for trained k,q)\n",
    "    - Plot the correlation on this: QxdotKx vs xdoty \n",
    "- description for correlation matrix\n",
    "\n",
    "or x being actual inputs $x \\in R^d$, project x using K and Q (for a lot of x) would be generally a projection into to the same subspace, namely $Kx \\cdot Qx$ be high\n",
    "    - PCA on K{x}, project on the first 100 components\n",
    "    - project on the first 100 components of Q{x}\n",
    "\n",
    "$K{x} : subspace {Kx| x \\in R^d}$\n",
    "compare projecting K{x} on the principal components of Q{x} to projecting K{x} on the standard basis\n",
    "(n.b., projecting on the first 100 components of the standard basis is just taking the first 100 coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 24\n",
    "plt.plot(X_train[idx])\n",
    "print(y_train[:10])\n",
    "print(reg.predict(X_train[:10][:]))\n",
    "print(X_train[:10].sum(axis=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
